<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[word embedding作用及用法]]></title>
    <url>%2F2020%2F06%2F07%2Fword-embedding%E4%BD%9C%E7%94%A8%E5%8F%8A%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[关于word embedding总结]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>NLP</tag>
        <tag>词向量</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LightGBM论文笔记]]></title>
    <url>%2F2020%2F03%2F14%2FLightGBM%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[lightGBM论文总结]]></title>
    <url>%2F2020%2F03%2F10%2Fxgboost%E5%92%8ClightGBM%2F</url>
    <content type="text"><![CDATA[LightGBM提出动机为了解决GBDT在海量数据中遇到的问题，让GBDT算法更好的适用于工业实践。1、XGBoost的缺点 需要保存特征值和排序结果，还需要保存排序的索引 每次分裂一个点的时候，都需要计算收益 对cache优化不友好，容易造成cache miss 2、LightGBM的优化 单边梯度采样GOSS 直方图算法 互斥特征捆绑算法 Leaf-Wise分裂算法 类别特征最有分裂 并行学习优化 cache命中率优化 2. 数据原理2.1.基于直方图的算法对于XGBoost，其实现是预排序算法，LiggtGBM是基于直方图的算法。 直方图算法计算过程 遍历每一个叶子结点的每一个特征 为每一个特征创建一个直方图，将样本的梯度($g_i$)之和和样本数$n$保存到bin中 然后遍历所有的bin，以当前的bin作为分裂点，然后计算分裂后的左右节点梯度和节点数目 通过直方图加速法算出左右节点的梯度和$S_L$和$S_R$，已经bin的数量 计算分裂后的收益$loss=\frac{S_L^2}{n_L}+\frac{S_R^2}{n_R}-\frac{S_P^2}{n_p}$ 其实，思想和xgb差不多，在选择分裂点的时候，xgb用的是预排序算法，lgb用的是梯度直方图。 然后在计算上的代价也大幅降低，预排序算法每遍历一个特征值就需要计算一次分裂的增益，而直方图算法只需要计算k次（k可以认为是常数），时间复杂度从O(#data#feature)优化到O(k#features)。 直方图离散化优点： 占用内存更小，相对于XGBoost预排序算法，无需存储特征值和排序索引 计算代价更小，预排序算法需要每遍历一个特征值，就计算一次收益，而直方图算法只用计算K次，时间复杂度有O(data feature)下降到O(k feature) 当然，Histogram算法并不是完美的。由于特征被离散化后，找到的并不是很精确的分割点，所以会对结果产生影响。但在不同的数据集上的结果表明，离散化的分割点对最终的精度影响并不是很大，甚至有时候会更好一点。原因是决策树本来就是弱模型，分割点是不是精确并不是太重要；较粗的分割点也有正则化的效果，可以有效地防止过拟合；即使单棵树的训练误差比精确分割的算法稍大，但在梯度提升（Gradient Boosting）的框架下没有太大的影响。 2.2 单边梯度采样GOSS对于GBDT的数据，梯度越大，说明训练误差越大，这样的样本对模型的提升也越大(adaboost思想)，因此GOSS的算法的思想是保留梯度交大的样本，然后在剩余梯度较小的样本中进行采样。不直接丢掉梯度较小的样本数据的原因是会影响数据总体分布。 具体流程 首先将分裂的特征按照绝对值大小进行排序 选择梯度最大的a%的数据 在剩余的数据中随机挑选b%个数据 然后对于梯度较小的数据，乘以1个常数$\frac{1-a}{b}$ 最后将挑选出来的数据进行合并，计算信息增益 2.3 互斥特征捆绑算法互斥捆绑算法的目的是为了减少特征维度，因为实际任务中，特征一般是高维稀疏的。 对于完全互斥的特征，可以将其捆绑起来，例如one-shot产生的特征，捆绑之后不会造成信息丢失。 对于不完全互斥的特征，存在部分情况下两个特征都为非0值，可以使用冲突比率（同时不为0的样本数之和/所有样本数）对不互斥程度进行衡量，当小于一定值时，可以将两个不完全互斥的特征捆绑。 对于特征捆绑，有两个问题 1、如何确定哪些特征需要绑在一起 2、如何构建绑定后的特征 对于第一个问题，确定那些问题需要绑定，LightGBM的做法如下 1、构建一个无向加权图，顶点表示特征，边的权值大小表示冲突比率 2、基于特征在图中的度数进行降序排序 3、遍历每个捆绑特征，检查捆绑之后特征数是否小于最大冲突数 冲突数小于K，将该特征添加到捆绑 冲突数大于K，创建新的捆绑特征 对于第二个问题，如何构建绑定后的特征，关键在于如何从绑定后的特征识别出原始特征中的值。基于直方图算法存储的是离散的箱子，而不是连续的特征值。LightGBM是基于特征从属于不同的箱子来构建捆绑特征的。假设特征A的原始特征取值空间为[0,10),特征B的取值空间为[0,20)，当 此时可以在特征B的区间上加上偏置10，此时B的取值空间为[10,20)，而AB绑定后的特征取值空间为[0,30)。 EFB算法可以将很多互斥稀疏特征捆绑成少量稠密特征，避免针对特征值0的不必要计算。虽然可以优化基于直方图的算法，使用一张表保存每个特征非0取值，然后通过扫描这张表来构建直方图，这样时间复杂度就从原来的O(data)变成了O(no_zero_data)，缺点在于需要额外的算力和空间保存和更新这张表。LGB将其作为辅助功能。 2.4 Leaf-Wise分裂算法 2.5 类别特征最优分裂这部分没怎么看懂，参考的 离散特征建立直方图的过程：统计该特征下每一种离散值出现的次数，并从高到低排序，并过滤掉出现次数较少的特征值, 然后为每一个特征值，建立一个bin容器, 对于在bin容器内出现次数较少的特征值直接过滤掉，不建立bin容器。 计算分裂阈值的过程： 先看该特征下划分出的bin容器的个数，如果bin容器的数量小于4，直接使用one vs other方式, 逐个扫描每一个bin容器，找出最佳分裂点; 对于bin容器较多的情况, 先进行过滤，只让子集合较大的bin容器参加划分阈值计算, 对每一个符合条件的bin容器进行公式计算(公式如下: 该bin容器下所有样本的一阶梯度之和/该bin容器下所有样本的二阶梯度之和 + 正则项(参数cat_smooth)，这里为什么不是label的均值呢？其实上例中只是为了便于理解，只针对了学习一棵树且是回归问题的情况， 这时候一阶导数是Y, 二阶导数是1)， 3 工程优化3.1 并行学习优化LightGBM 提供以下并行学习优化算法： 特征并行适用于数据量比较少，feature比较多 传统的特征并行算法旨在于在并行化决策树中的“ Find Best Split.主要流程如下: 垂直划分数据（不同的机器有不同的特征集） 在本地特征集寻找最佳划分点 {特征, 阈值} 本地进行各个划分的通信整合并得到最佳划分 以最佳划分方法对数据进行划分，并将数据划分结果传递给其他线程 其他线程对接受到的数据进一步划分 然而，该特征并行算法在数据量很大时仍然存在计算上的局限。因此，建议在数据量很大时使用数据并行。 数据并行适用于大数据，feature比较少 数据并行旨在于并行化整个决策学习过程。数据并行的主要流程如下： 水平划分数据 线程以本地数据构建本地直方图 将本地直方图整合成全局整合图 在全局直方图中寻找最佳划分，然后执行此划分 数据并行的缺点 机器的通讯开销大约为 “O(#machine #feature #bin)” 。 如果使用集成的通讯算法（例如， “All Reduce”等），通讯开销大约为 “O(2 #feature #bin)”[8] 。 投票并行大数据并且feature比较多 基于投票的并行是对于数据并行的优化，主要分为两步： 通过本地数据，找到本地top k的特征 利用投票筛选出可能是全局最优点的特征 合并直方图时，只合并被选出来的部分 3.2 Cache命中率优化预排序算法： 不同的特征访的梯度顺序不同 对于索引表的访问，pre_sort使用了行号和叶子节点的索引表 都是随机访问，容易造成cache miss lightGBM对直方图优化： 梯度直方图不需要对梯度进行排序 直方图算法不需要数据到叶子id的索引表 4 XGBoost和LightGBM区别 xgboost是预排序算法，lightGBM是直方图算法。 分裂方式，xgb是level-wise，lgb是Leaf-Wise lgb支持类别特征 采用了单边梯度采样和互信息捆绑进行优化 并行化，feature在节点进行分裂的时候采用了多线程并行化，而lgb采用了特征并行、数据并行、投票并行 基于分裂算法的不同，lgb对cache命中更加高效 参考1、https://cloud.tencent.com/developer/article/1528372 2、https://mp.weixin.qq.com/s/M25d_43gHkk3FyG_Jhlvog 3、https://www.biaodianfu.com/lightgbm.html 4、https://www.zhihu.com/question/266195966 5、https://lightgbm.apachecn.org/#/docs/4 6、直方图算法深入理解]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>决策树</tag>
        <tag>Xgboost</tag>
        <tag>lightGBM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[XGBoost原理总结]]></title>
    <url>%2F2020%2F03%2F09%2FXGBoost%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Xgboost, 是GBDT的一种实现方式，并且xgboost做了一些改进和优化。1. 原理1.1 优化目标函数对于GBDT方法，都是基模型组成的加法公式。 \hat y_i = \sum_{i=1}^kf_t(x_i)\tag{1}其中$f_k$为基模型,$y_i$表示第$i$个样本预测值。正则化损失函数 \zeta^t=\sum_{i=1}^n l(y_i,\hat y_i^{(t-1)})+\Omega(f_t)\tag{2}对于损失函数（2）进行二阶展开有： \zeta^{(t)} \approx \sum_{i=1}^n[l(y_i,\hat y_i) +g_if_t(x_i)+\frac{1}{2}h_if_t^2(x_i)]+\Omega(f_t) \\ where\quad \Omega(f)=\gamma T+\frac{1}{2}\lambda||w||^2\tag{3}对于损失函数，xgboost在处理的时候进行了二阶展开，其中$g_i=\frac{\partial l(y_i,\hat y_i^{(t-1)})}{\partial \hat y_i^{(t-1)}}$, $h_i=\frac{\partial ^2l(y_i,\hat y_i^{(t-1)})}{\partial (\hat y_i^{(t-1)})^2}$。其中$g_i$和$h_i$分别对应一阶倒和二阶倒数，正则项$T$表示叶子节点数目，$w$表示叶子的分数。$\gamma$空值叶子节点的个数，保证叶子节点不会过多分裂，而$\lambda$空值叶子结点的分值，避免分值过大造成过拟合。 对于第$t$步而言，前面的$t-1$步已经固定，因此有一阶、二阶梯度$g_i$和$h_i$为一个常数。因此目标函数可以化简为 \hat \zeta^t=\sum_{i=1}^n[g_if_t(x_i)+\frac{1}{2}h_if_t^2(x_i)]+\Omega(f_t)\tag{4}定义$I_j=\{x|q(x_i)=j\}$,表示为叶子结点$j$中的样本。所以上式(3)可以重写为 \hat\zeta^{(t-1)}=\sum_{i=1}^n[g_if_t(x_i)+\frac{1}{2}h_if^2_t(x_i)]+\gamma T + \frac{1}{2}\lambda \sum_{j=1^T}w_j^2\tag{5} =\sum_{j=1}^T[(\sum_{i\in I_j}g_i)w_j+\frac{1}{2}(\sum_{i\in I_j}h_i+\lambda)w_j^2]+\gamma T \tag{6}这里其实进行了一个转换，对于公式5而言，计算的损失函数是将所有数据得到损失函数。对于决策树，样本最终会落到叶子结点，因此公式6是通过叶子节点求损失值。 对于固定结构的$q(x)$，即改树节点时固定的，可以计算叶子结点$j$的最优权重$w_j^*$ w_j^*=-\frac{2\sum_{i\in I_j}g_i}{\sum_{i\in I_j}h_i+\lambda}将结果带入上式6有 \hat \zeta^{(t)}=-\frac{1}{2} \sum_{j=1}^T\frac{(\sum_{i\in I_j}g_i)^2}{\sum_{i\in I_j}h_i+\lambda}\tag{7}定$G_j=\sum_{i\in I_j}g_i$,$H_j=\sum_{i\in I_j}h_i$，则有 w_j^*=-\frac{G_j}{H_j+\lambda}将上式带入公式7化简有 \zeta^{(t)}=-\frac{1}{2}\sum_{j=1}^T\frac{G_j^2}{H_j+\lambda}\tag{8}对于Xgboost使用泰勒展开的原因是因为想统一损失函数的形式，方便自定义损失函数。 1.2最佳切分点算法xgboost支持两种实现，贪心算法和近似算法。sklearn中GBDT是贪心算法 1）贪心算法，和GBDT一样，暴力枚举 1、对于所有叶子节点枚举可用的特征，并且将特征值按照升序排序 2、计算节点分裂时候的收益 3、选择收益做大的节点和特征进行分裂 4、重复1，直到分裂结束 关键点在于对收益的计算 假设某一节点完成分裂，在分裂前，其目标函数为 L(y,\hat y_i)=-\frac{1}{2}[\frac{(G_L+G_R)^2}{H_L+H_R+\lambda}]+\gamma\tag{9}分裂后的目标函数为 L=-\frac{1}{2}[\frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda}]+2\gamma\tag{10}所以分裂一个节点的收益可以从用式（9）-（10） Gain=-\frac{1}{2}[\frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda}-\frac{(G_L+G_R)^2}{H_L+H_R+\lambda}]-\gammaG表示所有叶子节点的梯度 2)近似算法 作用在于选择，当数据量比较大，无法全部读入内存时，给出近似最优解。对比贪心算法，可能在精度上有所缺失，但是提升了速度，降低了内存消耗。 该算法的核心思想是根据特征分布的分位数提出候选点，然后将特征映射到候选划分的桶之中，然后统计桶中的聚合信息(指的前面的$g$和$h$)，找到所有区间最佳分裂点。 1、对于特征k根据分位数找到候选集合 2、将样本映射到改候选集合对应的分区桶中 该算法有两种变体，区别在于何时剔除候选点： Global：在初始阶段就给出所有候选节点，并且在后续分裂中使用相同的分裂节点。 Local：每次分裂重新提出候选节点 分位图 加权分位图： 由于前面我们知道目标函数为 L=\sum_{i=1}^n[g_if_t(x_i)+\frac{1}{2}h_if_t^2(x_i)]+\Omega(f_t)\tag{11}由于$g_i$和$h_i$是有上一轮迭代得到，因此都是常数，所以上式可以变形为： L\approx\sum_{i=1}^n\frac{1}{2}h_i[(f_t(x_i)+\frac{g_i}{h_i})^2]+\Omega(f_t)+C \\C=-\frac{g_i^2}{h_i}\tag{12}这样损失函数就变成了加权的形式，因此对于每个样本，其实权值是不等的，所以采用加权分位图。 1.3 稀疏感知分裂在实际问题中，通常输入数据都是稀疏的，造成稀疏的原因有： 数据缺失 一些统计量常常为0 特征工程的结果，如one-shot 稀疏感知算法的目的是给每个节点一个默认的分裂方向，其思想非常简单，就是分别计算缺失值样本分裂到左边或者右边是的收益，选择收益大的一个分支作为最优缺省值方向 2. 工程优化2.1 块结构设计树学习中最耗时的部分是数据排序。为了减少排序的成本，我们提出将数据存储在内存单元中，称之为block。每个block中的数据每列根据特征取值排序，并以压缩列（CSC）格式储存。这种输入数据布局只需要在训练前计算一次，可以在后续迭代中重复使用。 每个块包含一个或者多个已经排好序的特征 缺失值将不在进行排序 每个特征值都会存储样本梯度统计值索引 因为每个特征都是独立存放，因此在选择特征进行分裂的时候可以分布式实现 2.2 缓存方法优化算法是通过行索引提取梯度统计量，但是在排序之后就会乱掉，不能够直接访问。并且当统计量没法放进CPU缓存是，会导致访问失败，因此xgb给每个线程分配一个内部缓冲区。 2.3 核外快计算方式对于数据量比较大的数据，没有办法存储到内存，可以考虑部分读取，将数据存储到硬盘，但是硬盘读取会占用大量时间 XGBoost采用两种方式降低硬盘读取开销 1、块压缩：对Block进行案列压缩，并且在读取时解压 2、块拆分：将每个块存储到不同的磁盘，然后从多个磁盘读取增加吞吐量。 3. GBDT和XGBoost区别 传统GBDT以CART作为基分类器，xgboost还支持线性分类器，这个时候xgboost相当于带L1和L2正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）。 传统GBDT在优化时只用到一阶导数信息，xgboost则对代价函数进行了二阶泰勒展开，同时用到了一阶和二阶导数。顺便提一下，xgboost工具支持自定义代价函数，只要函数可一阶和二阶求导。 xgboost在代价函数里加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、每个叶子节点上输出的score的L2模的平方和。从Bias-variance tradeoff角度来讲，正则项降低了模型的variance，使学习出来的模型更加简单，防止过拟合，这也是xgboost优于传统GBDT的一个特性。 Shrinkage（缩减），相当于学习速率（xgboost中的eta）。xgboost在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间。实际应用中，一般把eta设置得小一点，然后迭代次数设置得大一点。（补充：传统GBDT的实现也有学习速率） 列抽样（column subsampling）。xgboost借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算，这也是xgboost异于传统gbdt的一个特性。 对缺失值的处理。对于特征的值有缺失的样本，xgboost可以自动学习出它的分裂方向。 xgboost工具支持并行。boosting不是一种串行的结构吗?怎么并行的？注意xgboost的并行不是tree粒度的并行，xgboost也是一次迭代完才能进行下一次迭代的（第t次迭代的代价函数里包含了前面t-1次迭代的预测值）。xgboost的并行是在特征粒度上的。我们知道，决策树的学习最耗时的一个步骤就是对特征的值进行排序（因为要确定最佳分割点），xgboost在训练之前，预先对数据进行了排序，然后保存为block结构，后面的迭代中重复地使用这个结构，大大减小计算量。这个block结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行。 可并行的近似直方图算法。树节点在进行分裂时，我们需要计算每个特征的每个分割点对应的增益，即用贪心法枚举所有可能的分割点。当数据无法一次载入内存或者在分布式情况下，贪心算法效率就会变得很低，所以xgboost还提出了一种可并行的近似直方图算法，用于高效地生成候选的分割点。 调参技巧略，直接看API就行了。。。。懒得总结了 参考资料 [1].https://www.zhihu.com/question/41354392/answer/98658997 [2].https://mp.weixin.qq.com/s/LoX987dypDg8jbeTJMpEPQ [3].行抽样、列抽样]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>决策树</tag>
        <tag>GBDT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop数据倾斜及解决办法]]></title>
    <url>%2F2019%2F12%2F15%2Fhadoop%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95%2F</url>
    <content type="text"></content>
      <categories>
        <category>hadoop</category>
        <category>hive</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于决策树总结]]></title>
    <url>%2F2019%2F11%2F04%2F%E5%85%B3%E4%BA%8E%E5%86%B3%E7%AD%96%E6%A0%91%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[决策树处理连续值]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>决策树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[梯度提升树]]></title>
    <url>%2F2019%2F10%2F10%2FGBDT%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[GBDT主要由三个概念组成：Regression Decistion Tree（即DT)，Gradient Boosting（即GB)，Shrinkage（算法的一个重要演进分枝，目前大部分源码都按该版本实现）。搞定这三个概念后就能明白GBDT是如何工作的，要继续理解它如何用于搜索排序则需要额外理解RankNet概念，之后便功德圆满。下文将逐个碎片介绍，最终把整张图拼出来。 加法模型对于算法模型而言，一个性能弱的算法模型可能很难得到很好的效果，加法模型的思想是将性能较弱的模型通过加权得到一个性能较强的模型。形如 f(x)=\sum_{m=1}^{M}\beta_m b(x;\gamma_m)\tag{1}其中$b(x;y_m)$表示基函数，$\gamma_m$表示基函数系数，$\beta_m$表示基函数系数。 前向分布算法在给定训练集的情况下以及损失函数$L(y,f(x))$的条件下，学习加法模型$f(x)$即为最小化损失函数的问题： \min\limits_{\beta_m,\gamma_m}\sum_{i=1}^N L(y_i,\sum_{m=1}^M\beta_mb(x_i;\gamma_m))\tag{2}前向分步算法的思想：加法模型是不同模型的组合，因此从前向后每次学习一个基函数和基函数系数来逐步优化目标函数$(1)$,从而降低复杂度。 计算流程： (1).初始化第一个基函数$f_0(x)$ (2)对于$m=1,2,3,…,M$，极小化损失函数 (\beta_m,\gamma_m)=\arg \min\limits_{\beta,\gamma}+\beta_mb(x;\gamma_m)\tag{3}得到参数$\beta_m,\gamma_m$ (3) 更新加法模型 f_m(x)=f_{m-1}(x)+\beta_mb(x;\gamma_m)\tag{4}(4)得到加法模型 f(x)=\sum_{i=1}^M\beta_mb(x;\gamma_m)\tag{5}GBDT梯度提升模型提升树算法提升方法可以总结为加法模型与前向分布算法，以决策树为基函数的模型成为提升树，无论是分类问题还是回归问题，都是基于回归树(这点和统计学系方法里面不一样)，提升树算法则是采用前向分步算法来更新加法模型。对于提升树，基函数变为决策树，所以加法模型为 f_m(x)=\sum_{i=1}^MT(x;w_m)\tag{6}其中$M$为决策树的个数，$w$为决策树的参数，$T$表示决策树。 初始化第一棵决策树，第$m$部的模型为 f_m(x)=f_{m-1}(x)+T(x;w)\tag{7}通过最小化损失函数确定下一棵决策树的参数$w_m$ \arg\min\limits_{w_m}\sum_{i=1}^NL(y_i,f_{m-1}+T(x_i,w_m))当采用平方误差时 L(y,f(x))=(y-f(x))^2\tag{8}损失函数变为 L(y)=(y-f_{m-1}(x)-T(x;w_m))^2 =[r-T(x;w_m)]^2\tag{9}其中残差$r=y-f_{m-1}(x)$，所以最后的目的就是为了是$T(x;w_m)$的值更加接近残差，从而达到最小化损失函数的作用。 回归问题提升树1.计算出第一颗树第一棵提升树 f_0(x)=\arg \min\limits\sum_{i=1}^NL(y_i,c)\tag{10}2.得到提升树的残差 r_{mi}=y_i-f_{m-1}(x_i), i=1,2,3....,N\tag{11}3.通过拟合残茶学习回归树，得到$T_m(x;w_m)$ 4.更新提升树 f_m(x)=f_{m-1}(x)+T(x;w_m)\tag{12}梯度提升梯度提升本质其实是利用梯度下降算法来对前向分步算法进行优化求解的方法。其关键是利用损失函数负梯度在当前模型的值作为残差的近似值，进行一个拟合。 r_{mi}=-[\frac{\partial L(y,f(x_i))}{\partial f(x_i)}]_{f(x_i)=f_m(x_i) }\tag{13}利用负梯度代替残差的原因是因为只有在损失函数为平方差的时候，梯度才等于残差，但是当损失函数比较复杂的时候，此时梯度是不等于残差的。 对于特征的选择和回归树一样，同样是遍历所有特征找到最佳切分点。 回归例子可以参见统计学习方法。 GBDT用于分类和回归的区别前面主要将的是GBDT的思想，利用残差不断的拟合，直到最后接近目标。但是对于对于分类和回归任务的处理，主要有以下几个方面不一样。 特征选择1、分裂节点的评价标准不同 对于回归类问题，分裂节点的时候主要评价方式为 (1)平方误差 L(x,c)=min \sum_{i=1}^m\sum_{j\in R_i}(x_j-c_i)^2将特征划分为m个不同的区域$R_i$，然后求出每个区域的平方误差求和，平方误差和最小的特征和切分点。 (2)绝地值误差 L(x,c)=min \sum_{i=1}^m\sum_{j\in R_i}|x_j-c_i|(3)friedman_mse：费尔德曼均方误差，改进后的均方误差，一般能够达到比较好的效果 对于分类问题，其节点分类的评价方式为 (1)信息熵(entropy) H(x)=-\sum_{i=1}^np_i\log p_i(2)gini,基尼系数(信息增益) g(D,A)=H(D)-H(D|A)详细计算过程见统计学习方法。 损失函数在介绍分类的原理之前首先要了解一下对数损失函数 L(y,P(Y|X))=log P(Y|X)\tag{14}对于分类任务，GBDT是结合回归加分类模型计算每种分类的概率，对于二分类，采用的是logistic进行分类 P(Y=1|X)=\frac{1}{1+exp(-\sum_{i=1}^Mf_i(x))}\tag{15} P(Y=0|X)=\frac{1}{1+exp(\sum_{i=1}^Mf_i(x))}\tag{16}令$h_\theta(x)=\frac{1}{1+exp(-\sum_{i=1}^Mf_i(x))}$ 所以有 P(Y=1|X)=h_\theta(x)\tag{17} P(Y=0|X)=1-h_\theta(x)\tag{18} P(Y|X)=h_\theta(x)^{y_i}(1-h_\theta(x))^{1-y_i}损失函数为 J_\theta(x)=-\sum_{i=1}^N [y_ilogh_\theta(x)+(1-y_i)log(1-h_\theta(x))]\tag{19}所以经过计算有 \frac{\partial J}{\partial h_\theta(x)}=y-\hat y对于多分类问题 损失函数为交叉熵 L(y,p(y|x))=-\sum_{i=1}^M y_ilog {p_i}\tag{20}其中$i$表示所属类别，$M$表示分类树,$p_i$表示属于$i$的概率 并且有 p(y=i|x)=\frac{exp(F_i(x))}{\sum_{i=1}^Mexp(F_i(x))}\tag{21}同样求梯度有 r_{mi}=-\frac{\partial L(y_i,F(x_i))}{\partial F(x_i)}|_{f(x_i)=f_{m-1}(x_i)}回归损失函数 (1)平方损失函数 L(y,x)=\sum_{i=1}^n(y_i-f(x_i))^2(2)绝对值损失函数 L(y,x)=\sum_{i=1}^n|y_i-f(x_i)|(3)huber损失函数 L(y)=\left\{ \begin{array}{rcl} \frac{1}{2}(y-f(x))^2 & & {|y-f(x)|\leq\delta}\\ \delta*|y-f(x)-\frac{1}{2}\delta| & & {|y-f(x)|>\delta} \end{array} \right.GBDT的正则化和Adaboost一样，我们也需要对GBDT进行正则化，防止过拟合。GBDT的正则化主要有三种方式。 （1）第一种是和Adaboost类似的正则化项，即步长（learning rate）。定义为ν,对于前面的弱学习器的迭代 f_k(x)=f_{k-1}(x)+h_k(x) 如果我们加上了正则化项，则有 f_k(x)=f_{k-1}(x)+v\cdot h_k(x) ν的取值范围为0&lt;ν≤10。对于同样的训练集学习效果，较小的ν意味着我们需要更多的弱学习器的迭代次数。通常我们用步长和迭代最大次数一起来决定算法的拟合效果。 （2）第二种正则化的方式是通过子采样比例（subsample）。取值为(0,1]。注意这里的子采样和随机森林不一样，随机森林使用的是放回抽样，而这里是不放回抽样。如果取值为1，则全部样本都使用，等于没有使用子采样。如果取值小于1，则只有一部分样本会去做GBDT的决策树拟合。选择小于1的比例可以减少方差，即防止过拟合，但是会增加样本拟合的偏差，因此取值不能太低。推荐在[0.5, 0.8]之间。 使用了子采样的GBDT有时也称作随机梯度提升树(Stochastic Gradient Boosting Tree, SGBT)。由于使用了子采样，程序可以通过采样分发到不同的任务去做boosting的迭代过程，最后形成新树，从而减少弱学习器难以并行学习的弱点。（注：这一点没明白。。） （3）第三种是对于弱学习器即CART回归树进行正则化剪枝。在决策树章节里我们已经讲过，这里就不重复了。 调参经验分类sklearn.ensemble.`RandomForestClassifier Parameters n_estimators ：树的个数，迭代次数 The number of trees in the forest.Changed in version 0.22: The default value of n_estimators changed from 10 to 100 in 0.22. criterion： 叶子结点分裂的方式，默认的是gini和entropy max_depth：树的深度，默认为空，会一直分裂，直到无法继续分裂 min_samples_split： 分裂一个节点所需要的最小样本 int：表示样本数 float 表示的百分比 min_samples_leaf：保持一颗叶子结点所需要的样本数，该参数能够对模型进行平滑，特别在回归任务中。int和float和min_samples_split一样。 min_weight_fraction_leaf：叶子结点所有权重和的最小值，如果分布相差很大或者有很多缺失值，可以引入该参数 max_features：当考虑最佳分割点是考虑的特征数。 如果是float型，表示的是百分比 如果是’auto’ or ‘log2’，表示sqrt(n_features) 如果是log2, 表示log2(n_features) max_leaf_nodes : 最大叶子结点，用于防止过拟合 min_impurity_split：早停的阈值，如果一个节点的不纯度高于该值，则分裂，否则为叶子结点 Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.Deprecated since version 0.19: min_impurity_split has been deprecated in favor of min_impurity_decrease in 0.19. The default value of min_impurity_split will change from 1e-7 to 0 in 0.23 and it will be removed in 0.25. Use min_impurity_decrease instead. bootstrap： 是否使用bootstrap采样，为否表示使用整个数据集 oob_score：袋外精度来泛化 Whether to use out-of-bag samples to estimate the generalization accuracy. class_weight：类别权重，用于样本分布不均衡时使用 ‘’dict, list of dicts, “balanced”, “balanced_subsample” or None, optional (default=None） 格式为{class_label: weight} ，例如 {0: 1, 1: 1} ’balanced‘模式下会自动调整权值，根据训练数据中类别出现频率， n_samples/(n_class *np.bincount()) ‘balanced_subsample’和balanced一样，区别在于才用的boostrap max_samples：从训练集中取出的每个样本量 None：表示使用所有样本 如果为int 表示为该值 float表示 百分比 class sklearn.ensemble.``GradientBoostingRegressor loss ：损失函数，默认为ls ‘ls’ 平方损失函数，损失函数为$L(y)=(y-f(x))^2$ ‘lad’，绝对值 ,损失函数 $L(y)=|y-f(x)|$ ‘huber’： 两者的结合 L(y)=\left\{ \begin{array}{rcl} \frac{1}{2}(y-f(x))^2 & & {|y-f(x)|\leq\delta}\\ \delta*|y-f(x)-\frac{1}{2}\delta| & & {|y-f(x)|>\delta} \end{array} \right. subsample：子采样比例，子采样会减少方差，增大偏差 criterion： 衡量节点分裂质量的指标 friedman_mse, ‘mse’ ’mae‘ New in version 0.18. min_samples_split: 和分类一样 tol：学习率 参考资料 [1]https://zhuanlan.zhihu.com/p/86281279 [2].统计学习方法]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>决策树</tag>
        <tag>集成学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pandas的基本用法]]></title>
    <url>%2F2019%2F10%2F05%2Fpandas%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Matplotlib的基本用法]]></title>
    <url>%2F2019%2F10%2F04%2FMatplotlib%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Matplotlib的基本用法简单的折线图plt.plot(x,y, fortmat_string)作用是定义画图的样式x,y表示横纵左表， format可以定义画图格式12345678#导入Matploylib库from matplotlib import pyplot as plt %matplotlib inline #画布上画图plt.plot([1,2,3,4], [1,2,3,4], 'b', linewidth=2)plt.plot([1,2,3,4], [1,4,9,16], 'r', linewidth=2)#在画布上显示plt.show() 添加标题标签及图的样式123456789101112from matplotlib import pyplot as plt %matplotlib inline x = [5,2,7]y = [2,16,4]plt.plot(x,y)# 图片的标题plt.title('Image Title')# 坐标轴Y轴plt.ylabel('Y axis')# 坐标轴X轴plt.xlabel('X axis')plt.show() 12345678910111213141516from matplotlib import pyplot as pltfrom matplotlib import style style.use('ggplot')x = [5,8,10]y = [12,16,6]x2 = [6,9,11]y2 = [6,15,7]plt.plot(x,y,'g',label='line one', linewidth=5)plt.plot(x2,y2,'r',label='line two',linewidth=5)plt.title('Epic Info')plt.ylabel('Y axis')plt.xlabel('X axis')#设置图例位置plt.legend()plt.grid(True,color='k')plt.show() 直方图pyplot.bar(left, height, alpha=1, width=0.8, color=, edgecolor=, label=, lw=3) 画一个柱状图 参数 left： x轴的位置序列，一般采用arange函数产生一个序列 height: y轴的数值序列，也就是柱状图的高度，即我们需要展示的数据 alpha： 透明度 width: 柱状图的宽度 color or facecolor: 柱状图的填充颜色 edgecolor: 图形边缘颜色 label: 每个图像代表的意思 linewidth or linewidths or lw：边缘or线的宽度 12345678from matplotlib import pyplot as plt plt.bar([0.25,1.25,2.25,3.25,4.25],[50,40,70,80,20],label="BMW", color='b', width=.5)plt.bar([.75,1.75,2.75,3.75,4.75],[80,20,20,50,60],label="Audi", color='r',width=.5)plt.legend()plt.xlabel('Days')plt.ylabel('Distance (kms)')plt.title('Information')plt.show() 频率图matplotlib.pyplot.hist(x, bins=10, range=None, normed=False, weights=None, cumulative=False, bottom=None, histtype=u’bar’, align=u’mid’, orientation=u’vertical’, rwidth=None, log=False, color=None, label=None, stacked=False) 统计每个区间出现的频率 参数 x：直方图统计的数据 bins: 指定统计的间隔，如bins=10时表示以10为一个区间 color: 柱状图的颜色 histtype: 可选{‘bar’, ‘barstacked’,’step’, ‘stepfilled’}之一 density: 显示频率 stacked: 是否显示堆叠柱状图 12345678import matplotlib.pyplot as pltpopulation_age = [22,55,62,45,21,22,34,42,42,4,2,102,95,85,55,110,120,70,65,55,111,115,80,75,65,54,44,43,42,48]bins = [0,10,20,30,40,50,60,70,80,90,100]plt.hist(population_age, bins=10, histtype='bar', color='b', rwidth=0.8)plt.xlabel('age groups')plt.ylabel('Number of people')plt.title('Histogram')plt.show() 散点图12345678910111213import matplotlib.pyplot as pltx = [1,1.5,2,2.5,3,3.5,3.6]y = [7.5,8,8.5,9,9.5,10,10.5] x1=[8,8.5,9,9.5,10,10.5,11]y1=[3,3.5,3.7,4,4.5,5,5.2] # scatter表示画散点图plt.scatter(x,y, label='high income low saving',color='r')plt.scatter(x1,y1,label='low income high savings',color='b')plt.xlabel('saving*100')plt.ylabel('income*1000')plt.title('Scatter Plot')plt.legend()plt.show() 堆叠图matplotlib.pyplot.stackplot(x, args, labels=(), colors=None, baseline=’zero’, data=None, *kwargs) 画堆叠图，主要有三个参数 x:需要画堆叠图的数值 laebl: 堆叠图中折现的标签 colors: 设置折线图的颜色 1234567891011sleeping =[7,8,6,11,7]eating = [2,3,4,3,2]working =[7,8,7,2,2]playing = [8,5,7,8,13] labels = ['Sleeping', 'Eating', 'Working', 'Playing']plt.stackplot(days, sleeping,eating,working,playing,labels=labels,colors=['m','c','r','k']) plt.xlabel('x')plt.ylabel('y')plt.title('Stack Plot')plt.legend()plt.show() 饼状图123456slices = [7,3,2,13]activities = ['sleeping','eating','working','playing']cols = ['c','m','r','b'] plt.pie(slices, labels=activities, colors=cols, startangle=90, shadow= True, explode=(0,0.1,0,0), autopct='%1.1f%%') plt.title('Pie Plot')plt.show() 多个子图合并plt.subplot(numRows, numCols, plotNum) 将一块画布分为多个区域，将不同图分别放入不同的子图 参数 numRows：指的行数 numCols：指的列数 plotNum：子图的位置 如上面所示的221，表示的是将图分为2 * 2个子图，然后使用第一个位置 子图的位置依次为 123(1,1) (1,2)(2,1) (2,2) 依次对应的位置为1,2,3,4 1234567891011import numpy as npimport matplotlib.pyplot as plt def f(t): return np.exp(-t) * np.cos(2*np.pi*t)t1 = np.arange(0.0, 5.0, 0.1)t2 = np.arange(0.0, 5.0, 0.02)plt.subplot(221)plt.plot(t1, f(t1), 'bo', t2, f(t2))plt.subplot(222)plt.plot(t2, np.cos(2*np.pi*t2))plt.show() pandas与matplotlib结合123import pandas as pdimport numpy as npimport matplotlib.pyplot as plt np.random.rand(nums) 随即产生nums个位于[0,1]的样本 np.random.randn(nums) 随即返回nums个标准正态分布的样本 1plt.plot(np.random.rand(10)) 1[&lt;matplotlib.lines.Line2D at 0x24f3122c2b0&gt;] 设置坐标轴刻度 图名 x轴标签 y轴标签 图例 x轴边界 y轴边界 x轴刻度 y轴刻度 x轴刻度标签 y轴刻度标签 123456789101112131415161718192021df = pd.DataFrame(np.random.rand(10,2),columns=['A','B'])fig = df.plot(figsize=(8,4)) # figsize：创建图表窗口，设置窗口大小plt.title('TITLETITLETITLE') # 图名plt.xlabel('XXXXXX') # x轴标签plt.ylabel('YYYYYY') # y轴标签plt.legend(loc = 'upper right') # 显示图例，loc表示位置plt.xlim([0,12]) # x轴边界plt.ylim([0,1.5]) # y轴边界plt.xticks(range(10)) # 设置x刻度plt.yticks([0,0.2,0.4,0.6,0.8,1.0,1.2]) # 设置y刻度fig.set_xticklabels("%.1f" %i for i in range(10)) # x轴刻度标签fig.set_yticklabels("%.2f" %i for i in [0,0.2,0.4,0.6,0.8,1.0,1.2]) # y轴刻度标签# 这里x轴范围是0-12，但刻度只是0-9，刻度标签使得其显示1位小数 1234567[Text(0, 0, &apos;0.00&apos;), Text(0, 0, &apos;0.20&apos;), Text(0, 0, &apos;0.40&apos;), Text(0, 0, &apos;0.60&apos;), Text(0, 0, &apos;0.80&apos;), Text(0, 0, &apos;1.00&apos;), Text(0, 0, &apos;1.20&apos;)] 修改图标样式pd.Series()作用是产生一个有编号的序列 np.random.randn()产生正太分布的样本，当只有一个参数是，返回n个标准正太分布的结果，当有两个或多个参数时，参数表示对应的维度 np.random.rand() 用法和上面一个函数一样，但是返回的是 np.cumsum()表示将前一行或者前一列加到后面 参数 ​ a：表示传入函数的数据 axi：{0,1}，axi=0时表示行相加，axi=1时表示列相加 12s = pd.Series(np.random.randn(100).cumsum())s.plot(linestyle = '--', marker = '.',color="r",grid=False) dataframe直接画图DataFrame.plot(x=None, y=None, kind=’line’, ax=None, subplots=False, sharex=None, sharey=False, layout=None,figsize=None, use_index=True, title=None, grid=None, legend=True, style=None, logx=False, logy=False, loglog=False, xticks=None, yticks=None, xlim=None, ylim=None, rot=None, xerr=None,secondary_y=False, sort_columns=False, **kwds) Parameters:x : label or position, default None#指数据框列的标签或位置参数 y : label or position, default None kind : str‘line’ : line plot (default)#折线图‘bar’ : vertical bar plot#条形图‘barh’ : horizontal bar plot#横向条形图‘hist’ : histogram#柱状图‘box’ : boxplot#箱线图‘kde’ : Kernel Density Estimation plot#Kernel 的密度估计图，主要对柱状图添加Kernel 概率密度线‘density’ : same as ‘kde’‘area’ : area plot#不了解此图‘pie’ : pie plot#饼图‘scatter’ : scatter plot#散点图 需要传入columns方向的索引‘hexbin’ : hexbin plot#不了解此图 ax : matplotlib axes object, default None#子图(axes, 也可以理解成坐标轴) 要在其上进行绘制的matplotlib subplot对象。如果没有设置，则使用当前matplotlib subplot其中，变量和函数通过改变figure和axes中的元素（例如：title,label,点和线等等）一起描述figure和axes，也就是在画布上绘图。 subplots : boolean, default False#判断图片中是否有子图 Make separate subplots for each column sharex : boolean, default True if ax is None else False#如果有子图，子图共x轴刻度，标签 In case subplots=True, share x axis and set some x axis labels to invisible; defaults to True if ax is None otherwise False if an ax is passed in; Be aware, that passing in both an ax and sharex=True will alter all x axis labels for all axis in a figure! sharey : boolean, default False#如果有子图，子图共y轴刻度，标签 In case subplots=True, share y axis and set some y axis labels to invisible layout : tuple (optional)#子图的行列布局 (rows, columns) for the layout of subplots figsize : a tuple (width, height) in inches#图片尺寸大小 use_index : boolean, default True#默认用索引做x轴 Use index as ticks for x axis title : string#图片的标题用字符串 Title to use for the plot grid : boolean, default None (matlab style default)#图片是否有网格 Axis grid lines legend : False/True/’reverse’#子图的图例，添加一个subplot图例(默认为True) Place legend on axis subplots style : list or dict#对每列折线图设置线的类型 matplotlib line style per column logx : boolean, default False#设置x轴刻度是否取对数 Use log scaling on x axis logy : boolean, default False Use log scaling on y axis loglog : boolean, default False#同时设置x，y轴刻度是否取对数 Use log scaling on both x and y axes xticks : sequence#设置x轴刻度值，序列形式（比如列表） Values to use for the xticks yticks : sequence#设置y轴刻度，序列形式（比如列表） Values to use for the yticks xlim : 2-tuple/list#设置坐标轴的范围，列表或元组形式 ylim : 2-tuple/list rot : int, default None#设置轴标签（轴刻度）的显示旋转度数 Rotation for ticks (xticks for vertical, yticks for horizontal plots) fontsize : int, default None#设置轴刻度的字体大小 Font size for xticks and yticks colormap : str or matplotlib colormap object, default None#设置图的区域颜色 Colormap to select colors from. If string, load colormap with that name from matplotlib. colorbar : boolean, optional #图片柱子 If True, plot colorbar (only relevant for ‘scatter’ and ‘hexbin’ plots) position : float Specify relative alignments for bar plot layout. From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5 (center) layout : tuple (optional) #布局 (rows, columns) for the layout of the plot table : boolean, Series or DataFrame, default False #如果为正，则选择DataFrame类型的数据并且转换匹配matplotlib的布局。 If True, draw a table using the data in the DataFrame and the data will be transposed to meet matplotlib’s default layout. If a Series or DataFrame is passed, use passed data to draw a table. yerr : DataFrame, Series, array-like, dict and str See Plotting with Error Bars for detail. xerr : same types as yerr. stacked : boolean, default False in line and bar plots, and True in area plot. If True, create stacked plot. sort_columns : boolean, default False # 以字母表顺序绘制各列，默认使用前列顺序 secondary_y : boolean or sequence, default False ##设置第二个y轴（右y轴） Whether to plot on the secondary y-axis If a list/tuple, which columns to plot on secondary y-axis mark_right : boolean, default True When using a secondary_y axis, automatically mark the column labels with “(right)” in the legend kwds : keywords Options to pass to matplotlib plotting method Returns:axes : matplotlib.AxesSubplot or np.array of them 12345# 直接用风格样式设置# 透明度与颜色版# s.plot(style="--.",alpha = 0.8,colormap = 'Reds_r')df = pd.DataFrame(np.random.randn(100, 4),columns=list('ABCD')).cumsum()df.plot(style = '--.',alpha = 0.8,colormap = 'summer_r') 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x24f379a4cc0&gt; 123df = pd.DataFrame(np.random.randn(10,2))df.plot(style = '--o')plt.text(5,0.5,'Hello',fontsize=12) 1Text(5, 0.5, &apos;Hello&apos;) 子图绘制figure对象plt.figure(num=None, figsize=None, dpi=None, facecolor=None, edgecolor=None, frameon=True, FigureClass=, **kwargs) 作用创建一块画布 num相当于id，如果没有id则递增创建，如果已存在则返回该存在的对象 1234fig1 = plt.figure(num=1,figsize=(8,6))plt.plot(np.random.rand(50).cumsum(),'k--')fig2 = plt.figure(num=2,figsize=(8,6))plt.plot(50-np.random.rand(50).cumsum(),'k--') 1[&lt;matplotlib.lines.Line2D at 0x24f3780f6d8&gt;] 先创建子图然后填充12345678910111213141516171819202122# 先建立子图然后填充图表fig = plt.figure(figsize=(10,6),facecolor = 'gray')# 第一个子图曲线图ax1 = fig.add_subplot(2,2,1)plt.plot(np.random.rand(50).cumsum(),'k--')plt.plot(np.random.randn(50).cumsum(),'b--')# 第二个字图，直方图ax2 = fig.add_subplot(2,2,2)ax2.hist(np.random.rand(50),alpha=0.4)# 第三个饼状图slices = [7,3,2,13]activities = ['sleeping','eating','working','playing']cols = ['c','m','r','b']ax3 = fig.add_subplot(223)ax3.pie(slices, labels=activities, colors=cols, startangle=90, shadow= True, explode=(0,0.1,0,0), autopct='%1.1f%%')# 第四个折线图ax4 = fig.add_subplot(2,2,4) df2 = pd.DataFrame(np.random.rand(10, 4), columns=['a', 'b', 'c', 'd'])ax4.plot(df2,alpha=0.5,linestyle='--',marker='.') 1234[&lt;matplotlib.lines.Line2D at 0x24f38c19940&gt;, &lt;matplotlib.lines.Line2D at 0x24f3905ed68&gt;, &lt;matplotlib.lines.Line2D at 0x24f3905ef28&gt;, &lt;matplotlib.lines.Line2D at 0x24f3906b0f0&gt;] 使用subplots子图数组填充子图12345678910# 创建一个新的figure，并返回一个subplot对象的numpy数组 → plt.subplotfig,axes = plt.subplots(2,3,figsize=(10,4))ts = pd.Series(np.random.randn(1000).cumsum())print(axes, axes.shape, type(axes))# 生成图表对象的数组# 通过数组访问对应的子图ax1 = axes[0,1]ax1.plot(ts) 123456[[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F38EFABA8&gt; &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F38F13BA8&gt; &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F38CA4C88&gt;] [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F38CC8DA0&gt; &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F38CECEB8&gt; &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F38D17320&gt;]] (2, 3) &lt;class &apos;numpy.ndarray&apos;&gt; 1[&lt;matplotlib.lines.Line2D at 0x24f38d39978&gt;] 12345678910# plt.subplots 参数调整fig,axes = plt.subplots(2,2,sharex=True,sharey=True)# sharex,sharey：是否共享x，y刻度for i in range(2): for j in range(2): axes[i,j].hist(np.random.randn(500),color='k',alpha=0.5) # wspace,hspace：用于控制宽度和高度的百分比，比如subplot之间的间距plt.subplots_adjust(wspace=0,hspace=0) 多系列子图绘制plt.plot(): subplots, 是否分别绘制子图,为true的时候表示分开绘制，为false表示在一个图立面绘制 layout：挥之子图矩阵，按顺序填充 subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=None) 有六个可选参数来控制子图布局。值均为0~1之间。其中left、bottom、right、top围成的区域就是子图的区域。wspace、hspace分别表示子图之间左右、上下的间距。实际的默认值由matplotlibrc文件控制的。 1234567df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=list('ABCD'))df = df.cumsum()df.plot(style = '--.',alpha = 0.4,grid = True,figsize = (20,8), subplots = True, layout = (2,2), sharex = False)plt.subplots_adjust(wspace=0.1,hspace=0.2) 基本图表绘制Series 与 DataFrame 绘图plt.plot(kind=’line’, ax=None, figsize=None, use_index=True, title=None, grid=None, legend=False,style=None, logx=False, logy=False, loglog=False, xticks=None, yticks=None, xlim=None, ylim=None,rot=None, fontsize=None, colormap=None, table=False, yerr=None, xerr=None, label=None, secondary_y=False, **kwds) 参数含义： series的index为横坐标 value为纵坐标 kind → line,bar,barh…（折线图，柱状图，柱状图-横…） label → 图例标签，Dataframe格式以列名为label style → 风格字符串，这里包括了linestyle（-），marker（.），color（g） color → 颜色，有color指定时候，以color颜色为准 alpha → 透明度，0-1 use_index → 将索引用为刻度标签，默认为True rot → 旋转刻度标签，0-360 grid → 显示网格，一般直接用plt.grid xlim,ylim → x,y轴界限 xticks,yticks → x,y轴刻度值 figsize → 图像大小 title → 图名 legend → 是否显示图例，一般直接用plt.legend() 12345678910111213141516171819ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000)) # pandas 时间序列ts = ts.cumsum()ts.plot(kind='line', label = "what", style = '--.', color = 'g', alpha = 0.4, use_index = True, rot = 45, grid = True, ylim = [-50,50], yticks = list(range(-50,50,10)), figsize = (8,4), title = 'TEST_TEST', legend = True)# 对网格项进行更加细致的设置#plt.grid(True, linestyle = "--",color = "gray", linewidth = "0.5",axis = 'x') # 网格plt.legend()plt.show() 12345678910111213# subplots → 是否将各个列绘制到不同图表，默认Falsedf = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=list('ABCD')).cumsum()df.plot(kind='line', style = '--.', alpha = 0.4, use_index = True, rot = 45, grid = True, figsize = (8,4), title = 'test', legend = True, subplots = False, colormap = 'Greens') 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x24f32b0f630&gt; 柱状图 plt.bar() x,y参数：x，y值 width：宽度比例 facecolor柱状图里填充的颜色、edgecolor是边框的颜色 left-每个柱x轴左边界,bottom-每个柱y轴下边界 → bottom扩展即可化为甘特图 Gantt Chart align：决定整个bar图分布，默认left表示默认从左边界开始绘制,center会将图绘制在中间位置xerr/yerr ：x/y方向error bar 1234567891011121314151617181920# 创建一个新的figure，并返回一个subplot对象的numpy数组fig,axes = plt.subplots(4,1,figsize = (10,10))s = pd.Series(np.random.randint(0,10,16),index = list('abcdefghijklmnop')) df = pd.DataFrame(np.random.rand(10,3), columns=['a','b','c'])# 单系列柱状图方法一：plt.plot(kind='bar/barh')s.plot(kind='bar',color = 'k',grid = True,alpha = 0.5,ax = axes[0]) # ax参数 → 选择第几个子图# 多系列柱状图df = pd.DataFrame(np.random.rand(10,3), columns=['a','b','c'])df.plot(kind='bar',ax = axes[1],grid = True,colormap='Reds_r')# 多系列堆叠图# stacked → 堆叠df.plot(kind='bar',ax = axes[2],grid = True,colormap='Blues_r',stacked=True) # The bars are positioned at y with the given align. Their dimensions are given by width and height. The horizontal baseline is left (default 0). # https://matplotlib.org/api/_as_gen/matplotlib.pyplot.barh.html?highlight=barh#matplotlib.pyplot.barhdf.plot.barh(ax = axes[3],grid = True,stacked=True,colormap = 'BuGn_r') 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x24f32cf0550&gt; 123456789101112131415plt.figure(figsize=(10,4))x = np.arange(10)y1 = np.random.rand(10)y2 = -np.random.rand(10)plt.bar(x,y1,width = 1,facecolor = 'yellowgreen',edgecolor = 'white',yerr = y1*0.1)plt.bar(x,y2,width = 1,facecolor = 'lightskyblue',edgecolor = 'white',yerr = y2*0.1)for i,j in zip(x,y1): plt.text(i-0.2,j-0.15,'%.2f' % j, color = 'white')for i,j in zip(x,y2): plt.text(i-0.2,j+0.05,'%.2f' % -j, color = 'white')# 给图添加text# zip() 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。 面积图 stacked：是否堆叠，默认情况下，区域图被堆叠 为了产生堆积面积图，每列必须是正值或全部负值！ 当数据有NaN时候，自动填充0，图标签需要清洗掉缺失值 1234567fig,axes = plt.subplots(2,1,figsize = (8,6))df1 = pd.DataFrame(np.random.rand(10, 4), columns=['a', 'b', 'c', 'd'])df2 = pd.DataFrame(np.random.randn(10, 4), columns=['a', 'b', 'c', 'd'])df1.plot.area(colormap = 'Greens_r',alpha = 0.5,ax = axes[0])df2.plot.area(stacked=False,colormap = 'Set2',alpha = 0.5,ax = axes[1]) 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x24f3288f668&gt; 填图123456789101112131415161718192021fig,axes = plt.subplots(2,1,figsize = (8,6))x = np.linspace(0, 1, 500)y1 = np.sin(4 * np.pi * x) * np.exp(-5 * x)y2 = -np.sin(4 * np.pi * x) * np.exp(-5 * x)axes[0].fill(x, y1, 'r',alpha=0.5,label='y1')axes[0].fill(x, y2, 'g',alpha=0.5,label='y2')# 对函数与坐标轴之间的区域进行填充，使用fill函数# 也可写成：plt.fill(x, y1, 'r',x, y2, 'g',alpha=0.5)x = np.linspace(0, 5 * np.pi, 1000) y1 = np.sin(x) y2 = np.sin(2 * x) axes[1].fill_between(x, y1, y2, color ='b',alpha=0.5,label='area') # 填充两个函数之间的区域，使用fill_between函数for i in range(2): axes[i].legend() axes[i].grid()# 添加图例、格网 饼图plt.pie(x, explode=None, labels=None, colors=None, autopct=None, pctdistance=0.6, shadow=False, labeldistance=1.1, startangle=None, radius=None, counterclock=True, wedgeprops=None, textprops=None, center=(0, 0), frame=False, hold=None, data=None) 参数含义： 第一个参数：数据 explode：指定每部分的偏移量 labels：标签 colors：颜色 autopct：饼图上的数据标签显示方式 pctdistance：每个饼切片的中心和通过autopct生成的文本开始之间的比例 labeldistance：被画饼标记的直径,默认值：1.1 shadow：阴影 startangle：开始角度 radius：半径 frame：图框 counterclock：指定指针方向，顺时针或者逆时针 1234567891011121314s = pd.Series(3 * np.random.rand(4), index=['a', 'b', 'c', 'd'], name='series')plt.axis('equal') # 保证长宽相等plt.pie(s, explode = [0.1,0,0,0], labels = s.index, colors=['r', 'g', 'b', 'c'], autopct='%.2f%%', pctdistance=0.6, labeldistance = 1.2, shadow = True, startangle=0, radius=1.5, frame=False)plt.show() 直方图plt.hist(x, bins=10, range=None, normed=False, weights=None, cumulative=False, bottom=None,histtype=’bar’, align=’mid’, orientation=’vertical’,rwidth=None, log=False, color=None, label=None,stacked=False, hold=None, data=None, **kwargs) 参数 bin：箱子的宽度 normed 标准化 histtype 风格，bar，barstacked，step，stepfilled orientation 水平还是垂直{‘horizontal’, ‘vertical’} align : {‘left’, ‘mid’, ‘right’}, optional(对齐方式) stacked：是否堆叠 1234567891011# 直方图s = pd.Series(np.random.randn(1000))s.hist(bins = 20, histtype = 'bar', align = 'mid', orientation = 'vertical', alpha=0.5, normed =True)# 密度图s.plot(kind='kde',style='k--')plt.show() 123D:\Program Files (x86)\Anaconda3\lib\site-packages\pandas\plotting\_core.py:2477: MatplotlibDeprecationWarning: The &apos;normed&apos; kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use &apos;density&apos; instead. ax.hist(values, bins=bins, **kwds) 123456789101112131415# 堆叠直方图plt.figure(num=1)df = pd.DataFrame(&#123;'a': np.random.randn(1000) + 1, 'b': np.random.randn(1000), 'c': np.random.randn(1000) - 1, 'd': np.random.randn(1000)-2&#125;, columns=['a', 'b', 'c','d'])df.plot.hist(stacked=True, bins=20, colormap='Greens_r', alpha=0.5, grid=True)# 使用DataFrame.plot.hist()和Series.plot.hist()方法绘制df.hist(bins=50)# 生成多个直方图 12345array([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F34C1B710&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F34C4D2E8&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F34C80898&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F34CB2E48&gt;]], dtype=object) 1&lt;Figure size 432x288 with 0 Axes&gt; 散点图plt.scatter(x, y, s=20, c=None, marker=’o’, cmap=None, norm=None, vmin=None, vmax=None, alpha=None, linewidths=None,verts=None, edgecolors=None, hold=None, data=None, **kwargs) 参数含义： s：散点的大小 c：散点的颜色 vmin,vmax：亮度设置，标量 cmap：colormap 1234567891011plt.figure(figsize=(8,6))x = np.random.randn(1000)y = np.random.randn(1000)plt.scatter(x,y,marker='.', s = np.random.randn(1000)*100, cmap = 'Reds_r', c = y, alpha = 0.8,)plt.grid() 12D:\Program Files (x86)\Anaconda3\lib\site-packages\matplotlib\collections.py:857: RuntimeWarning: invalid value encountered in sqrt scale = np.sqrt(self._sizes) * dpi / 72.0 * self._factor 123456789101112# pd.scatter_matrix()散点矩阵# pd.scatter_matrix(frame, alpha=0.5, figsize=None, ax=None, # grid=False, diagonal='hist', marker='.', density_kwds=None, hist_kwds=None, range_padding=0.05, **kwds)# diagonal：(&#123;‘hist’, ‘kde’&#125;)，必须且只能在&#123;‘hist’, ‘kde’&#125;中选择1个 → 每个指标的频率图# range_padding：(float, 可选)，图像在x轴、y轴原点附近的留白(padding)，该值越大，留白距离越大，图像远离坐标原点df = pd.DataFrame(np.random.randn(100,4),columns = ['a','b','c','d'])pd.plotting.scatter_matrix(df,figsize=(10,6), marker = 'o', diagonal='kde', alpha = 0.5, range_padding=0.5) 1234567891011121314151617array([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F39EB5828&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F222278&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F37E518&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F391F98&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F3AF128&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F3C5278&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F3DC3C8&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F3F3550&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F3F3588&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F41FC18&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F43C208&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F4507B8&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F466D68&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F483358&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F498908&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F4AFEB8&gt;]], dtype=object) 箱型图箱型图：又称为盒须图、盒式图、盒状图或箱线图，是一种用作显示一组数据分散情况资料的统计图 包含一组数据的：最大值、最小值、中位数、上四分位数（Q1）、下四分位数（Q3）、异常值 ① 中位数 → 一组数据平均分成两份，中间的数 ② 下四分位数Q1 → 是将序列平均分成四份，计算(n+1)/4与(n-1)/4两种，一般使用(n+1)/4 ③ 上四分位数Q3 → 是将序列平均分成四份，计算(1+n)/4*3=6.75 ④ 内限 → T形的盒须就是内限，最大值区间Q3+1.5IQR,最小值区间Q1-1.5IQR （IQR=Q3-Q1） ⑤ 外限 → T形的盒须就是内限，最大值区间Q3+3IQR,最小值区间Q1-3IQR （IQR=Q3-Q1） ⑥ 异常值 → 内限之外 - 中度异常，外限之外 - 极度异常 plt.plot.box(),plt.boxplot() 123456789101112131415# plt.plot.box()绘制fig,axes = plt.subplots(2,1,figsize=(10,6))df = pd.DataFrame(np.random.rand(10, 5), columns=['A', 'B', 'C', 'D', 'E'])color = dict(boxes='DarkGreen', whiskers='DarkOrange', medians='DarkBlue', caps='Gray')# 箱型图着色# boxes → 箱线# whiskers → 分位数与error bar横线之间竖线的颜色# medians → 中位数线颜色# caps → error bar横线颜色df.plot.box(ylim=[0,1.2], grid = True, color = color, ax = axes[0]) 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x24f394cc9b0&gt; 1234567891011121314151617181920212223242526272829303132333435df = pd.DataFrame(np.random.rand(10, 5), columns=['A', 'B', 'C', 'D', 'E'])plt.figure(figsize=(10,4))# 创建图表、数据f = df.boxplot(sym = 'o', # 异常点形状，参考marker vert = True, # 是否垂直 whis = 1.5, # IQR，默认1.5，也可以设置区间比如[5,95]，代表强制上下边缘为数据95%和5%位置 patch_artist = True, # 上下四分位框内是否填充，True为填充 meanline = False,showmeans=True, # 是否有均值线及其形状 showbox = True, # 是否显示箱线 showcaps = True, # 是否显示边缘线 showfliers = True, # 是否显示异常值 notch = False, # 中间箱体是否缺口 return_type='dict' # 返回类型为字典 ) plt.title('boxplot')for box in f['boxes']: box.set( color='b', linewidth=1) # 箱体边框颜色 box.set( facecolor = 'b' ,alpha=0.5) # 箱体内部填充颜色for whisker in f['whiskers']: whisker.set(color='k', linewidth=0.5,linestyle='-')for cap in f['caps']: cap.set(color='gray', linewidth=2)for median in f['medians']: median.set(color='DarkBlue', linewidth=2)for flier in f['fliers']: flier.set(marker='o', color='y', alpha=0.5)# boxes, 箱线# medians, 中位值的横线,# whiskers, 从box到error bar之间的竖线.# fliers, 异常值# caps, error bar横线# means, 均值的横线, 1234567891011# plt.boxplot()绘制# 分组汇总df = pd.DataFrame(np.random.rand(10,2), columns=['Col1', 'Col2'] )df['X'] = pd.Series(['A','A','A','A','A','B','B','B','B','B'])df['Y'] = pd.Series(['A','B','A','B','A','B','A','B','A','B'])df.boxplot(by = 'X')df.boxplot(column=['Col1','Col2'], by=['X','Y'])# columns：按照数据的列分子图# by：按照列分组做箱型图 123array([&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3519AD68&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F34B67C88&gt;], dtype=object)]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>matplotlib</tag>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Matplotlib的Seaborn风格可视化]]></title>
    <url>%2F2019%2F10%2F04%2FMatplotlib%E7%9A%84Seaborn%E9%A3%8E%E6%A0%BC%E5%8F%AF%E8%A7%86%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Seaborn风格可视化什么事seaborn​ Seaborn是基于matplotlib的图形可视化python包。它提供了一种高度交互式界面，便于用户能够做出各种有吸引力的统计图表。Seaborn是在matplotlib的基础上进行了更高级的API封装，从而使得作图更加容易，在大多数情况下使用seaborn能做出很具有吸引力的图，而使用matplotlib就能制作具有更多特色的图。应该把Seaborn视为matplotlib的补充，而不是替代物。同时它能高度兼容numpy与pandas数据结构以及scipy与statsmodels等统计模式。 seaborn APISeaborn 要求原始数据的输入类型为 pandas 的 Dataframe 或 Numpy 数组，画图函数有以下几种形式: sns.图名(x=’X轴 列名’, y=’Y轴 列名’, data=原始数据df对象) sns.图名(x=’X轴 列名’, y=’Y轴 列名’, hue=’分组绘图参数’, data=原始数据df对象) sns.图名(x=np.array, y=np.array[, …]) 123456import numpy as npimport pandas as pdimport scipy as statsimport matplotlib.pyplot as pltimport seaborn as sns%matplotlib inline 基本绘图设置1234567# 创建正弦函数def sinplot(flip=1): x = np.linspace(0, 14, 100) for i in range(1,7): plt.plot(x, np.sin(x+i*.5)*(7-i)*flip)sinplot() 简单切换成Seaborn风格1234# 切换Seaborn风格sns.set()fig = plt.figure(figsize=(8,6))sinplot() 1234567891011# 切换seaborn图标风格fig = plt.figure(figsize=(10,6), facecolor='white')ax1 = fig.add_subplot(211)sns.set_style('whitegrid')data = np.random.normal(size=(20,6))+np.arange(6)/2sns.boxplot(data=data)plt.title('style-whitegrid')ax2 = fig.add_subplot(212)sns.set_style('dark')sinplot() 设置图标坐标轴1234567891011121314151617181920212223242526#despine()# seaborn.despine(fig=None, ax=None, top=True, right=True, left=False, bottom=False, offset=None, trim=False)# 设置风格sns.set_style("ticks")# 创建图表fig = plt.figure(figsize=(6,9))plt.subplots_adjust(hspace=0.3)ax1 = fig.add_subplot(3,1,1) sinplot()# 删除了上、右坐标轴sns.despine()ax2 = fig.add_subplot(3,1,2)sns.violinplot(data=data)# offset：与坐标轴之间的偏移# trim：为True时，将坐标轴限制在数据最大最小值#sns.despine(offset=10, trim=True)ax3 = fig.add_subplot(3,1,3)# top, right, left, bottom：布尔型，为True时不显示#sns.despine(left=True, right = False)sns.boxplot(data=data, palette="deep") 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b20e4f7a58&gt; 设置局部图标风格123456789with sns.axes_style("darkgrid"): plt.subplot(211) sinplot()# 设置局部图表风格，用with做代码块区分sns.set_style("whitegrid")plt.subplot(212)sinplot()# 外部表格风格 设置显示比例123456789#set_context()# 选择包括：'paper', 'notebook', 'talk', 'poster'## 与上面的cell比较你就会发现不同 sns.set_style("whitegrid")sns.set_context("poster")plt.subplot(212)sinplot() 调色板123456789# color_palette()# 默认6种颜色：deep, muted, pastel, bright, dark, colorblind# seaborn.color_palette(palette=None, n_colors=None, desat=None)current_palette = sns.color_palette()print(type(current_palette))# sns.palplot(current_palette[2:4])sns.palplot(current_palette) 1&lt;class &apos;seaborn.palettes._ColorPalette&apos;&gt; 颜色风格1234567891011121314# 颜色风格内容：Accent, Accent_r, Blues, Blues_r, BrBG, BrBG_r, BuGn, BuGn_r, BuPu, # BuPu_r, CMRmap, CMRmap_r, Dark2, Dark2_r, GnBu, GnBu_r, Greens, Greens_r, Greys, Greys_r, OrRd, OrRd_r, Oranges, Oranges_r, PRGn, PRGn_r, # Paired, Paired_r, Pastel1, Pastel1_r, Pastel2, Pastel2_r, PiYG, PiYG_r, PuBu, PuBuGn, PuBuGn_r, PuBu_r, PuOr, PuOr_r, PuRd, PuRd_r, Purples,# Purples_r, RdBu, RdBu_r, RdGy, RdGy_r, RdPu, RdPu_r, RdYlBu, RdYlBu_r, RdYlGn, RdYlGn_r, Reds, Reds_r, Set1, Set1_r, Set2, Set2_r, Set3, # Set3_r, Spectral, Spectral_r, Wistia, Wistia_r, YlGn, YlGnBu, YlGnBu_r, YlGn_r, YlOrBr, YlOrBr_r, YlOrRd, YlOrRd_r, afmhot, afmhot_r, # autumn, autumn_r, binary, binary_r, bone, bone_r, brg, brg_r, bwr, bwr_r, cool, cool_r, coolwarm, coolwarm_r, copper, copper_r, cubehelix, # cubehelix_r, flag, flag_r, gist_earth, gist_earth_r, gist_gray, gist_gray_r, gist_heat, gist_heat_r, gist_ncar, gist_ncar_r, gist_rainbow, # gist_rainbow_r, gist_stern, gist_stern_r, gist_yarg, gist_yarg_r, gnuplot, gnuplot2, gnuplot2_r, gnuplot_r, gray, gray_r, hot, hot_r, hsv, # hsv_r, icefire, icefire_r, inferno, inferno_r, jet, jet_r, magma, magma_r, mako, mako_r, nipy_spectral, nipy_spectral_r, ocean, ocean_r, # pink, pink_r, plasma, plasma_r, prism, prism_r, rainbow, rainbow_r, rocket, rocket_r, seismic, seismic_r, spectral, spectral_r, spring, # spring_r, summer, summer_r, terrain, terrain_r, viridis, viridis_r, vlag, vlag_r, winter, winter_rsns.palplot(sns.color_palette('Accent',12))sns.palplot(sns.color_palette('Accent_r',8)) 设置饱和度和亮度1234sns.palplot(sns.hls_palette(4,l=.3,s=.8))# l-&gt;亮度# s-&gt;饱和度 设置颜色线性变化1234567891011#设置颜色线性变化sns.palplot(sns.cubehelix_palette(16, gamma=2))sns.palplot(sns.cubehelix_palette(16, start=.5, rot=.75))sns.palplot(sns.cubehelix_palette(16,start=0.5, rot=0, dark=0.95, reverse=True))# n_colors → 颜色个数# start → 值区间在0-3，开始颜色# rot → 颜色旋转角度# gamma → 颜色伽马值，越大颜色越暗# dark，light → 值区间0-1，颜色深浅# reverse → 布尔值，默认为False，由浅到深 创建分散颜色123456plt.figure(figsize = (8,6))x = np.arange(25).reshape(5, 5)# 创建分散颜色cmap = sns.diverging_palette(200, 20, sep=20, as_cmap=True)sns.heatmap(x, cmap=cmap) 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21a370cf8&gt; 123456789sns.set_style('whitegrid')fig=plt.figure(figsize=(12,8))with sns.color_palette('PuBuGn_d'): plt.subplot(211) sinplot() sns.set_palette('husl')plt.subplot(212)sinplot() 123456sns.set_style('darkgrid')sns.set_context('paper')import warningswarnings.filterwarnings('ignore')#不再发出警告 分布数据可视化直方图12345678910111213141516#直方图#设计随即种子rs = np.random.RandomState(10)s = pd.Series(rs.randn(100)*100)sns.distplot(s, bins=10, hist=True, kde=False, norm_hist=False, rug=True,vertical=False,color='y', label='distplot', axlabel='x')plt.legend()# bins → 箱数# hist、ked → 是否显示箱/密度曲线# norm_hist → 直方图是否按照密度来显示# rug → 是否显示数据分布情况# vertical → 是否水平显示# color → 设置颜色# label → 图例# axlabel → x轴标注 1&lt;matplotlib.legend.Legend at 0x1b20e65e4e0&gt; 123456sns.distplot(s, rug=True, rug_kws=&#123;'color':'g'&#125;, kde_kws=&#123;"color": "k", "lw": 1, "label": "KDE",'linestyle':'--'&#125;, # 设置密度曲线颜色，线宽，标注、线形 hist_kws=&#123;"histtype": "step", "linewidth": 1,"alpha": 1, "color": "g"&#125;) # 设置箱子的风格、线宽、透明度、颜色 # 风格包括：'bar', 'barstacked', 'step', 'stepfilled' 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21bc8e828&gt; 密度图123456789101112131415161718# 密度图 - kdeplot()# 单个样本数据密度分布图sns.kdeplot(s, shade = False, # 是否填充 color = 'b', # 设置颜色 vertical = False # 设置是否水平 )sns.kdeplot(s,bw=5, label="bw: 0.2", linestyle = '-',linewidth = 1.2,alpha = 0.5)sns.kdeplot(s,bw=20, label="bw: 2", linestyle = '-',linewidth = 1.2,alpha = 0.5)# bw → 控制拟合的程度，类似直方图的箱数sns.rugplot(s,height = 0.1,color = 'k',alpha = 0.5)# 数据频率分布图 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21babf470&gt; 123456789101112131415161718# 密度图 - kdeplot()# 两个样本数据密度分布图rs = np.random.RandomState(2) # 设定随机数种子df = pd.DataFrame(rs.randn(100,2), columns = ['A','B'])sns.kdeplot(df['A'],df['B'], cbar = True, # 是否显示颜色图例 shade = True, # 是否填充 cmap = 'Reds', # 设置调色盘 shade_lowest=False, # 最外围颜色是否显示 n_levels = 10 # 曲线个数（如果非常多，则会越平滑） )# 两个维度数据生成曲线密度图，以颜色作为密度衰减显示sns.rugplot(df['A'], color="g", axis='x',alpha = 0.5)sns.rugplot(df['B'], color="r", axis='y',alpha = 0.5)# 注意设置x，y轴 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21bb63470&gt; 1234567891011121314151617# 密度图 - kdeplot()# 两个样本数据密度分布图# 多个密度图rs1 = np.random.RandomState(2) rs2 = np.random.RandomState(5) df1 = pd.DataFrame(rs1.randn(100,2)+2,columns = ['A','B'])df2 = pd.DataFrame(rs2.randn(100,2)-2,columns = ['A','B'])# 创建数据sns.kdeplot(df1['A'],df1['B'],cmap = 'Greens', shade = True,shade_lowest=False)sns.kdeplot(df2['A'],df2['B'],cmap = 'Blues', shade = True,shade_lowest=False)# 创建图表#sns.rugplot(df2['A']+df1['A'], color="g", axis='x',alpha = 0.5)#sns.rugplot(df2['B']+df1['B'], color="r", axis='y',alpha = 0.5) 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21be56278&gt; 综合散点图1234567891011121314151617# 综合散点图 - jointplot()# 散点图 + 分布图rs = np.random.RandomState(2) df = pd.DataFrame(rs.randn(200,2),columns = ['A','B'])sns.jointplot(x=df['A'], y=df['B'], # 设置xy轴，显示columns名称 data=df, # 设置数据 color = 'k', # 设置颜色 s = 50, edgecolor="w",linewidth=1, # 设置散点大小、边缘线颜色及宽度(只针对scatter） kind = 'scatter', # 设置类型：“scatter”、“reg”、“resid”、“kde”、“hex” space = 0.2, # 设置散点图和布局图的间距 size = 8, # 图表大小（自动调整为正方形） ratio = 5, # 散点图与布局图高度比，整型 marginal_kws=dict(bins=15, rug=True) # 设置柱状图箱数，是否设置rug ) 1&lt;seaborn.axisgrid.JointGrid at 0x1b21bee2be0&gt; 12345678910# 综合散点图 - jointplot()# 散点图 + 分布图# 六边形图df = pd.DataFrame(rs.randn(500,2),columns = ['A','B'])with sns.axes_style("white"): sns.jointplot(x=df['A'], y=df['B'],data = df, kind="hex", color="g", marginal_kws=dict(bins=20)) 123456789101112131415# 综合散点图 - jointplot()# 散点图 + 分布图# 密度图rs = np.random.RandomState(15)df = pd.DataFrame(rs.randn(300,2),columns = ['A','B'])# 创建数据g = sns.jointplot(x=df['A'], y=df['B'],data = df, kind="kde", color="k", shade_lowest=False)# 创建密度图g.plot_joint(plt.scatter,c="w", s=30, linewidth=1, marker="*")# 添加散点图 1&lt;seaborn.axisgrid.JointGrid at 0x1b21c4325f8&gt; 1234567891011121314151617181920212223242526# 综合散点图 - JointGrid()# 可拆分绘制的散点图# plot_joint() + ax_marg_x.hist() + ax_marg_y.hist()sns.set_style("white")# 设置风格tips = sns.load_dataset("tips")print(tips.head())# 导入数据g = sns.JointGrid(x="total_bill", y="tip", data=tips)# 创建一个绘图表格区域，设置好x、y对应数据g.plot_joint(plt.scatter, color ='m', edgecolor = 'white') # 设置框内图表，scatterg.ax_marg_x.hist(tips["total_bill"], color="b", alpha=.6, bins=np.arange(0, 60, 3)) # 设置x轴直方图，注意bins是数组g.ax_marg_y.hist(tips["tip"], color="r", alpha=.6, orientation="horizontal", bins=np.arange(0, 12, 1)) # 设置x轴直方图，注意需要orientation参数from scipy import statsg.annotate(stats.pearsonr) # 设置标注，可以为pearsonr，spearmanrplt.grid(linestyle = '--') 123456 total_bill tip sex smoker day time size0 16.99 1.01 Female No Sun Dinner 21 10.34 1.66 Male No Sun Dinner 32 21.01 3.50 Male No Sun Dinner 33 23.68 3.31 Male No Sun Dinner 24 24.59 3.61 Female No Sun Dinner 4 1234567891011# 综合散点图 - JointGrid()# 可拆分绘制的散点图# plot_joint() + plot_marginals()g = sns.JointGrid(x="total_bill", y="tip", data=tips)# 创建一个绘图表格区域，设置好x、y对应数据g = g.plot_joint(plt.scatter,color="g", s=40, edgecolor="white") # 绘制散点图plt.grid(linestyle = '--')g.plot_marginals(sns.distplot, kde=True, color="g") # 绘制x，y轴直方图 1&lt;seaborn.axisgrid.JointGrid at 0x1b21c630da0&gt; 123456789101112# 综合散点图 - JointGrid()# 可拆分绘制的散点图# plot_joint() + plot_marginals()# kde - 密度图g = sns.JointGrid(x="total_bill", y="tip", data=tips)# 创建一个绘图表格区域，设置好x、y对应数据g = g.plot_joint(sns.kdeplot,cmap = 'Reds_r') # 绘制密度图plt.grid(linestyle = '--')g.plot_marginals(sns.kdeplot, shade = True, color="r") # 绘制x，y轴密度图 1&lt;seaborn.axisgrid.JointGrid at 0x1b21d7aef60&gt; 矩阵散点图1234567891011121314151617# 矩阵散点图 - pairplot()sns.set_style("white")# 设置风格iris = sns.load_dataset("iris")print(iris.head())# 读取数据sns.pairplot(iris, kind = 'scatter', # 散点图/回归分布图 &#123;‘scatter’, ‘reg’&#125; diag_kind="hist", # 直方图/密度图 &#123;‘hist’, ‘kde’&#125; hue="species", # 按照某一字段进行分类 palette="husl", # 设置调色板 markers=["o", "s", "D"], # 设置不同系列的点样式（这里根据参考分类个数） size = 2, # 图表大小 ) 123456 sepal_length sepal_width petal_length petal_width species0 5.1 3.5 1.4 0.2 setosa1 4.9 3.0 1.4 0.2 setosa2 4.7 3.2 1.3 0.2 setosa3 4.6 3.1 1.5 0.2 setosa4 5.0 3.6 1.4 0.2 setosa 1&lt;seaborn.axisgrid.PairGrid at 0x1b21d8a44e0&gt; 123456# 矩阵散点图 - pairplot()# 只提取局部变量进行对比sns.pairplot(iris,vars=["sepal_width", "sepal_length"], kind = 'reg', diag_kind="kde", hue="species", palette="husl") 1&lt;seaborn.axisgrid.PairGrid at 0x1b21e003c18&gt; 123456789# 矩阵散点图 - pairplot()# 其他参数设置sns.pairplot(iris, diag_kind="kde", markers="+", plot_kws=dict(s=50, edgecolor="b", linewidth=1), # 设置点样式 diag_kws=dict(shade=True) # 设置密度图样式 ) 1&lt;seaborn.axisgrid.PairGrid at 0x1b21c37be48&gt; 123456789101112131415161718192021# 矩阵散点图 - PairGrid()# 可拆分绘制的散点图# map_diag() + map_offdiag()g = sns.PairGrid(iris,hue="species",palette = 'hls', vars = ['sepal_length','sepal_width','petal_length','petal_width'], # 可筛选 )# 创建一个绘图表格区域，设置好x、y对应数据，按照species分类g.map_diag(plt.hist, histtype = 'barstacked', # 可选：'bar', 'barstacked', 'step', 'stepfilled' linewidth = 1, edgecolor = 'w') # 对角线图表，plt.hist/sns.kdeplotg.map_offdiag(plt.scatter, edgecolor="w", s=40,linewidth = 1, # 设置点颜色、大小、描边宽度 ) # 其他图表，plt.scatter/plt.bar...g.add_legend()# 添加图例 1&lt;seaborn.axisgrid.PairGrid at 0x1b218fe3f98&gt; 12345678# 矩阵散点图 - PairGrid()# 可拆分绘制的散点图# map_diag() + map_lower() + map_upper()g = sns.PairGrid(iris)g.map_diag(sns.kdeplot, lw=3) # 设置对角线图表g.map_upper(plt.scatter, color = 'r') # 设置对角线上端图表g.map_lower(sns.kdeplot, cmap="Blues_d") # 设置对角线下端图表 1&lt;seaborn.axisgrid.PairGrid at 0x1b21ee966a0&gt; 分类数据可视化分类散点图1234567891011121314# stripplot()# 按照不同类别对样本数据进行分布散点图绘制tips = sns.load_dataset("tips")print(tips.head())sns.stripplot(x="day", # x → 设置分组统计字段 y="total_bill", # y → 数据分布统计字段 # 这里xy数据对调，将会使得散点图横向分布 data=tips, # data → 对应数据 jitter = True, # jitter → 当点数据重合较多时，用该参数做一些调整，也可以设置间距如：jitter = 0.1 size = 5, edgecolor = 'w',linewidth=1,marker = 'o' # 设置点的大小、描边颜色或宽度、点样式 ) 123456 total_bill tip sex smoker day time size0 16.99 1.01 Female No Sun Dinner 21 10.34 1.66 Male No Sun Dinner 32 21.01 3.50 Male No Sun Dinner 33 23.68 3.31 Male No Sun Dinner 24 24.59 3.61 Female No Sun Dinner 4 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21f971320&gt; 12345# stripplot()# 通过hue参数再分类sns.stripplot(x="sex", y="total_bill", hue="day", data=tips, jitter=True) 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21f9b2b00&gt; 12345678# stripplot()# 设置调色盘sns.stripplot(x="sex", y="total_bill", hue="day", data=tips, jitter=True, palette="Set2", # 设置调色盘 dodge=True, # 是否拆分 ) 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21fc11198&gt; 123456789# stripplot()# 筛选分类类别print(tips['day'].value_counts())# 查看day字段的唯一值sns.stripplot(x="day", y="total_bill", data=tips,jitter = True, order = ['Sat','Sun'])# order → 筛选类别 12345Sat 87Sun 76Thur 62Fri 19Name: day, dtype: int64 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21fc8c748&gt; 分簇散点图1234567# swarmplot()# 分簇散点图sns.swarmplot(x="total_bill", y="day", data=tips, size = 5, edgecolor = 'w',linewidth=1,marker = 'o', palette = 'Reds')# 用法和stripplot类似 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21fcdef28&gt; 箱型图123456789101112131415# boxplot()sns.boxplot(x="day", y="total_bill", data=tips, linewidth = 2, # 线宽 width = 0.8, # 箱之间的间隔比例 fliersize = 3, # 异常点大小 palette = 'hls', # 设置调色板 whis = 1.5, # 设置IQR notch = True, # 设置是否以中值做凹槽 order = ['Thur','Fri','Sat','Sun'], # 筛选类别 )# 绘制箱型图#sns.swarmplot(x="day", y="total_bill", data=tips,color ='k',size = 3,alpha = 0.8)# 可以添加散点图 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21fd32710&gt; 123# 通过hue参数再分类sns.boxplot(x="day", y="total_bill", data=tips, hue = 'smoker', palette = 'Reds') 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21fdce5c0&gt; 小提琴图12345678910111213# violinplot()sns.violinplot(x="day", y="total_bill", data=tips, linewidth = 2, # 线宽 width = 0.8, # 箱之间的间隔比例 palette = 'hls', # 设置调色板 order = ['Thur','Fri','Sat','Sun'], # 筛选类别 scale = 'area', # 测度小提琴图的宽度：area-面积相同，count-按照样本数量决定宽度，width-宽度一样 gridsize = 50, # 设置小提琴图边线的平滑度，越高越平滑 inner = 'box', # 设置内部显示类型 → “box”, “quartile”, “point”, “stick”, None #bw = 0.8 # 控制拟合程度，一般可以不设置 ) 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21feb0d68&gt; 123456# 通过hue参数再分类sns.violinplot(x="day", y="total_bill", data=tips, hue = 'smoker', palette="muted", split=True, # 设置是否拆分小提琴图 inner="quartile") 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21ff37940&gt; 12345# 结合散点图sns.violinplot(x="day", y="total_bill", data=tips, palette = 'hls', inner = None)sns.swarmplot(x="day", y="total_bill", data=tips, color="w", alpha=.5)# 插入散点图 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21fff0e80&gt; LV图123456789101112# lvplot()sns.lvplot(x="day", y="total_bill", data=tips, palette="mako", #hue = 'smoker', width = 0.8, # 箱之间间隔比例 linewidth = 12, scale = 'area', # 设置框的大小 → “linear”、“exonential”、“area” k_depth = 'proportion', # 设置框的数量 → “proportion”、“tukey”、“trustworthy” )# 绘制LV图sns.swarmplot(x="day", y="total_bill", data=tips,color ='k',size = 3,alpha = 0.8)# 可以添加散点图 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b22101c400&gt; 分类统计图1234567891011121314151617181920# barplot()# 柱状图 - 置信区间估计# 置信区间：样本均值 + 抽样误差titanic = sns.load_dataset("titanic")#print(titanic.head())#print('-----')# 加载数据sns.barplot(x="sex", y="survived", hue="class", data=titanic, palette = 'hls', order = ['male','female'], # 筛选类别 capsize = 0.05, # 误差线横向延伸宽度 saturation=.8, # 颜色饱和度 errcolor = 'gray',errwidth = 2, # 误差线颜色，宽度 ci = 'sd' # 置信区间误差 → 0-100内值、'sd'、None )#print(titanic.groupby(['sex','class']).mean()['survived'])#print(titanic.groupby(['sex','class']).std()['survived'])# 计算数据 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b2210a1048&gt; 1234567# barplot()# 柱状图 - 置信区间估计sns.barplot(x="day", y="total_bill", hue="sex", data=tips, palette = 'Blues',edgecolor = 'w')tips.groupby(['day','sex']).mean()# 计算数据 .dataframe tbody tr th:only-of-type { vertical-align: middle; } 1234567.dataframe tbody tr th &#123; vertical-align: top;&#125;.dataframe thead th &#123; text-align: right;&#125; total_bill tip size day sex Thur Male 18.714667 2.980333 2.433333 Female 16.715312 2.575625 2.468750 Fri Male 19.857000 2.693000 2.100000 Female 14.145556 2.781111 2.111111 Sat Male 20.802542 3.083898 2.644068 Female 19.680357 2.801786 2.250000 Sun Male 21.887241 3.220345 2.810345 Female 19.872222 3.367222 2.944444 12345678910111213141516171819202122# 1、barplot()# 柱状图 - 置信区间估计crashes = sns.load_dataset("car_crashes").sort_values("total", ascending=False)print(crashes.head())# 加载数据f, ax = plt.subplots(figsize=(6, 15))# 创建图表sns.set_color_codes("pastel")sns.barplot(x="total", y="abbrev", data=crashes, label="Total", color="b",edgecolor = 'w')# 设置第一个柱状图sns.set_color_codes("muted")sns.barplot(x="alcohol", y="abbrev", data=crashes, label="Alcohol-involved", color="b",edgecolor = 'w')# 设置第二个柱状图ax.legend(ncol=2, loc="lower right")sns.despine(left=True, bottom=True) 12345678910111213 total speeding alcohol not_distracted no_previous ins_premium \40 23.9 9.082 9.799 22.944 19.359 858.97 34 23.9 5.497 10.038 23.661 20.554 688.75 48 23.8 8.092 6.664 23.086 20.706 992.61 3 22.4 4.032 5.824 21.056 21.280 827.34 17 21.4 4.066 4.922 16.692 16.264 872.51 ins_losses abbrev 40 116.29 SC 34 109.72 ND 48 152.56 WV 3 142.39 AR 17 137.13 KY 1234567# countplot()# 计数柱状图sns.countplot(x="class", hue="who", data=titanic,palette = 'magma')#sns.countplot(y="class", hue="who", data=titanic,palette = 'magma') # x/y → 以x或者y轴绘图（横向，竖向）# 用法和barplot相似 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b22117aac8&gt; 123456789101112# pointplot()# 折线图 - 置信区间估计sns.pointplot(x="time", y="total_bill", hue = 'smoker',data=tips, palette = 'hls', dodge = True, # 设置点是否分开 join = True, # 是否连线 markers=["o", "x"], linestyles=["-", "--"], # 设置点样式、线型 )tips.groupby(['time','smoker']).mean()['total_bill']# 计算数据# # 用法和barplot相似 123456time smokerLunch Yes 17.399130 No 17.050889Dinner Yes 21.859429 No 20.095660Name: total_bill, dtype: float64 线性数据可视化基本使用1234567891011# 基本用法tips = sns.load_dataset("tips")print(tips.head())# 加载数据sns.lmplot(x="total_bill", y="tip", hue = 'smoker',data=tips,palette="Set1", ci = 70, # 误差值 size = 5, # 图表大小 markers = ['+','o'], # 点样式 ) 123456 total_bill tip sex smoker day time size0 16.99 1.01 Female No Sun Dinner 21 10.34 1.66 Male No Sun Dinner 32 21.01 3.50 Male No Sun Dinner 33 23.68 3.31 Male No Sun Dinner 24 24.59 3.61 Female No Sun Dinner 4 1&lt;seaborn.axisgrid.FacetGrid at 0x1b21c57d7b8&gt; 多表格1sns.lmplot(x="total_bill", y="tip", col="smoker", data=tips) 1&lt;seaborn.axisgrid.FacetGrid at 0x1b2215774e0&gt; 1234567# 多图表1sns.lmplot(x="size", y="total_bill", hue="day", col="day",data=tips, aspect=0.6, # 长宽比 x_jitter=.30, # 给x或者y轴随机增加噪音点 col_wrap=4, # 每行的列数 ) 1&lt;seaborn.axisgrid.FacetGrid at 0x1b2216276a0&gt; 12345# 多图表2sns.lmplot(x="total_bill", y="tip", row="sex", col="time",data=tips, size=4)# 行为sex字段，列为time字段# x轴total_bill, y轴tip 1&lt;seaborn.axisgrid.FacetGrid at 0x1b22160a400&gt; 非线性回归1234# 非线性回归sns.lmplot(x="total_bill", y="tip",data=tips, order = 2) 1&lt;seaborn.axisgrid.FacetGrid at 0x1b2214d7b00&gt; 其他图表可视化时间线图123456789101112131415# tsplot()x = np.linspace(0, 15, 31)data = np.sin(x) + np.random.rand(10, 31) + np.random.randn(10, 1)#print(data.shape)#print(pd.DataFrame(data).head())# 创建数据sns.tsplot(data=data, err_style="ci_band", # 误差数据风格，可选：ci_band, ci_bars, boot_traces, boot_kde, unit_traces, unit_points interpolate=True, # 是否连线 ci = [40,70,90], # 设置误差区间 color = 'r' # 设置颜色 ) 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21668c860&gt; 123sns.tsplot(data=data, err_style="boot_traces", n_boot=300 # 迭代次数 ) 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b216533048&gt; 12345678910111213gammas = sns.load_dataset("gammas")print(gammas.head())print('数据量为：%i条' % len(gammas))print('timepoint为0.0时的数据量为：%i条' % len(gammas[gammas['timepoint'] == 0]))print('timepoint共有%i个唯一值' % len(gammas['timepoint'].value_counts()))#print(gammas['timepoint'].value_counts()) # 查看唯一值具体信息# 导入数据sns.tsplot(time="timepoint", # 时间数据，x轴 value="BOLD signal", # y轴value unit="subject", # condition="ROI", # 分类 data=gammas) 123456789 timepoint ROI subject BOLD signal0 0.0 IPS 0 0.5134331 0.0 IPS 1 -0.4143682 0.0 IPS 2 0.2146953 0.0 IPS 3 0.8148094 0.0 IPS 4 -0.894992数据量为：6000条timepoint为0.0时的数据量为：60条timepoint共有100个唯一值 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b221f95a58&gt; 热图123456789# 热图 - heatmap()# 简单示例df = pd.DataFrame(np.random.rand(10,15))# 创建数据 - 10*12图表sns.heatmap(df, # 加载数据 vmin=0, vmax=1 # 设置图例最大最小值 ) 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b221faac88&gt; 123456789101112131415161718# heatmap()# 参数设置flights = sns.load_dataset("flights")flights = flights.pivot("month", "year", "passengers") #print(flights.head())# 加载数据 sns.heatmap(flights, annot = True, # 是否显示数值 fmt = 'd', # 格式化字符串 linewidths = 0.2, # 格子边线宽度 #center = 100, # 调色盘的色彩中心值，若没有指定，则以cmap为主 #cmap = 'Reds', # 设置调色盘 cbar = True, # 是否显示图例色带 #cbar_kws=&#123;"orientation": "horizontal"&#125;, # 是否横向显示图例色带 #square = True, # 是否正方形显示图表 ) 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b223040588&gt; 123456789101112131415161718192021# heatmap()# 绘制半边热图sns.set(style="white")# 设置风格rs = np.random.RandomState(33)d = pd.DataFrame(rs.normal(size=(100, 26)))corr = d.corr() # 求解相关性矩阵表格# 创建数据mask = np.zeros_like(corr, dtype=np.bool)mask[np.triu_indices_from(mask)] = True# 设置一个“上三角形”蒙版cmap = sns.diverging_palette(220, 10, as_cmap=True)# 设置调色盘sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, square=True, linewidths=0.2)# 生成半边热图 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b2231f3128&gt; 图标矩阵12345678910111213141516attend = sns.load_dataset("attention")print(attend.head())# 加载数据g = sns.FacetGrid(attend, col="subject", col_wrap=5, # 设置每行的图表数量 size=1.5)g.map(plt.plot, "solutions", "score", marker="o",color = 'gray',linewidth = 2)# 绘制图表矩阵g.set(xlim = (0,4), ylim = (0,10), xticks = [0,1,2,3,4], yticks = [0,2,4,6,8,10] )# 设置x，y轴刻度 123456 Unnamed: 0 subject attention solutions score0 0 1 divided 1 2.01 1 2 divided 1 3.02 2 3 divided 1 3.03 3 4 divided 1 5.04 4 5 divided 1 4.0 1&lt;seaborn.axisgrid.FacetGrid at 0x1b22328cb00&gt;]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>matplotlib</tag>
        <tag>可视化</tag>
        <tag>Seaborn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PCA主成分分析]]></title>
    <url>%2F2019%2F09%2F26%2FPCA%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[S_B=(u_1-u_2)(u_1-u_2)^T S_w^{-1}(u_1-u_2)(u_1-u_2)^Tw=\lambda W因为$(u_1-u_2)^Tw$是一个标量，所以可以看出 W\propto S_W^{-1}(u_1-u_2)需要注意的是$S_W$在大多数情况下是不可逆的，所以为了解决这个问题，通常有两种方法 令$S_W=S_W+\gamma I$，其中$I$是一个特别小的数，这样$S_W$一定可逆 先使用PCA对数据局进行降维，使得降维后的数据的$S_W$一定可逆 S_w=\sum_{i=1}^C S_{wi} S_{wi}=\sum_{x\in{y_i}}(x-\mu_i)(x-\mu_i)^T S_B=\sum_{i=1}^C\frac{N_i}{N}(\mu_i-\mu)(\mu_i-\mu)^T其中$\mu$表示所有的特征值得均值 \mu=\frac{1}{N}\sum_{\forall x\in y_i}x而$\mu_i$求的是每一个分类的均值，在而分类中$S_B$表示的是类间的差值，但是在多分类中肯定无法这样计算，所以分类中计算的是每个分类中心点到所以分类中心点的方差。C表示的是分类数。 最后得到的结果和原来还是一样 S_w^{-1}S_Bw_i=\lambda w_i所以总结下来LDA的计算流程为 计算每个分类的特征中心值$\mu$ 计算每个分类的类内方差$S_W$ 计算每个分类的类间方差$S_B$ 计算评价函数$J(w)=\frac{wS_Bw^t}{wS_ww^t}$ 利用拉格朗日得到最后的结果 LDA用于降维，和PCA有很多相同，也有很多不同的地方，因此值得好好的比较一下两者的降维异同点。 首先我们看看相同点： 1）两者均可以对数据进行降维。 2）两者在降维时均使用了矩阵特征分解的思想。 3）两者都假设数据符合高斯分布。 我们接着看看不同点： 1）LDA是有监督的降维方法，而PCA是无监督的降维方法 2）LDA降维最多降到类别数k-1的维数，而PCA没有这个限制。，所以 3）LDA除了可以用于降维，还可以用于分类。 4）LDA选择分类性能最好的投影方向，而PCA选择样本点投影具有最大方差的方向。 这点可以从下图形象的看出，在某些数据分布下LDA比PCA降维较优。 感觉使用latex写公式真的爽的一笔啊 f(x)=\frac{1}{x}+3y+7z]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>特征工程</tag>
        <tag>特征降维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据挖掘比赛技巧]]></title>
    <url>%2F2019%2F09%2F21%2F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E6%AF%94%E8%B5%9B%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[特征工程 缺失值填充 特征为连续值，且为正态分布，使用均值填充，保持期望不变 特征值为连续值，且为长尾分布，使用中值填充，避免异常点影响 特征为离散值，使用众数填充 使用模型预测完善用户画像 特征转换 对长尾分布的特征，做对数变换 标准化、归一化 连续值特征离散化 基于LR、SVM、DNN等对特征的分布和尺度敏感的，归一化有助于模型收敛，基于树模型，具有伸缩不变形，不需要做特征变换 ID类特征处理 OneHot编码，例如性别，编码为0,1或者1,0 使用某种特征的统计量代替该特征 Word Embedding，将高纬稀疏特征映射到低纬稠密特征。 异常值剔除 模型选择1、对于高维稀疏特征(如ID特征 One hot编码后)，使用线性模型LR、FM(腾讯社交广告大赛) 2、对于低纬稠密特征，使用集成树模型XgBoost，GDBT，Random Forest(o2o优惠券核销预测) 3、对于图像语音类数据，使用DNN，如CNN，LSTM 数据挖掘比赛中集成树模型占优势的原因： 比赛数据特点 结构化标单数据 混合类型(类别型，连续型) 大量缺失值 含有离群点 长尾分布 树算法模型法特点 善于处理混合类型特征 善于处理缺失值 伸缩不变性 对离群点有鲁棒性 容易并行化、有高效开源工具 模型融合Average、Voting、Stacking，Blending Stacking工具mlxtend 调参经验和技巧 树模型调参经验 GridSearchCV]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>特征工程</tag>
        <tag>数据降维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hive的基本操作]]></title>
    <url>%2F2019%2F09%2F17%2Fhive%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[表的增删改查操作创建表使用if not exists 如果存在则跳过，comment为注释。123456789create table if not exists mydb.employees( name string comment 'Employee name', salary float comment 'Employee salary', subordinates array&lt;string&gt; comment 'Names of subordinates', deduction map&lt;string, float&gt;, address struct&lt;street:string, city:string, state:string, zip:int&gt; comment 'Home address')comment 'descriptions of table'location '/user/hive/warehouse/mydb.db/employees'; 描述表显示表的字段和结构，使用desc/describe 1234--显示表的字段和数据类型desc table_name;--显示对应字段的数据类型desc table_name.columns 管理表和外部表管理表是hive创建的表，由hive控制其生命周期，hive默认情况下会将数据存在在配置文件指定的目录当中，由hive.metastore.warehouse.dir指定。当使用hive删除表的时候，对应的数据也会被删除，即hdfs文件系统中的数据也会被删除。管理表的缺点在于无法共享数据，比如利用pig等工具创建的数据，hive对其没有权限。当使用hive查询这些数据的时候就可以使用一个外部表指向这份数据，而不需要对其的权限。外部表需要使用external修饰。 123456789101112create external table if not exists stocks( exchange string, symbol string, ymd string, price__open string, price__high string, price__low string, price__close float, volume int, price_adj_close float)row format delimited fields terminated by ',' '分隔符为,'location 'data/stocks'; 加上external字段值后，删除表并不会删除这份数据，不过描述标的元数据信息会被删除。元数据可以理解为对该表的描述信息，而不是表内数据。 需要注意的是如果语句省略了external关键字同事源表是外部表，那么新表也是外部表，如果源表是管理表，新表也是管理表。在加上external之后，无论源表是管理表还是外部表，新表都是外部表。 分区表在建表过程中，会根据分区字段创建对应目录，优点在于分层存储，可以加快查询速度，而缺点在于一些数据存在于文件目录下，但是hive只能从表中读取数据，因此会造成资源浪费。分区表创建： 12345678create table employees( name string, salary float, subordinates array&lt;string&gt;, deduction map&lt;string,float&gt;, address struct&lt;street:string, city:string, city:string, state:string&gt;)partitioned by (country string, state string); 在建表的时候hive在hdfs上的目录为…/employees/country/state 查看表中存在所有分区 1show partitions employees; 查询指定分区 1show partitions employees partition(country='CHINA') 删除表1drop table if exists table_name; 对于管理表，表的元数据和表内数据都会被删除。 修改表 表的重命名将表从ａ重命名为ｂ 1alter table a rename to b; 增加表分区1234567alter table add partiion--在一个查询语句中增加多个分区alter table table_name if not exists partition(...) location '/user/hive/warehouse/a'partition(...) location '/user/hive/warehouse/b'partition(...) location '/user/hive/warehouse/c' 修改列的信息将列名从a改到b，并且将其移到serverity字段后面。 1234alter table table_name change column a b type_name '修改列的数据类型'comment 'xxx'after serverity 增加新的列1234alter table table_name add column( app_name string comment 'Application name', session_id long comment 'the current session id';) 删除或替换列1234alter table table_name replace columns（ hour_mins_secs INT comment 'xxx' severity string comment 'xxx';) 将之前的列都删除，只留下replace的列 修改表的属性1alter table table_name set tblproperties('notes'='xxx'); 修改表的存储属性1alter table table_name partition(a=xxx,b=xxx,c=xxx) set fileformat sequencefile; 指定对应的分区中的表，并且重新设置其格式。 加载和导出数据从本地加载数据123load data local inpath '/home/hadopp/data.txt'overwrite into table employeespartition(country='US',state='CA'); 需要注意的是创建分区表的时候使用的是partition by。如果目录不存在，hive会先创建分区目录。 通过查询语句加载数据123insert overwrite table employeespartition(country='US',state='CA')select * from table_name where xxx=xxx; 通过查询语句建表12create table if not exists table_name as select * from table_name_b; 导出数据12345--方法一，谁用hadoop提供的工具hadoop fs -cp source_path target_path--方法二insert overwrite local directory '/home/hadoop/employees'select * from employees; hive的连接操作table stu 12341 chenli 212 xuzeng 223 xiaodan 234 hua 24 table sub 12341 chinese2 english3 science5 nature 内连接inner join，关键字 join on。仅列出两个表中符合连接条件的数据。 12345select a.*,b.* from stu a join sub b on a.id=b.id--结果1 chenli 21 1 chinese2 xuzeng 22 2 english3 xiaodan 23 3 science join后面连接表，而on指定连接条件。 左连接和右连接左连接，显示左边表的所有数据，如果右边表有与之对应的数据则显示，否则显示为NULL。 123456select a.* from stu a left outer join sub b on a.id=b.id;--结果1 chenli 21 1 chinese2 xuzeng 22 2 english3 xiaodan 23 3 science4 hua 24 NULL NULL 右连接与左连接相反，使用的关键字为 right outer join xxx on xxx。 标准查询关键字执行顺序为 from-&gt;where-&gt;group by-&gt;having-&gt;order by。 全连接左表和右表都显示，如果没有对应数据，则都显示为NULL 1234567select a.* from stu a full outer join sub b on a.id=b.id;--结果1 chenli 21 1 chinese2 xuzeng 22 2 english3 xiaodan 23 3 science4 hua 24 NULL NULLNULL NULL NULL 5 nature 左半开连接左半开连接。left semi join，语法与左连接不一样，只能选择出左边表的数据，此数据符合on后面的条件。 1234567select a.* from stu a left semi join sub b on a.id=b.id;--结果1 chenli 212 xuzeng 223 xiaodan 23--下列语句会报错select a.*,b.* from stu a left semi join sub b on a.id=b.id; 笛卡尔连接123456789101112131415161718select a.*,b.* from cl_student a join cl_stu_sub b;--结果1 chenli 21 1 chinese1 chenli 21 2 english1 chenli 21 3 science1 chenli 21 5 nature2 xuzeng 22 1 chinese2 xuzeng 22 2 english2 xuzeng 22 3 science2 xuzeng 22 5 nature3 xiaodan 23 1 chinese3 xiaodan 23 2 english3 xiaodan 23 3 science3 xiaodan 23 5 nature4 hua 24 1 chinese4 hua 24 2 english4 hua 24 3 science4 hua 24 5 nature 花了几天的时间整理了hive的用法，终于不用在对着SQL摸瞎了，加油吧进击的SQL boy！ 日常福利(●´∀｀●)]]></content>
      <categories>
        <category>大数据</category>
        <category>hive编程</category>
      </categories>
      <tags>
        <tag>Hive</tag>
        <tag>基本操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hive数据类型]]></title>
    <url>%2F2019%2F09%2F08%2Fhive%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[文本文件数据编码 TSV：tab separated values；即“制表符分隔值”，用制表符分隔数据 CSV： comma separated values；即“逗号分隔值”，用逗号分隔数据 两种文件存在的缺点在于文件中可能存在不需要作为分隔符的逗号或者制表符存在，所有hive有专门的分隔符。hive记录中默认的分隔符 分隔符 描述 \n 对于文本文件来说每一行都是记录，可以使用换行符作为分隔符 ^A(ctrl+A) 用于分隔字段(列)，在CREATE TABLE 语句中可以使用八进制编码\001表示，键盘上打不出来。 ^B 用于分隔array或者struct中的元素，或于用map钟键值对的分隔，在CREATE TABLE中使用\002表示 ^C 用于MAP钟键与值的分隔，用\003表示 读时模式传统数据库是写时模式，即在写入文件的时候会，会对数据的格式进行校验，如果不符合，将无法写入数据库。 hive是读时模式，在往数据库里写入不会对数据进行校验，但是在读取数据的时候会对数据进行校验，对于不合格的数据，会设置为null。 hive的优点在于加载(写)数据的时候速度较快，因为不需要对数据进行解析，而传统写时模式则有利于数据的查询。 好久没有更新博客了，这篇虽然水了点，写得像个笔记，算是开篇吧，福利就上亚丝娜吧!!!]]></content>
      <categories>
        <category>大数据</category>
        <category>hive编程</category>
      </categories>
      <tags>
        <tag>Hive</tag>
        <tag>编码类型</tag>
      </tags>
  </entry>
</search>
