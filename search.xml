<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[leetcode题型归纳总结]]></title>
    <url>%2F2021%2F03%2F13%2Fleetcode%E9%A2%98%E5%9E%8B%E5%BD%92%E7%BA%B3%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[LeetCode常见题型及对应解法技巧类矩阵数据旋转48. 旋转图像给定一个 n × n 的二维矩阵 matrix 表示一个图像。请你将图像顺时针旋转 90 度。你必须在 原地 旋转图像，这意味着你需要直接修改输入的二维矩阵。请不要 使用另一个矩阵来旋转图像。示例 1：12输入：matrix = [[1,2,3],[4,5,6],[7,8,9]]输出：[[7,4,1],[8,5,2],[9,6,3]] 思路：对于正方形，最外圈是规律变化的，因此只需要将最外圈进行进行顺时针置换就行了。需要注意深拷贝和浅拷贝的问题。 1234567891011121314151617181920212223class Solution: def rotate(self, matrix) -&gt; None: """ Do not return anything, modify matrix in-place instead. """ n = len(matrix) mid = int(n/2) for i in range(mid): # 深拷贝 left = [a[i] for a in matrix] right = [b[n-i-1] for b in matrix] upper = matrix[i].copy() bottom = matrix[n-i-1].copy() for j in range(i, n-i): matrix[i][j] = left[n-j-1] matrix[j][n-i-1] = upper[j] matrix[n-i-1][j] = right[n-j-1] matrix[j][i] = bottom[j] 238. 除自身以外数组的乘积 给你一个长度为 n 的整数数组 nums，其中 n &gt; 1，返回输出数组 output ，其中 output[i] 等于 nums 中除 nums[i] 之外其余各元素的乘积。 示例: 12输入: [1,2,3,4]输出: [24,12,8,6] 思路：采用左右双数组，L和R L[i] = \prod_{j=0}^{i-1}nums[j] R[i] = \prod_{j=i+1}^{n-1}nums[j] output[i]=L[i]*R[i]所以有L = [1,1,2,6], R=[24,12,4,1]。 哈希1、两数之和给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 的那 两个 整数，并返回它们的数 组下标。 你可以假设每种输入只会对应一个答案。但是，数组中同一个元素不能使用两遍。 你可以按任意顺序返回答案。 输入：nums = [2,7,11,15], target = 9 输出：[0,1] 解释：因为 nums[0] + nums[1] == 9 ，返回 [0, 1] 。 解析：利用哈希，对于每一个元素x，利用哈希表保存x的值及其对应的索引，然后当target-y在hash表中时，则说明前面有值x+y = target。 123456789class Solution: def twoSum(self, nums: List[int], target: int) -&gt; List[int]: hashtable = &#123;&#125; for index, val in enumerate(nums): if target - nums[index] in hashtable: return [hashtable[target - nums[index]], index] hashtable[nums[index]] = index return [0, 0] 49. 字母异位词分组 给定一个字符串数组，将字母异位词组合在一起。字母异位词指字母相同，但排列不同的字符串。 示例: 1234567输入: [&quot;eat&quot;, &quot;tea&quot;, &quot;tan&quot;, &quot;ate&quot;, &quot;nat&quot;, &quot;bat&quot;]输出:[ [&quot;ate&quot;,&quot;eat&quot;,&quot;tea&quot;], [&quot;nat&quot;,&quot;tan&quot;], [&quot;bat&quot;]] 思路：排序+哈希 [“ate”,”eat”,”tea”]排序之后，都是aet，可以将ate全都存到hash表中，key值为ate，每个key值保存的都是对应的字母异位词组 123456789101112131415class Solution: """ 思路：将字符串转换成列表排序后合并，然后进行映射，将结果相同的合并 """ def groupAnagrams(self, strs): res = &#123;&#125; for s in strs: word_label = ''.join(sorted(list(s))) if word_label not in res: res[word_label] = [] res[word_label].append(s) return list(res.values()) 169.多数元素 给定一个大小为 n 的数组，找到其中的多数元素。多数元素是指在数组中出现次数 大于 ⌊ n/2 ⌋ 的元素。 思路： 思路一：哈希，找到每个元素出现的次数，然后挑选出出现次数大于n/2的 思路二：排序，利用快排对数组进行排序，然后找到中间位置的数，即为n/2的数据。 287. 寻找重复数 给定一个包含 n + 1 个整数的数组 nums ，其数字都在 1 到 n 之间（包括 1 和 n），可知至少存在一个重复的整数。 假设 nums 只有 一个重复的整数 ，找出 这个重复的数 。 思路： 哈希，同上一题相同思路。 560. 和为K的子数组 给定一个整数数组和一个整数 k，你需要找到该数组中和为 k 的连续的子数组的个数。 示例 1 : 12输入:nums = [1,1,1], k = 2输出: 2 , [1,1] 与 [1,1] 为两种不同的情况。 说明 : 数组的长度为 [1, 20,000]。 数组中元素的范围是 [-1000, 1000] ，且整数 k 的范围是 [-1e7, 1e7]。 思路：利用哈希记录当前位置的前缀值prefix，此时prefix表示每个位置的前缀和，以实例1为例prefix=[1,2,3]。此时要判断当前位置的连续和是否为k只需要判断prefix[i] - k 是否在prefix中就行了，当存在前缀和的时候，有prefix[j] + k = prefix[i]， 此时[i,j]之间的数组和为k。因此只需要求前缀和，然后每次判断prefix[i]-k是否在其中，当同一个前缀和出现多次，表示有不同长度的数组到当前位置i的结果为k。 12345678910111213141516171819202122class Solution: """ 思路一：暴力枚举，不解释连招，超时 思路二：利用哈希记录前缀值 """ def subarraySum(self, nums, k): # 初始化结果 pre = &#123;0:1&#125; cur = 0 count = 0 for i in range(len(nums)): cur += nums[i] if cur - k in pre: count += pre[cur - k] if cur in pre: pre[cur] += 1 else: pre[cur] = 1 return count 437. 路径总和 III 给定一个二叉树，它的每个结点都存放着一个整数值。 找出路径和等于给定数值的路径总数。 路径不需要从根节点开始，也不需要在叶子节点结束，但是路径方向必须是向下的（只能从父节点到子节点）。 二叉树不超过1000个节点，且节点数值范围是 [-1000000,1000000] 的整数。 示例： 123456789101112131415root = [10,5,-3,3,2,null,11,3,-2,null,1], sum = 8 10 / \ 5 -3 / \ \ 3 2 11 / \ \3 -2 1返回 3。和等于 8 的路径有:1. 5 -&gt; 32. 5 -&gt; 2 -&gt; 13. -3 -&gt; 11 思路：前缀和+dfs。 由于路径只能从上到下，所以都是单路径，可以求每条路径上的前缀和，在判断结果是否符合。需要注意，如果两个路径都有节点的前缀和为n，那么在统计另外一个前缀和是否为n的时候，不应该考虑当前路径的情况。 123456789101112131415161718192021222324252627282930class Solution: """ 前缀和+递归，与560题思路类似，注意 """ def pathSum(self, root: TreeNode, sum: int) -&gt; int: count = 0 prefix = &#123;0: 1&#125; def dfs(root, total, prefix): nonlocal count, sum if not root: return else: total += root.val if total - sum in prefix: count += prefix[total - sum] if total in prefix: prefix[total] += 1 else: prefix[total] = 1 dfs(root.left, total, prefix) dfs(root.right, total, prefix) # 保持前缀都是在一条路径下面 prefix[total] -= 1 dfs(root, 0, prefix) return count 438. 找到字符串中所有字母异位词 给定一个字符串 s 和一个非空字符串 p，找到 s 中所有是 p 的字母异位词的子串，返回这些子串的起始索引。 字符串只包含小写英文字母，并且字符串 s 和 p 的长度都不超过 20100。 说明： 字母异位词指字母相同，但排列不同的字符串。 不考虑答案输出的顺序。 示例 1: 123456789输入:s: &quot;cbaebabacd&quot; p: &quot;abc&quot;输出:[0, 6]解释:起始索引等于 0 的子串是 &quot;cba&quot;, 它是 &quot;abc&quot; 的字母异位词。起始索引等于 6 的子串是 &quot;bac&quot;, 它是 &quot;abc&quot; 的字母异位词。 思路：哈希+滑窗 将p用哈希表保存，记录下每个字母出现的次数p_count，然后采用滑窗，记录s在滑窗中的字符s_count，如果p_count=s_count，说明当前滑窗中的字符和p为异位词。然后向右移动，左边移出字符次数-1，右边移入字符次数+1，然后一次对比p_count是否等于s_count。 12345678910111213141516171819202122232425262728293031class Solution: """ 思路：参考49，滑窗+哈希+排序。超时，还需要优化 思路二：滑窗+哈希表，采用哈希将结果保存 """ def findAnagrams(self, s: str, p: str) : p_count = [0] * 26 s_count = [0] * 26 m = len(p) n = len(s) for c in p: p_count[ord(c)-97] += 1 res = [] left, right = 0, 0 for right in range(n): if right &lt; m - 1: s_count[ord(s[right]) - 97] += 1 else: s_count[ord(s[right]) - 97] += 1 if s_count == p_count: res.append(left) s_count[ord(s[left]) - 97] -= 1 left += 1 return res 448. 找到所有数组中消失的数字 给定一个范围在 1 ≤ a[i] ≤ n ( n = 数组大小 ) 的 整型数组，数组中的元素一些出现了两次，另一些只出现一次。 找到所有在 [1, n] 范围之间没有出现在数组中的数字。 您能在不使用额外空间且时间复杂度为O(n)的情况下完成这个任务吗? 你可以假定返回的数组不算在额外空间内。 示例: 12345输入:[4,3,2,7,8,2,3,1]输出:[5,6] 思路一：哈希，构建一个1-n的哈希表，找到出现次数为0的数。时间复杂度O(n)，空间复杂度O(n) 思路二：原地修改。 贪心算法贪心算法（又称贪婪算法）是指，在对问题求解时，总是做出在当前看来是最好的选择。也就是说，不从整体最优上加以考虑，他所做出的是在某种意义上的局部最优解。 贪心算法不是对所有问题都能得到整体最优解，关键是贪心策略的选择，选择的贪心策略必须具备无后效性，即某个状态以前的过程不会影响以后的状态，只与当前状态有关。 406. 根据身高重建队列 假设有打乱顺序的一群人站成一个队列，数组 people 表示队列中一些人的属性（不一定按顺序）。每个 people[i] = [hi, ki] 表示第 i 个人的身高为 hi ，前面 正好 有 ki 个身高大于或等于 hi 的人。 请你重新构造并返回输入数组 people 所表示的队列。返回的队列应该格式化为数组 queue ，其中 queue[j] = [hj, kj] 是队列中第 j 个人的属性（queue[0] 是排在队列前面的人）。 示例 1： 12345678910输入：people = [[7,0],[4,4],[7,1],[5,0],[6,1],[5,2]]输出：[[5,0],[7,0],[5,2],[6,1],[4,4],[7,1]]解释：编号为 0 的人身高为 5 ，没有身高更高或者相同的人排在他前面。编号为 1 的人身高为 7 ，没有身高更高或者相同的人排在他前面。编号为 2 的人身高为 5 ，有 2 个身高更高或者相同的人排在他前面，即编号为 0 和 1 的人。编号为 3 的人身高为 6 ，有 1 个身高更高或者相同的人排在他前面，即编号为 1 的人。编号为 4 的人身高为 4 ，有 4 个身高更高或者相同的人排在他前面，即编号为 0、1、2、3 的人。编号为 5 的人身高为 7 ，有 1 个身高更高或者相同的人排在他前面，即编号为 1 的人。因此 [[5,0],[7,0],[5,2],[6,1],[4,4],[7,1]] 是重新构造后的队列。 思路：排序+贪心 由于个子矮的对个子高的没有影响，因此优先将个子矮的放到前面(对于拍在他前面的人数相同时)。 以下写法是考虑到插入排序的特性，优先把高的放到一个位置，然后将低的放到同样的位置，高的向后移动一位。 12345678910111213class Solution: """ 贪心+排序: 首先将身高按照降序排序，身高高的优先放到前面 个子矮的对于个子高的没有影响，因此个子矮的一般要放到前面 """ def reconstructQueue(self, people): people.sort(key=lambda x: (-x[0], x[1])) output = [] for p in people: output.insert(p[1], p) return output 621. 任务调度器 给你一个用字符数组 tasks 表示的 CPU 需要执行的任务列表。其中每个字母表示一种不同种类的任务。任务可以以任意顺序执行，并且每个任务都可以在 1 个单位时间内执行完。在任何一个单位时间，CPU 可以完成一个任务，或者处于待命状态。 然而，两个 相同种类 的任务之间必须有长度为整数 n 的冷却时间，因此至少有连续 n 个单位时间内 CPU 在执行不同的任务，或者在待命状态。 你需要计算完成所有任务所需要的 最短时间 。 示例 1： 1234输入：tasks = [&quot;A&quot;,&quot;A&quot;,&quot;A&quot;,&quot;B&quot;,&quot;B&quot;,&quot;B&quot;], n = 2输出：8解释：A -&gt; B -&gt; (待命) -&gt; A -&gt; B -&gt; (待命) -&gt; A -&gt; B 在本示例中，两个相同类型任务之间必须间隔长度为 n = 2 的冷却时间，而执行一个任务只需要一个单位时间，所以中间出现了（待命）状态。 思路：贪心+分桶 对于不同的任务，根据任务重复数对其进行分桶，然后计算按照任务次数多少，依次往桶里面填充。 总排队时间=（桶个数 - 1）* 桶的容量 + 最后一桶的任务数 1234567891011121314class Solution: """ 分桶的思想： """ def leastInterval(self, tasks, n) -&gt; int: import collections freq = collections.Counter(tasks) # 最多的执行次数 max_exec = max(freq.values()) # 具有最多执行次数的任务数量 max_count = sum(1 for v in freq.values() if v == max_exec) # 总排队时间 = (桶个数 - 1) * (n + 1) + 最后一桶的任务数 return max((max_exec - 1) * (n + 1) + max_count, len(tasks)) 动态规划算法解释： 动态规划（英语：Dynamic programming，简称 DP）是一种在数学、管理科学、计算机科学、经济学和生物信息学中使用的，通过把原问题分解为相对简单的子问题的方式求解复杂问题的方法。 动态规划常常适用于有重叠子问题和最优子结构性质的问题，动态规划方法所耗时间往往远少于朴素解法。 动态规划背后的基本思想非常简单。大致上，若要解一个给定问题，我们需要解其不同部分（即子问题），再根据子问题的解以得出原问题的解。动态规划往往用于优化递归问题，例如斐波那契数列，如果运用递归的方式来求解会重复计算很多相同的子问题，利用动态规划的思想可以减少计算量。 通常许多子问题非常相似，为此动态规划法试图仅仅解决每个子问题一次，具有天然剪枝的功能，从而减少计算量：一旦某个给定子问题的解已经算出，则将其记忆化存储，以便下次需要同一个子问题解之时直接查表。这种做法在重复子问题的数目关于输入的规模呈指数增长时特别有用。 回文串5.最长回文子串 给你一个字符串 s，找到 s 中最长的回文子串。 示例 1： 123输入：s = &quot;babad&quot;输出：&quot;bab&quot;解释：&quot;aba&quot; 同样是符合题意的答案。 思路：动态规划，关键思想，以当前位数s[i]为回文字符串尾部，每次只考虑max_len+1或者max_len+2的长度。也就是说，每一次 12345678910111213141516171819202122class Solution: def longestPalindrome(self, s: str) -&gt; str: if not s: return "" length = len(s) # 如果字符串长度为或者s本身是字符串，直接返回 if length == 1 or s == s[::-1]: return s max_len, start = 1, 0 # 遍历每一个字符，假设为回文字符的尾字符 for i in range(1, length): # [i-max_len, i]，一共max_len+1个元素 even = s[i - max_len:i + 1] # [i-max_len-1, i] 一共max_len+2个元素 odd = s[i - max_len - 1:i + 1] if i - max_len - 1 &gt;= 0 and odd == odd[::-1]: start = i - max_len - 1 max_len += 2 elif i - max_len &gt;= 0 and even == even[::-1]: start = i - max_len max_len += 1 return s[start:start + max_len] 正则表达式给你一个字符串 s 和一个字符规律 p，请你来实现一个支持 ‘.’ 和 ‘*’ 的正则表达式匹配。 ‘.’ 匹配任意单个字符 ‘*’ 匹配零个或多个前面的那一个元素 所谓匹配，是要涵盖 整个 字符串 s的，而不是部分字符串。 根据分析其实可以得出p的第一个字符只能为’.’或者string字符，不能是’*’ 正则匹配的遍历条件是两者同时匹配到终点。 ​ 如果两者同时到达结尾，则能匹配上，如果其中一个p已经遍历结束，但是s还没有遍历完则匹配不上 ​ 由于模式里面第一个不可能是’*’。判断的时候我们只需要从左往右判断就行。 ​ 如果p的第二字字符是*，则需要判断第一个字符是否能匹配上，如果能匹配上。则，模式有三种： 字符串向下移动，但是p不变。 p移动两位，即*的中间匹配位数为0，s不动 p不变，s向后移动。 如果p的第二个字符不是*，判断就很简单，只需要一个一个往后面移动。 状态方程有： 1、当p的第j个时小写字母时，s中必须为相同的小写字母有 f[i][j]= \begin{cases} f[i-1][j-1]& \text{p[j]=s[i]}\\ false& \text{p[j]!=s[i]} \end{cases}2、当第p个为’.’的时候，可以匹配s中任意小写字母，此时 f[i][j]=f[i-1][j-1]3、当p的第j个字符为’*’，可以匹配前面一个字符0次或者无数次。 当s[i] = p[j-1]的时候，有 f[i][j]= \begin{cases} f[i][j-1]& \text{s[i]=p[j-1], 匹配一个}\\ f[i][j-2]& \text{s[i]!=p[j-1]，不匹配} \end{cases} f[i][j]= \begin{cases} f[i-1][j] or f[i][j-2]& \text{p[j]='*', s[i]=p[j-1]}\\ f[i][j-2]& \text{s[i]!=p[j-1]} \end{cases} 直接对照代码更容易理解 1234567891011121314151617181920212223242526class Solution: def isMatch(self, s: str, p: str) -&gt; bool: m, n = len(s), len(p) def matches(i: int, j: int) -&gt; bool: if i == 0: return False if p[j - 1] == '.': return True return s[i - 1] == p[j - 1] f = [[False] * (n + 1) for _ in range(m + 1)] f[0][0] = True for i in range(m + 1): for j in range(1, n + 1): # 如果p][j]='*' if p[j - 1] == '*': # 匹配0个的情况 f[i][j] |= f[i][j - 2] # 匹配一个的情况 if matches(i, j - 1): f[i][j] |= f[i - 1][j] else: if matches(i, j): f[i][j] |= f[i - 1][j - 1] return f[m][n] 子序列系列53. 最大子序和 给定一个整数数组 nums ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。 示例 1： 123输入：nums = [-2,1,-3,4,-1,2,1,-5,4]输出：6解释：连续子数组 [4,-1,2,1] 的和最大，为 6 。 思路：动态规划，关键点在于当和小于0时，需要重新选择序列头 12345678910111213141516class Solution: def maxSubArray(self, nums): cur = 0 sum_all = -float('inf') for i in range(len(nums)): if cur &gt; 0: cur += nums[i] else: cur = nums[i] if cur &gt; sum_all: sum_all = cur return sum_all 128. 最长连续序列 给定一个未排序的整数数组 nums ，找出数字连续的最长序列（不要求序列元素在原数组中连续）的长度。 进阶：你可以设计并实现时间复杂度为 O(n) 的解决方案吗？ 示例 1： 123输入：nums = [100,4,200,1,3,2]输出：4解释：最长数字连续序列是 [1, 2, 3, 4]。它的长度为 4。 思路： 一：排序+双指针 思路二：哈希 代码: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# class Solution: """ 思路一：排序 + 双指针 """ def longestConsecutive(self, nums): nums = sorted(nums) length = len(nums) if length &lt; 2: return length start = 0 end = 0 cur = 1 max_len = 0 while cur &lt; length: if nums[end] + 1 == nums[cur] or nums[end] == nums[cur]: end = cur else: end = cur start = end l = len(set(nums[start:end+1])) if l &gt; max_len: max_len = l cur += 1 return max_len class Solution: def longestConsecutive(self, nums): longest_streak = 0 num_set = set(nums) for num in num_set: if num - 1 not in num_set: current_num = num current_streak = 1 while current_num + 1 in num_set: current_num += 1 current_streak += 1 longest_streak = max(longest_streak, current_streak) return longest_streak 300. 最长递增子序列 给你一个整数数组 nums ，找到其中最长严格递增子序列的长度。 子序列是由数组派生而来的序列，删除（或不删除）数组中的元素而不改变其余元素的顺序。例如，[3,6,2,7] 是数组 [0,3,1,6,2,2,7] 的子序列。 示例 1： 123输入：nums = [10,9,2,5,3,7,101,18]输出：4解释：最长递增子序列是 [2,3,7,101]，因此长度为 4 。 思路：定义$dp[i]$为前i个元素中，以i为数字结尾的最长上升序列的长度。因此我们可以从小到大计算dp的值。在计算$dp[i]$之前，已经算出了$dp[0, …, i-1]$的值，则状态转移方程为 dp[i]=max(dp[j]) + 1其中 $0\leq j &lt; i$并且$nums[j] &lt; nums[i]$。最后整个上身子序列的最大值为: LIS_{length}=max(dp[i])，其中0\leq i < n1234567891011121314151617181920212223class Solution: """ 思路一：比较简单，动态规划， O(n^2),从后往前遍历 思路二： """ def lengthOfLIS(self, nums): length = len(nums) dis = [1] * length dis[0] = 1 max_len = 1 for i in range(1, length): j = i - 1 while j &gt;= 0: if nums[i] &gt; nums[j]: dis[i] = max(dis[j]+1, dis[i]) j -= 1 if dis[i] &gt; max_len: max_len = dis[i] return max_len 1143. 最长公共子序列 给定两个字符串 text1 和 text2，返回这两个字符串的最长公共子序列的长度。 一个字符串的 子序列 是指这样一个新的字符串：它是由原字符串在不改变字符的相对顺序的情况下删除某些字符（也可以不删除任何字符）后组成的新字符串。例如，”ace” 是 “abcde” 的子序列，但 “aec” 不是 “abcde” 的子序列。两个字符串的「公共子序列」是这两个字符串所共同拥有的子序列。 若这两个字符串没有公共子序列，则返回 0。 示例 1: 123输入：text1 = "abcde", text2 = "ace" 输出：3 解释：最长公共子序列是 "ace"，它的长度为 3。 思路：建立一个二维数组$dp[m][n]$。 边界条件 1、两个都是空串， $dp[0][0]=0$ 2、其中一个是空串，$dp[i][0]=0$ or $dp[[0][j]=0$。 如果不是空串，有两种情况 一种是$text[i]!=text[j]$，此时状态转移方程为$dp[i][j]=max(dp[i-1][j], dp[i][j-1])$ 当$text[i]=text[j]$时，状态方程为$dp[i][j]=dp[i-1][j-1]+1$。 代码: 1234567891011121314151617181920class Solution: def longestCommonSubsequence(self, text1: str, text2: str) -&gt; int: m, n = len(text1), len(text2) dp = [[0] * (n+1) for _ in range(m+1)] for i in range(m+1): dp[i][0] = 0 for j in range(n+1): dp[0][j] = 0 for i in range(1, m+1): for j in range(1, n+1): if text1[i-1] == text2[j-1]: dp[i][j] = dp[i-1][j-1] + 1 else: dp[i][j] = max(dp[i-1][j], dp[i][j-1]) return dp[m][n] 路径类问题路径类的问题，通常有个很明显的特点，就是从左上往右下慢慢异动，通常考虑最短路径或者路径数。思路基本是一样的。需要注意初始化边界。 62. 不同路径 一个机器人位于一个 m x n 网格的左上角 （起始点在下图中标记为 “Start” ）。 机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为 “Finish” ）。 问总共有多少条不同的路径？ 示例 1： 1234567输入：m = 3, n = 2输出：3解释：从左上角开始，总共有 3 条路径可以到达右下角。1. 向右 -&gt; 向下 -&gt; 向下2. 向下 -&gt; 向下 -&gt; 向右3. 向下 -&gt; 向右 -&gt; 向下 思路：动态规划，这类路径类的问题，有个最大 123456789101112131415class Solution: def uniquePaths(self, m, n): res = [(n * [0]) for i in range(m)] for i in range(m): res[i][0] = 1 for j in range(n): res[0][j] = 1 for i in range(1, m): for j in range(1, n): res[i][j] = res[i][j-1] + res[i-1][j] return res[m-1][n-1] 64. 最小路径和 给定一个包含非负整数的 *m* x *n* 网格 grid ，请找出一条从左上角到右下角的路径，使得路径上的数字总和为最小。 说明：每次只能向下或者向右移动一步。 示例 1： 123输入：grid = [[1,3,1],[1,5,1],[4,2,1]]输出：7解释：因为路径 1→3→1→1→1 的总和最小。 思路：动态规划 min\_dist[i][j] = min(min\_dist[i-1][j], min\_dist[i][j-1]) + dis[i][j]12345678910111213141516171819202122232425262728class Solution: def minPathSum(self, grid): m = len(grid) n = len(grid[0]) if m == 0: return 0 # 这种写法存在浅拷贝的坑 # min_path = [[0] * n] * m min_path = [([0] * n) for i in range(m)] # 初始化第一行与第一列 init_dis = 0 for i in range(m): init_dis += grid[i][0] min_path[i][0] = init_dis init_dis = grid[0][0] for i in range(1, n): init_dis += grid[0][i] min_path[0][i] += init_dis for i in range(1, m): for j in range(1, n): min_path[i][j] = min(min_path[i-1][j], min_path[i][j-1]) + grid[i][j] return min_path[m-1][n-1] 斐波那契类 f[0] = f[1]=1 f[n] = f[n-1] + f[n-2], n\geq270. 爬楼梯 假设你正在爬楼梯。需要 n 阶你才能到达楼顶。 每次你可以爬 1 或 2 个台阶。你有多少种不同的方法可以爬到楼顶呢？ 注意：给定 n 是一个正整数。 示例 1： 12345输入： 2输出： 2解释： 有两种方法可以爬到楼顶。1. 1 阶 + 1 阶2. 2 阶 进阶：剑指offer超级爬楼梯 f[0]=1\\f[1]=1\\f[2]=2\\ f(n) = \sum_{i=1}^n f(i)55. 跳跃游戏 给定一个非负整数数组 nums ，你最初位于数组的 第一个下标 。 数组中的每个元素代表你在该位置可以跳跃的最大长度。 判断你是否能够到达最后一个下标。 示例 1： 123输入：nums = [2,3,1,1,4]输出：true解释：可以先跳 1 步，从下标 0 到达下标 1, 然后再从下标 1 跳 3 步到达最后一个下标。 思路：动态规划，关键点，计算每个位置能够跳到的最远位置 right = max(right, i+nums[i])1234567891011121314151617181920class Solution: """ 关键点，index+ value 计算每个位置能够到达的最远位置 """ def canJump(self, nums): count = len(nums) flag = [False] * count flag[0] = True i = 0 right_most = 0 while i &lt; count: if i &lt;= right_most: right_most = max(right_most, i+nums[i]) if right_most &gt;= count - 1: return True i += 1 return False 279. 完全平方数 给定正整数 n，找到若干个完全平方数（比如 1, 4, 9, 16, ...）使得它们的和等于 n。你需要让组成和的完全平方数的个数最少。 给你一个整数 n ，返回和为 n 的完全平方数的 最少数量 。 完全平方数 是一个整数，其值等于另一个整数的平方；换句话说，其值等于一个整数自乘的积。例如，1、4、9 和 16 都是完全平方数，而 3 和 11 不是。 示例 1： 123输入：n = 12输出：3 解释：12 = 4 + 4 + 4 思路：动态规划，和前面哈希的题目优点类似。 12345678910111213141516171819202122import mathimport sysclass Solution: """ 动态规划 """ def numSquares(self, n: int) -&gt; int: square_nums = [i**2 for i in range(int(math.sqrt(n))+1)] dp = [sys.maxsize] * (n+1) dp[0] = 0 for i in range(1, n+1): # 从前到后遍历完全平方数 for square in square_nums: # 完全平方数大于目标和，直接跳过 if i &lt; square: break # 更新当前所需要完全平方数最小值。 dp[i] = min(dp[i], dp[i-square]+1) return dp[-1] 322. 零钱兑换 给定不同面额的硬币 coins 和一个总金额 amount。编写一个函数来计算可以凑成总金额所需的最少的硬币个数。如果没有任何一种硬币组合能组成总金额，返回 -1。 你可以认为每种硬币的数量是无限的。 示例 1： 123输入：coins = [1, 2, 5], amount = 11输出：3 解释：11 = 5 + 5 + 1 123456789101112class Solution: def coinChange(self, coins, amount): import sys n = len(coins) dp = [sys.maxsize] * (amount+1) dp[0] = 0 for i in coins: for j in range(i, amount+1): dp[j] = min(dp[j], dp[j-i]+1) return dp[amount] if dp[amount] != sys.maxsize else -1 编辑距离 编辑距离](https://leetcode-cn.com/problems/edit-distance/) 给你两个单词 word1 和 word2，请你计算出将 word1 转换成 word2 所使用的最少操作数 。 你可以对一个单词进行如下三种操作： 插入一个字符 删除一个字符 替换一个字符 示例 1： 123456输入：word1 = &quot;horse&quot;, word2 = &quot;ros&quot;输出：3解释：horse -&gt; rorse (将 &apos;h&apos; 替换为 &apos;r&apos;)rorse -&gt; rose (删除 &apos;r&apos;)rose -&gt; ros (删除 &apos;e&apos;) 思路：动态规划，关键点，空字符串是能够匹配的。 1、定义二维数组，dp，$dp[i][j]$表示word1中前i个字符换到word2中前j个字符需要的最短路径。 2、初始化，当word1 或者word2位空串的时候，需要插入对应的元素数。 3、状态转移方程 其实对于编辑距离问题，可以将其中一个字符固定，只对另一个进行操作。因为在word1中增加一个字符和在word2中删除一个字符其实是等价的。 增，相当于word1不动，word2删除一个。 $dp[i][j]=dp[i][j-1] + 1$ 删，word1删除一个，word2不动。$dp[i][j] =dp[i-1][j]+1$ 改，word1和word2都不动。$dp[i][j]=dp[i-1][j-1]+1$ 所以最短编辑距离为 dp[i][j] = min(dp[i][j-1], dp[i-1][j], dp[i-1][j-1]) + 1 123456789101112131415161718192021class Solution: def minDistance(self, word1: str, word2: str): m = len(word1) n = len(word2) distance = [([0] * (n+1)) for i in range(m+1)] # 初始化 for i in range(m+1): distance[i][0] = i for i in range(n+1): distance[0][i] = i for i in range(1, m+1): for j in range(1, n+1): if word1[i-1] == word2[j-1]: distance[i][j] = distance[i-1][j-1] else: distance[i][j] = min(distance[i-1][j], distance[i][j-1], distance[i-1][j-1]) + 1 return distance[m][n] 买卖股票121. 买卖股票的最佳时机 给定一个数组 prices ，它的第 i 个元素 prices[i] 表示一支给定股票第 i 天的价格。 你只能选择 某一天 买入这只股票，并选择在 未来的某一个不同的日子 卖出该股票。设计一个算法来计算你所能获取的最大利润。 返回你可以从这笔交易中获取的最大利润。如果你不能获取任何利润，返回 0 。 示例 1： 1234输入：[7,1,5,3,6,4]输出：5解释：在第 2 天（股票价格 = 1）的时候买入，在第 5 天（股票价格 = 6）的时候卖出，最大利润 = 6-1 = 5 。 注意利润不能是 7-1 = 6, 因为卖出价格需要大于买入价格；同时，你不能在买入前卖出股票。 思路：只买一次，然后卖出。所以选择最低点min_price买入，然后在低点之后的搞点卖出就行了。。 1234567891011121314class Solution: def maxProfit(self, prices): max_profit = 0 min_price = prices[0] for i in range(len(prices)): if prices[i] &lt; min_price: min_price = prices[i] if prices[i] - min_price &gt; max_profit: max_profit = prices[i] - min_price return max_profit 122. 买卖股票的最佳时机 II 给定一个数组，它的第 i 个元素是一支给定股票第 i 天的价格。 设计一个算法来计算你所能获取的最大利润。你可以尽可能地完成更多的交易（多次买卖一支股票）。 注意：你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。 示例 1: 1234输入: [7,1,5,3,6,4]输出: 7解释: 在第 2 天（股票价格 = 1）的时候买入，在第 3 天（股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5-1 = 4 。 随后，在第 4 天（股票价格 = 3）的时候买入，在第 5 天（股票价格 = 6）的时候卖出, 这笔交易所能获得利润 = 6-3 = 3 。 思路一：贪心，找到上升的趋势，计算结果。 123456789class Solution: def maxProfit(self, prices: List[int]) -&gt; int: max_profit = 0 for i in range(1, len(prices)): max_profit += max(0, prices[i]-prices[i-1]) return max_profit 309. 最佳买卖股票时机含冷冻期 难度中等698收藏分享切换为英文接收动态反馈 给定一个整数数组，其中第 i 个元素代表了第 i 天的股票价格 。 设计一个算法计算出最大利润。在满足以下约束条件下，你可以尽可能地完成更多的交易（多次买卖一支股票）: 你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。 卖出股票后，你无法在第二天买入股票 (即冷冻期为 1 天)。 示例: 123输入: [1,2,3,0,2]输出: 3 解释: 对应的交易状态为: [买入, 卖出, 冷冻期, 买入, 卖出] 思路：由于存在冷冻期，所以有三种状态 $f[i][0]$表示当前拥有一支股票，对应的最大累计收益 $f[i][1]$表示当前不持有任何股票且处在冷冻期对应的最大收益 $f[i][2]$表示当前不持有任何股票且没有处在冷冻期对应的最大收益 注意f表示是当天收盘结果。 对于一个当天结束持有股票，其持有的股票可以是前一天持有的没有卖出，也可以是当天买入的(前一天为非冷冻期)，因此最大收益$f[i][0]$为 f[i][0]=max(f[i-1][0], f[i-1][2] - prices[i])前一天有股票，今天卖出了，因此最大收益$f[i][1]$为 f[i][1] = f[i][0] + prices[i]i-1天卖出股票或者i-2天股票为空，都能使当天不持有任何股票，其最大收益$f[i][2]$为： f[i][2] = max(f[i-1][1], f[i-2][2])最后求三种状态的最大值，由于空仓收益更高，其实看两种状态就行了。 max\_profit=max(f[n-1][1], f[n-1][2])12345678910111213141516171819202122232425262728293031class Solution: """ 动态规划：一共三种状态 1、当前持有一直股票 ， 有股票且没有卖 2、当前不持有股票且处在冷冻期 3、当前不持有股票且不处在冷冻期，即没有股票或者有股票卖了 """ def maxProfit(self, prices): n = len(prices) if n == 0: return 0 f = [[0] * 3 for i in range(n)] f[0][0] = -prices[0] for i in range(1, n): # 关键点i表示今天结束的状态，也就是买入卖出操作执行结束 # 前一天有股票, 今天不属于冷冻期 # 当前最大收益的状态时卖出或者保持不变 f[i][0] = max(f[i-1][0], f[i-1][2] - prices[i]) # 当前一天不持有股票且处在冷冻期 f[i][1] = f[i-1][0] + prices[i] # 注意冷冻期是指 # 当前不持有股票且不再冷冻期，有以下几种情况 # 前一天有股票，且没有卖 # 股票已经卖完了 f[i][2] = max(f[i-1][1], f[i-1][2]) return max(f[n-1][1], f[n-1][2]) 相似题目： 188. 买卖股票的最佳时机 IV 小偷问题198. 打家劫舍 你是一个专业的小偷，计划偷窃沿街的房屋。每间房内都藏有一定的现金，影响你偷窃的唯一制约因素就是相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警。 给定一个代表每个房屋存放金额的非负整数数组，计算你 不触动警报装置的情况下 ，一夜之内能够偷窃到的最高金额。 1234输入：[1,2,3,1]输出：4解释：偷窃 1 号房屋 (金额 = 1) ，然后偷窃 3 号房屋 (金额 = 3)。 偷窃到的最高金额 = 1 + 3 = 4 。 12345678910111213141516171819class Solution: """和309一个类型的题目 判断每个状态偷还是不偷 """ def rob(self, nums): n = len(nums) if n == 0 or n == 1: return sum(nums) f = [[0] * 2 for _ in range(n)] f[0][0] = 0 # 不偷 f[0][1] = nums[0] # 偷 for i in range(1, n): f[i][0] = max(f[i-1][1], f[i-1][0]) f[i][1] = f[i-1][0] + nums[i] return max(f[n-1][0], f[n-1][1]) 213. 打家劫舍 II 你是一个专业的小偷，计划偷窃沿街的房屋，每间房内都藏有一定的现金。这个地方所有的房屋都 围成一圈 ，这意味着第一个房屋和最后一个房屋是紧挨着的。同时，相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警 。 给定一个代表每个房屋存放金额的非负整数数组，计算你 在不触动警报装置的情况下 ，能够偷窃到的最高金额。 示例 1： 123输入：nums = [2,3,2]输出：3解释：你不能先偷窃 1 号房屋（金额 = 2），然后偷窃 3 号房屋（金额 = 2）, 因为他们是相邻的。 337. 打家劫舍 III 在上次打劫完一条街道之后和一圈房屋后，小偷又发现了一个新的可行窃的地区。这个地区只有一个入口，我们称之为“根”。 除了“根”之外，每栋房子有且只有一个“父“房子与之相连。一番侦察之后，聪明的小偷意识到“这个地方的所有房屋的排列类似于一棵二叉树”。 如果两个直接相连的房子在同一天晚上被打劫，房屋将自动报警。 计算在不触动警报的情况下，小偷一晚能够盗取的最高金额。 示例 1: 12345678910输入: [3,2,3,null,3,null,1] 3 / \ 2 3 \ \ 3 1输出: 7 解释: 小偷一晚能够盗取的最高金额 = 3 + 3 + 1 = 7. 123456789101112131415161718192021class Solution: """ 思路一：dfs+深度优先计算 """ def rob(self, root) -&gt; int: def dfs(root): if not root: return 0, 0 # 投、不偷 left = dfs(root.left) right = dfs(root.right) rob_value = left[1] + right[1] + root.val skip_value = max(left[0], left[1]) + max(right[0], right[1]) return [rob_value, skip_value] value = dfs(root) return max(value[0], value[1]) 矩阵问题240. 搜索二维矩阵 II 编写一个高效的算法来搜索 *m* x *n* 矩阵 matrix 中的一个目标值 target 。该矩阵具有以下特性： 每行的元素从左到右升序排列。 每列的元素从上到下升序排列。 示例 1： 12输入：matrix = [[1,4,7,11,15],[2,5,8,12,19],[3,6,9,16,22],[10,13,14,17,24],[18,21,23,26,30]], target = 5输出：true 思路：和剑指offer二维数组查找差不多。选择右上或者左下遍历。以右上角为例，对于矩阵中的点$matrix[i][j]$，其左上角的点的值都小于$matrix[i][j]$，选择左下角和右上角的目的是可以沿着边走，找到最后的结果。 12345678910111213141516171819202122232425import numpy as npclass Solution: """ 剑指offer原题：二维数组查找 选择右上角往左下角移动，右上角和左下角的特点为 """ def searchMatrix(self, matrix, target): matrix = np.array(matrix) m = matrix.shape[0] n = matrix.shape[1] flag = False i, j = 0, n-1 while i &lt; m and j &gt;= 0: if matrix[i][j] == target: flag = True break elif matrix[i][j] &lt; target: i += 1 else: j -= 1 return flag 221. 最大正方形 难度中等701收藏分享切换为英文接收动态反馈 在一个由 &#39;0&#39; 和 &#39;1&#39; 组成的二维矩阵内，找到只包含 &#39;1&#39; 的最大正方形，并返回其面积。 示例 1： 12输入：matrix = [[&quot;1&quot;,&quot;0&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;],[&quot;1&quot;,&quot;0&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;],[&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;],[&quot;1&quot;,&quot;0&quot;,&quot;0&quot;,&quot;1&quot;,&quot;0&quot;]]输出：4 思路：构建状态矩阵，$dp[i][j]$表示以$(i,j)$为右下角且只包含1的正方形边长最大值。 对于每个位置$(i,j)$，如果该位置的值为0，则$dp[i][j]=0$，因为当前位置不可能出现在1组成的正方形中 如果当前位置是1，状态方程为 dp[i][j]=min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1]) + 1 12345678910111213141516171819202122class Solution: def maximalSquare(self, matrix) -&gt; int: if len(matrix) == 0 or len(matrix[0]) == 0: return 0 max_len = 0 row, col = len(matrix), len(matrix[0]) dp = [[0] * col for _ in range(row)] for i in range(row): for j in range(col): if matrix[i][j] == '1': if i == 0 or j == 0: dp[i][j] = 1 else: dp[i][j] = min(dp[i][j-1], dp[i-1][j-1], dp[i-1][j]) + 1 max_len = max(dp[i][j], max_len) max_square = max_len * max_len return max_square 139. 单词拆分 给定一个非空字符串 s 和一个包含非空单词的列表 wordDict，判定 s 是否可以被空格拆分为一个或多个在字典中出现的单词。 说明： 拆分时可以重复使用字典中的单词。 你可以假设字典中没有重复的单词。 示例 1： 123输入: s = &quot;leetcode&quot;, wordDict = [&quot;leet&quot;, &quot;code&quot;]输出: true解释: 返回 true 因为 &quot;leetcode&quot; 可以被拆分成 &quot;leet code&quot;。 思路： 1、创建一个dp，初始化dp[0] = True，表示串空且合法 2、对于字符串$s[0…i-1]$，我们只需要判断前面的单词和最后一个单词是否合法，假设分割点为$j$，因此只需要判断$s[0:j]$和$s[j+1:i-1]$是否合法就行了，因此状态转移方程为 dp[i]=dp[j] \quad \& \quad s[j:i]\quad in \quad word1234567891011121314class Solution: # 动态规划 def wordBreak(self, s: str, wordDict): word_set = set(wordDict) length = len(s) flag = [False] * (length+1) flag[0] = True # 空串为合法 for i in range(1, length+1): for j in range(0, i): if s[j: i] in word_set and flag[j]: flag[i] = True return flag[length] 152. 乘积最大子数组 给你一个整数数组 nums ，请你找出数组中乘积最大的连续子数组（该子数组中至少包含一个数字），并返回该子数组所对应的乘积。 123输入: [2,3,-2,4]输出: 6解释: 子数组 [2,3] 有最大乘积 6。 1234567891011121314class Solution: """ 两个数组，最大值和最小值 """ def maxProduct(self, nums): n = len(nums) max_res = [1] * (n+1) min_res = [1] * (n+1) for i in range(1, n+1): max_res[i] = max(max_res[i-1] * nums[i-1], min_res[i-1] * nums[i-1], nums[i-1]) min_res[i] = min(max_res[i-1] * nums[i-1], min_res[i-1] * nums[i-1], nums[i-1]) return max(max_res[1:]) 背包问题416. 分割等和子集 给定一个只包含正整数的非空数组。是否可以将这个数组分割成两个子集，使得两个子集的元素和相等。 注意: 每个数组中的元素不会超过 100 数组的大小不会超过 200 示例 1: 12345输入: [1, 5, 11, 5]输出: true解释: 数组可以分割成 [1, 5, 5] 和 [11]. 思路：对于这个问题，如果数组长度小于2，无法分成两个数组，如果数组和sum为奇数，那么一定无法分成两个，如果最大元素max_num &gt; sum//2，也无法分成两个相等的数组。 创建二维数组dp，包含n行，target+1列，其中$dp[i][j]$表示从数组$[0, i]$下标范围内选择若干个正整数，是否存在一种方案使得被选的正整数等于j。初始化时$dp$元素全部为false。 边界条件 $dp[i][0]=true$，不选择任何正整数或者选择的正整数等于0 $dp[0][nums[i]]=true$，当只有一个正整数可以选择时。 在确定$dp[i][j]$的时候，需要确认下面两种情况。 1、$j\geq nums[i]$时，对于当前的数字$nums[i]$，有两种情况，可以取，可以不取，两种情况只要有一种为$true$，就有$dp[i][j]=true$。 不选$nums[i]$，$dp[i][j]=dp[i-1][j]$ 选择$nums[i]$, $dp[i][j]=dp[i-1][j-nums[i]]$ 2、对于$j &lt; nums[i]$，$dp[i][j]=dp[i-1][j]$ 123456789101112131415161718192021222324252627282930class Solution: def canPartition(self, nums: List[int]) -&gt; bool: n = len(nums) if n &lt; 2: return False total = sum(nums) maxNum = max(nums) if total &amp; 1: return False target = total // 2 if maxNum &gt; target: return False dp = [[0] * (target + 1) for _ in range(n)] for i in range(n): # 如果不选择任何整数，则被选择的正整数等于0 dp[i][0] = True dp[0][nums[0]] = True for i in range(1, n): num = nums[i] for j in range(1, target + 1): if j &gt;= num: dp[i][j] = dp[i - 1][j] | dp[i - 1][j - num] else: dp[i][j] = dp[i - 1][j] return dp[n - 1][target] 回溯回溯算法实际上一个类似枚举的搜索尝试过程，主要是在搜索尝试过程中寻找问题的解，当发现已不满足求解条件时，就 “回溯” 返回，尝试别的路径。回溯法是一种选优搜索法，按选优条件向前搜索，以达到目标。但当探索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术为回溯法，而满足回溯条件的某个状态的点称为 “回溯点”。许多复杂的，规模较大的问题都可以使用回溯法，有“通用解题方法”的美称。 回溯算法的基本思想是：从一条路往前走，能进则进，不能进则退回来，换一条路再试。 一般采用dfs 最优解17. 电话号码的字母组合 给定一个仅包含数字 2-9 的字符串，返回所有它能表示的字母组合。答案可以按 任意顺序 返回。 给出数字到字母的映射如下（与电话按键相同）。注意 1 不对应任何字母。 12输入：digits = "23"输出：["ad","ae","af","bd","be","bf","cd","ce","cf"] 思路：回溯，dfs 关键在于终止条件，以及如何继续想下遍历 1234567891011121314151617181920212223242526272829303132333435class Solution: """ 常规题，采用dfs """ def letterCombinations(self, digits: str): num_dict = &#123;'2': 'abc', '3': 'def', '4': 'ghi', '5': 'jkl', '6': 'mno', '7': 'pqrs', '8': 'tuv', '9': 'wxyz'&#125; res = [] n = len(digits) if n == 0: return res str_list = [num_dict[i] for i in digits] def dfs(str_list, s, cur): nonlocal res if cur == n: res.append(s) else: for c in str_list[cur]: s += c dfs(str_list, s, cur+1) s = s[:cur] dfs(str_list, "", 0) return res 22. 括号生成 数字 n 代表生成括号的对数，请你设计一个函数，用于能够生成所有可能的并且 有效的 括号组合。 示例： 12输入：n = 3输出：[&quot;((()))&quot;,&quot;(()())&quot;,&quot;(())()&quot;,&quot;()(())&quot;,&quot;()()()&quot;] 123456789101112131415161718class Solution: def generateParenthesis(self, n: int): res = [] def dfs(str, left, right): if left == 0 and right == 0: res.append(str) if right &lt; left: return if left &gt; 0: dfs(str+'(', left-1, right) if right &gt; 0: dfs(str+')', left, right-1) dfs("", n, n) return res 39. 组合总和 给定一个无重复元素的数组 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。 candidates 中的数字可以无限制重复被选取。 说明： 所有数字（包括 target）都是正整数。解集不能包含重复的组合。示例 1： 123456输入：candidates = [2,3,6,7], target = 7,所求解集为：[ [7], [2,2,3]] 思路：dfs，不断遍历不同的情况。 关键点： 终止条件 遍历是是否能够重复选取 1234567891011121314151617181920class Solution: def __init__(self): self.res_all = [] def dfs(self, candiates, res, target): if sum(res) == target: self.res_all.append(res) return elif sum(res) &gt; target: return for i in range(len(candiates)): self.dfs(candiates[i:], res + [candiates[i]], target) def combinationSum(self, candidates, target): self.dfs(candidates,[], target) return self.res_all 排列问题46. 全排列 给定一个 没有重复 数字的序列，返回其所有可能的全排列。 示例: 12345678910输入: [1,2,3]输出:[ [1,2,3], [1,3,2], [2,1,3], [2,3,1], [3,1,2], [3,2,1]] 123456789101112131415161718class Solution: def permute(self, nums): m = len(nums) visited = [False] * (m+1) res = [] def dfs(linklist, n): if n == 0: res.append(linklist) for i in range(1, m+1): if not visited[i]: visited[i] = True dfs(linklist + [nums[i-1]], n - 1) visited[i] = False dfs([], m) return res 78. 子集 给你一个整数数组 nums ，数组中的元素 互不相同 。返回该数组所有可能的子集（幂集）。 解集 不能 包含重复的子集。你可以按 任意顺序 返回解集。 示例 1： 12输入：nums = [1,2,3]输出：[[],[1],[2],[1,2],[3],[1,3],[2,3],[1,2,3]] 思路：回溯 1234567891011121314151617181920212223242526class Solution: """ 第一反应是回溯 """ def subsets(self, nums): count = len(nums) res_all = [] def dfs(data, target, res): if target == 0: res_all.append(res.copy()) return for i in range(len(data)): res.append(data[i]) dfs(data[i+1:], target-1, res) res.pop() res_all.append([]) for i in range(1, count+1): dfs(nums, i, []) return res_all 494. 目标和 给定一个非负整数数组，a1, a2, …, an, 和一个目标数，S。现在你有两个符号 + 和 -。对于数组中的任意一个整数，你都可以从 + 或 -中选择一个符号添加在前面。 返回可以使最终数组和为目标数 S 的所有添加符号的方法数。 示例： 1234567891011输入：nums: [1, 1, 1, 1, 1], S: 3输出：5解释：-1+1+1+1+1 = 3+1-1+1+1+1 = 3+1+1-1+1+1 = 3+1+1+1-1+1 = 3+1+1+1+1-1 = 3一共有5种方法让最终目标和为3。 12345678910111213141516171819202122232425class Solution: """ 思路：dfs+剪枝，Java版通过，python版超时 """ def findTargetSumWays(self, nums, S): count = 0 n = len(nums) def dfs(nums, start, target, S): nonlocal count, n if start == n: if target == S: count += 1 else: if start &lt; len(nums): dfs(nums, start+1, target+nums[start], S) dfs(nums, start+1, target-nums[start], S) if S &gt; sum(nums) or S &lt; -sum(nums): return count else: dfs(nums, 0, 0, S) return count 给定一个二维网格和一个单词，找出该单词是否存在于网格中。 单词必须按照字母顺序，通过相邻的单元格内的字母构成，其中“相邻”单元格是那些水平相邻或垂直相邻的单元格。同一个单元格内的字母不允许被重复使用。 双指针11.盛水最多的容器 给你 n 个非负整数 a1，a2，...，a``n，每个数代表坐标中的一个点 (i, ai) 。在坐标内画 n 条垂直线，垂直线 i 的两个端点分别为 (i, ai) 和 (i, 0) 。找出其中的两条线，使得它们与 x 轴共同构成的容器可以容纳最多的水。 1234输入：[1,8,6,2,5,4,8,3,7]输出：49 解释：图中垂直线代表输入数组 [1,8,6,2,5,4,8,3,7]。在此情况下，容器能够容纳水（表示为蓝色部分）的最大值为 49。https://leetcode-cn.com/problems/container-with-most-water/ 思路：这是一道典型的双指针题目，题目意思是利用从数组中选择两个位置，当做挡板，看中间能够容纳多少水。所以思路很简单，建立一个双指针，从左右往中间移动，每次移动左右指针中值较小的那个，每次更新的时候判断面积是否大于最大面积，如果大于，就更新。 12345678910111213141516class Solution: def maxArea(self, height) -&gt; int: n = len(height) max_area = 0 l, r = 0, n-1 while l &lt; r: area = min(height[l], height[r]) * (r-l) max_area = max(area, max_area) if height[l] &lt;= height[r]: l += 1 else: r -= 1 return max_area 15. 三数之和 给你一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？请你找出所有和为 0 且不重复的三元组。 注意：答案中不可以包含重复的三元组。 12输入：nums = [-1,0,1,2,-1,-4]输出：[[-1,-1,2],[-1,0,1]] 思路：排序+双指针变体 设置三个指针，首先将数组从小到大进行排序，然后从前往后一次选择一个数作为三元组的第一个数，然后设置两个左右指针，判断节点是否小于0，如果小于0，左指针往右移动，如果大于0，右指针往左移动。每一次保存上一次满足条件的结果，然后下一次满足条件时与上一次结果对比，如果不一样，保存结果。 123456789101112131415161718192021222324252627282930313233class Solution: def threeSum(self, nums): nums.sort() count = len(nums) result = [] # 保留上一次结果，做去重使用 first = -1 second = -1 third = -1 for i in range(count-1): j = i + 1 # 左指针 k = count - 1 while j &lt; k: target = nums[i] + nums[j] + nums[k] if target &lt; 0: j += 1 elif target &gt; 0: k -= 1 else: # 判断是否已经存在改结果 if third == -1 or (nums[j] &gt; nums[second] or nums[k] &lt; nums[third] or nums[i] &gt; nums[first]): # 第一次满足条件 result.append([nums[i], nums[j], nums[k]]) first = i second = j third = k j += 1 return result 19. 删除链表的倒数第 N 个结点 给你一个链表，删除链表的倒数第 n 个结点，并且返回链表的头结点。 12输入：head = [1,2,3,4,5], n = 2输出：[1,2,3,5] 思路：双指针，一个先向后移动n步，然后两个指针一起移动。当前面一个移动到第n个时，后面的指针则指向第k个结点。 12345678910111213141516171819202122232425262728293031def get_length(head): # 获取链表长度 p = head count = 0 while p is not None: count += 1 p = p.next return countclass Solution: def removeNthFromEnd(self, head, n): m = get_length(head) # 返回头结点 if m == n: return head.next k = m - n - 1 p = head for i in range(k): p = p.next # 删除第n个结点 q = p.next if q is not None: p.next = q.next else: p.next = q return head 31. 下一个排列 实现获取 下一个排列 的函数，算法需要将给定数字序列重新排列成字典序中下一个更大的排列。 如果不存在下一个更大的排列，则将数字重新排列成最小的排列（即升序排列）。 必须 原地 修改，只允许使用额外常数空间。 示例： 12输入：nums = [1,2,3]输出：[1,3,2] 思路：双指针 注意到下一个排列总是比当前排列要大，除非该排列已经是最大的排列。我们希望找到一种方法，能够找到一个大于当前序列的新序列，且变大的幅度尽可能小。具体地： 我们需要将一个左边的「较小数」与一个右边的「较大数」交换，以能够让当前排列变大，从而得到下一个排列。 从有往左遍历。找到第一个nums[i] &lt; nums[i+1]的数，此时可以将数组分成两个部分，nums[0, i], nums[i+1, n-1]。 可以知道此时nums[i+1, n-1]此时是降序。交换nums[i]和nums[j]，然后将nums[i+1,n-1]进行升序排序就能得到结果 1234567891011121314151617181920212223242526272829class Solution: def nextPermutation(self, nums) -&gt; None: """ Do not return anything, modify nums in-place instead. """ i = len(nums) - 2 while i &gt;= 0: if nums[i] &lt; nums[i+1]: break i -= 1 if i &lt; 0: nums.reverse() else: j = len(nums) - 1 while j &gt; i: if nums[j] &gt; nums[i]: nums[j], nums[i] = nums[i], nums[j] break j -= 1 left = i + 1 right = len(nums) - 1 while left &lt; right: nums[left], nums[right] = nums[right], nums[left] left += 1 right -= 1 return nums 75. 颜色分类 难度中等802收藏分享切换为英文接收动态反馈 给定一个包含红色、白色和蓝色，一共 n 个元素的数组，原地对它们进行排序，使得相同颜色的元素相邻，并按照红色、白色、蓝色顺序排列。 此题中，我们使用整数 0、 1 和 2 分别表示红色、白色和蓝色。 示例 1： 12输入：nums = [2,0,2,1,1,0]输出：[0,0,1,1,2,2] 思路：双指针 1234567891011121314151617181920212223class Solution: """ 思路一：sort函数 思路二：单指针，第一次遍历，放0的位置，第二次遍历，放一的位置 思路二：双指针，如果是0异动到前面，2移动到后面 """ def sortColors(self, nums): """ Do not return anything, modify nums in-place instead. """ length = len(nums) p, q = 0, length - 1 i = 0 while i &lt;= q: if nums[i] == 0: nums[p], nums[i] = nums[i], nums[p] p += 1 if nums[i] == 2: nums[q], nums[i] = nums[i], nums[q] q -= 1 i += 1 581. 最短无序连续子数组 难度中等493收藏分享切换为英文接收动态反馈 给你一个整数数组 nums ，你需要找出一个 连续子数组 ，如果对这个子数组进行升序排序，那么整个数组都会变为升序排序。 请你找出符合题意的 最短 子数组，并输出它的长度。 示例 1： 123输入：nums = [2,6,4,8,10,9,15]输出：5解释：你只需要对 [6, 4, 8, 10, 9] 进行升序排序，那么整个表都会变为升序排序。 思路：排序+双指针 首先使用快排对结果进行排序，然后设置头指针，和尾指针 头指针，找到第一个和target位置不一样的元素。 尾指针，找到最后一个和target位置不一样的元素。 12345678910111213141516171819class Solution: def findUnsortedSubarray(self, nums): target = sorted(nums) start = len(nums) end = 0 max_len = 0 for i in range(len(nums)): if nums[i] != target[i]: start = min(i, start) end = max(i, end) if start &gt; end: max_len = 0 else: max_len = end - start + 1 return max_len 移动数组283. 移动零 给定一个数组 nums，编写一个函数将所有 0 移动到数组的末尾，同时保持非零元素的相对顺序。 12345678910111213141516171819class Solution: """ 思路一：将 """ def moveZeroes(self, nums): """ Do not return anything, modify nums in-place instead. """ index = 0 count = len(nums) for i in range(count): if nums[i] != 0: nums[index] = nums[i] index += 1 while index &lt; count: nums[index] = 0 index += 1 return nums 647. 回文子串 给定一个字符串，你的任务是计算这个字符串中有多少个回文子串。 具有不同开始位置或结束位置的子串，即使是由相同的字符组成，也会被视作不同的子串。 示例 1： 123输入：&quot;abc&quot;输出：3解释：三个回文子串: &quot;a&quot;, &quot;b&quot;, &quot;c&quot; 示例 2： 123输入：&quot;aaa&quot;输出：6解释：6个回文子串: &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;aa&quot;, &quot;aa&quot;, &quot;aaa&quot; 思路：双指针，以每个字符作为中心节点，从左右往两边扩展， 123456789101112131415class Solution: """从每一个中间往两边遍历""" def countSubstrings(self, s: str): ans = 0 n = len(s) for i in range(2*n): l = int(i/2) r = l + i %2 while l &gt;= 0 and r &lt; n and s[l] == s[r]: ans += 1 l -= 1 r += 1 return ans 快慢指针主要可以用来判断链表是否存在环，设置两个指针，快指针fast和慢指针slow。fast指针每次移动两步，slow指针每次移动一步。如果存在换，那么他们一定会相遇。 141. 环形链表 给定一个链表，判断链表中是否有环。 如果链表中有某个节点，可以通过连续跟踪 next 指针再次到达，则链表中存在环。 为了表示给定链表中的环，我们使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。 如果 pos 是 -1，则在该链表中没有环。注意：pos 不作为参数进行传递，仅仅是为了标识链表的实际情况。 如果链表中存在环，则返回 true 。 否则，返回 false 。 进阶： 你能用 O(1)（即，常量）内存解决此问题吗？ 示例 1： 123输入：head = [3,2,0,-4], pos = 1输出：true解释：链表中有一个环，其尾部连接到第二个节点。 思路：设置快慢指针，相交则说明有环。 12345678910111213141516171819202122class Solution: # 基础题，以前做过，快慢指针 def hasCycle(self, head): if not head or not head.next: return False low = head high = head.next flag = False while low and high: if low == high: return True low = low.next high = high.next if high: high = high.next return False 142.环形链表 II 给定一个链表，返回链表开始入环的第一个节点。 如果链表无环，则返回 null。 为了表示给定链表中的环，我们使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。 如果 pos 是 -1，则在该链表中没有环。注意，pos 仅仅是用于标识环的情况，并不会作为参数传递到函数中。 说明：不允许修改给定的链表。 进阶： 你是否可以使用 O(1) 空间解决此题？ 示例 1： 123输入：head = [3,2,0,-4], pos = 1输出：返回索引为 1 的链表节点解释：链表中有一个环，其尾部连接到第二个节点。 1234567891011121314151617181920212223242526272829303132class Solution: def detectCycle(self, head): if not head: return None point_slow = head point_fast = head count = 0 while point_slow and point_fast: if point_slow == point_fast and count != 0: break point_slow = point_slow.next point_fast = point_fast.next if point_fast: point_fast = point_fast.next count += 1 # 如果不存在环 if not point_slow or not point_fast: return None point_fast = head while point_fast != point_slow: point_fast = point_fast.next point_slow = point_slow.next return point_fast 滑动窗口​ 滑动窗口问题算是双指针的一种变形 无重复字符的最长子串 1234给定一个字符串，请你找出其中不含有重复字符的最长子串的长度。示例 1:输入: s = &quot;abcabcbb&quot;输出: 3 思路：设置首尾指针，都从0开始，然后尾指针end_index每向后移动一位，判断当前的字符是否在滑窗里面，如果不在 将尾指针字符加入滑窗，如果在，头指针向后移动一位，加入尾指针，然后更新滑窗的长度。如果当前长度大于最大长 ，则更新最长子串。 12345678910111213141516171819class Solution: def lengthOfLongestSubstring(self, s: str) -&gt; int: start_index = 0 end_index = start_index max_len = 0 n = len(s) while start_index &lt; n and end_index &lt; n: if end_index == 0: max_len = 1 if s[end_index] not in s[start_index: end_index]: end_index += 1 else: start_index += 1 if end_index-start_index &gt; max_len: max_len = end_index - start_index return max_len 239.滑动窗口最大值 123456789101112131415 给你一个整数数组 nums，有一个大小为 k 的滑动窗口从数组的最左侧移动到数组的最右侧。你只可以看到在滑动窗口内的 k 个数字。滑动窗口每次只向右移动一位。返回滑动窗口中的最大值。输入：nums = [1,3,-1,-3,5,3,6,7], k = 3输出：[3,3,5,5,6,7]解释：滑动窗口的位置 最大值[1 3 -1] -3 5 3 6 7 3 1 [3 -1 -3] 5 3 6 7 3 1 3 [-1 -3 5] 3 6 7 5 1 3 -1 [-3 5 3] 6 7 5 1 3 -1 -3 [5 3 6] 7 6 1 3 -1 -3 5 [3 6 7] 7 思路： 一、暴力求解，直接遍历每个元素组成的不同滑动窗口。超时 二、双端队列+滑动窗口欧 ​ 利用双端队列实现单调队列，每次里面保存最大的结果的索引，这样做的好处是即能取到对应的值，也可以通过index来判断当前元素距离队列头部保存index的距离，从而得到当前滑窗滑窗的大小。 123456789101112131415161718192021222324252627282930from collections import dequeclass Solution: """ 思路一：暴力求解，直接找出方框里面最大的值，基本超时 思路二：双端队列，其实就是利用双端队列实现最大堆，每次在结果里面保存可能最大的值 """ def maxSlidingWindow(self, nums, k): n = len(nums) q = deque() res = [] for i in range(k): if not q or nums[i] &lt;= nums[q[-1]]: q.append(i) else: while q and nums[i] &gt; nums[q[-1]]: q.pop() q.append(i) res.append(nums[q[0]]) for i in range(k, n): while q and nums[i] &gt; nums[q[-1]]: q.pop() q.append(i) if i - q[0] == k: q.popleft() res.append(nums[q[0]]) return res 76. 最小覆盖子串 难度困难987收藏分享切换为英文接收动态反馈 给你一个字符串 s 、一个字符串 t 。返回 s 中涵盖 t 所有字符的最小子串。如果 s 中不存在涵盖 t 所有字符的子串，则返回空字符串 &quot;&quot; 。 注意：如果 s 中存在这样的子串，我们保证它是唯一的答案。 示例 1： 12输入：s = &quot;ADOBECODEBANC&quot;, t = &quot;ABC&quot;输出：&quot;BANC&quot; 思路：滑动窗口 12345678910111213141516171819202122232425262728293031class Solution: def minWindow(self, s: str, t: str) -&gt; str: from collections import defaultdict hash_table = defaultdict(int) for c in t: hash_table[c] += 1 start = 0 end = 0 min_len = float('inf') # 包含子串的最小长度 count = 0 # 用于记录当前滑动窗口包含目标字符的个数，当count = len(t)，t为子串 res = '' while end &lt; len(s): # 当前元素在子串中，包含子串字符长度+1 # 同时对应子串个数应该-1，目的是为了防止同一个字符重复使用 if hash_table[s[end]] &gt; 0: count += 1 hash_table[s[end]] -= 1 end += 1 while count == len(t): if min_len &gt; end - start: min_len = end - start res = s[start: end] # 如果头部不在子串中，则包含子串长度-1 if hash_table[s[start]] == 0: count -= 1 hash_table[s[start]] += 1 start += 1 return res 239. 滑动窗口最大值 给你一个整数数组 nums，有一个大小为 k 的滑动窗口从数组的最左侧移动到数组的最右侧。你只可以看到在滑动窗口内的 k 个数字。滑动窗口每次只向右移动一位。 返回滑动窗口中的最大值。 示例 1： 1234567891011输入：nums = [1,3,-1,-3,5,3,6,7], k = 3输出：[3,3,5,5,6,7]解释：滑动窗口的位置 最大值--------------- -----[1 3 -1] -3 5 3 6 7 3 1 [3 -1 -3] 5 3 6 7 3 1 3 [-1 -3 5] 3 6 7 5 1 3 -1 [-3 5 3] 6 7 5 1 3 -1 -3 [5 3 6] 7 6 1 3 -1 -3 5 [3 6 7] 7 123456789101112131415161718192021222324252627282930313233from collections import dequeclass Solution: """ 思路一：暴力求解，直接找出方框里面最大的值，基本超时 思路二：双端队列，其实就是利用双端队列实现最大堆，每次在结果里面保存可能最大的值 """ def maxSlidingWindow(self, nums, k): n = len(nums) q = deque() res = [] # 保存前k个最大值 for i in range(k): if not q or nums[i] &lt;= nums[q[-1]]: q.append(i) else: while q and nums[i] &gt; nums[q[-1]]: q.pop() q.append(i) # 弹出第一个最大值 res.append(nums[q[0]]) for i in range(k, n): # 如果当前元素大于队列顶部元素，弹出，然后加入新的新的元素 while q and nums[i] &gt; nums[q[-1]]: q.pop() q.append(i) # 如果队列已经满了，弹出 if i - q[0] == k: q.popleft() # 每次遍历时加入最大结果 res.append(nums[q[0]]) return res 类似题目： 无重复字符的最长子串 串联所有单词的子串 最小覆盖子串 至多包含两个不同字符的最长子串 长度最小的子数组 滑动窗口最大值 字符串的排列 最小区间 最小窗口子序列 栈括号问题借助栈的特性，来判断括号是否合法 20. 有效的括号 给定一个只包括 ‘(‘，’)’，’{‘，’}’，’[‘，’]’ 的字符串 s ，判断字符串是否有效。 有效字符串需满足： 左括号必须用相同类型的右括号闭合。 左括号必须以正确的顺序闭合。 思路：借助辅助栈，如果当前字符是左括号，入栈。如果当前字符是右括号，出栈。如果栈空，则表明都是合法的，如果非空，表示不合法。 123456789101112131415class Solution: def isValid(self, s: str) -&gt; bool: stack = list() lens = len(s) for i in range(lens): if len(stack) == 0: stack.append(s[i]) else: if (s[i] == ')' and stack[-1] == '(') or (s[i] == '&#125;' and stack[-1] == '&#123;') or \ (s[i] == ']' and stack[-1] == '['): stack.pop() else: stack.append(s[i]) return len(stack) == 0 32. 最长有效括号 给你一个只包含 &#39;(&#39; 和 &#39;)&#39; 的字符串，找出最长有效（格式正确且连续）括号子串的长度。 示例： 123输入：s = &quot;(()&quot;输出：2解释：最长有效括号子串是 &quot;()&quot; 思路：借助栈，由于字符串只包含两种字符，因此对于左括号进展，对于右括号，出栈时，当前元素和栈顶元素的差则为有效括号的长度，不断更新有效括号，就能得到最后结果。 123456789101112131415161718192021class Solution: def longestValidParentheses(self, s: str) -&gt; int: stack = [] max_len = 0 length = 0 if len(s) == 0: return 0 for i in range(len(s)): if not stack or s[i] == '(' or s[stack[-1]] == ')': stack.append(i) else: stack.pop() length = i - (stack[-1] if stack else -1) max_len = max(max_len, length) return max_len 56. 合并区间 以数组 intervals 表示若干个区间的集合，其中单个区间为 intervals[i] = [starti, endi] 。请你合并所有重叠的区间，并返回一个不重叠的区间数组，该数组需恰好覆盖输入中的所有区间。 示例 1： 123输入：intervals = [[1,3],[2,6],[8,10],[15,18]]输出：[[1,6],[8,10],[15,18]]解释：区间 [1,3] 和 [2,6] 重叠, 将它们合并为 [1,6]. 思路：排序+栈 123456789101112131415161718class Solution: """ 借助栈 """ def merge(self, intervals): intervals = sorted(intervals, key=lambda x: (x[0], x[1])) stack = [] for i in intervals: if stack and stack[-1][1] &gt;= i[0]: cur = stack.pop() union = [min(i[0], cur[0]), max(i[1], cur[1])] stack.append(union) else: stack.append(i) return stack 394. 字符串解码 给定一个经过编码的字符串，返回它解码后的字符串。 编码规则为: k[encoded_string]，表示其中方括号内部的 encoded_string 正好重复 k 次。注意 k 保证为正整数。 示例 1： 12输入：s = "3[a]2[bc]"输出："aaabcbc" 思路：采用两个栈数字占和字符栈，算法计算步骤 将数字和字母分别保存 遇到‘【’，入栈 遇到‘】’，出栈，计算当前结果 然后将结果拼接到字符串后面。 1234567891011121314151617181920212223242526class Solution: """ 采用栈： 输入栈和输出栈 """ def decodeString(self, s: str) -&gt; str: num_stack = [] str_stack = [] multi = 0 res = "" for c in s: if '0' &lt;= c &lt;= '9': multi = multi * 10 + int(c) elif 'a' &lt;= c &lt;= 'z': res += c elif c == '[': num_stack.append(multi) str_stack.append(res) res = "" multi = 0 else: current_multi = num_stack.pop() current_char = str_stack.pop() res = current_char + current_multi * res return res 单调栈 最长有效括号](https://leetcode-cn.com/problems/longest-valid-parentheses/) 给你一个只包含 &#39;(&#39; 和 &#39;)&#39; 的字符串，找出最长有效（格式正确且连续）括号子串的长度。 判断入栈条件 如果栈空，入栈 当前字符为’(‘，入栈 当前栈为’)’ 上述三种情况无法进行匹配出栈，所以直接消除 出栈： 通过出栈时’)’的下标与队列中下标进行对比。 其实有两种情况 当栈为空的时候，表示前面的括号都是合法的，所以合法长度为i+1 当栈不为空的时候，表示前面存在不合法括号，所以直接用$i- index_{not\;legal}$ 1234567891011121314151617181920class Solution: def longestValidParentheses(self, s: str) -&gt; int: stack = [] max_len = 0 length = 0 if len(s) == 0: return 0 for i in range(len(s)): if not stack or s[i] == '(' or s[stack[-1]] == ')': stack.append(i) else: stack.pop() length = i - (stack[-1] if stack else -1) max_len = max(max_len, length) return max_len 42. 接雨水 给定 n 个非负整数表示每个宽度为 1 的柱子的高度图，计算按此排列的柱子，下雨之后能接多少雨水。 1234567输入：height = [0,1,0,2,1,0,1,3,2,1,2,1]输出：6解释：上面是由数组 [0,1,0,2,1,0,1,3,2,1,2,1] 表示的高度图，在这种情况下，可以接 6 个单位的雨水（蓝色部分表示雨水）。 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/trapping-rain-water著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 思路：单调栈 根据下面的图，我们知道接雨水的时候，其实是由两个边界决定的。因此我们构建一个单调递减的栈stack用于保存当前数组元素的边界。 遍历数组： 当栈非空且当前元素大于栈顶元素，弹出栈顶元素left 计算当前元素到栈顶元素的距离$distance= current - stack[-1] -1$ 找到界定高度$max_height = min(height[stack[-1]], height[current]) - height[left]$ 计算结果$res=max_height * distance$ 其实上述过程简单来讲，就是每次弹出站时，按层计算结果。 12345678910111213141516171819202122232425262728class Solution: """ 思路：最小栈 """ def trap(self, height) -&gt; int: n = len(height) stack = [] current = 0 res = 0 if n == 0: return 0 while current &lt; n: # 如果栈为空或者当前位置高度小于栈顶元素，入栈 while stack and height[current] &gt;= height[stack[-1]]: # 弹出栈顶元素 left = stack.pop() if not stack: break distance = current - stack[-1] - 1 max_height = min(height[stack[-1]], height[current]) - height[left] res += max_height * distance stack.append(current) current += 1 return res 84. 柱状图中最大的矩形 给定 n 个非负整数，用来表示柱状图中各个柱子的高度。每个柱子彼此相邻，且宽度为 1 。 求在该柱状图中，能够勾勒出来的矩形的最大面积。 以上是柱状图的示例，其中每个柱子的宽度为 1，给定的高度为 [2,1,5,6,2,3]。 图中阴影部分为所能勾勒出的最大矩形面积，其面积为 10 个单位。 示例: 12输入: [2,1,5,6,2,3]输出: 10 思路：单调栈，和接雨水思路差不多。构建一个单调递增栈。 如果栈为空或者当前元素小于栈顶元素，入栈 如果栈不为空，并且当前元素大于栈顶元素，出栈，$cur_height=nums[stack.pop()]$ 当前宽度$cur_width=i - stack[-1] - 1$ 更新面积 123456789101112131415161718192021222324class Solution: """ 思路一：单调栈，当前元素大于栈顶元素，出栈，出栈时计算面积 """ def largestRectangleArea(self, heights): stack = [] max_area = 0 heights = [0] + heights + [0] n = len(heights) for i in range(n): if not stack or heights[i] &gt;= heights[stack[-1]]: stack.append(i) else: # 采用单调栈保存最后的结果 while stack and heights[stack[-1]] &gt; heights[i]: cur_height = heights[stack.pop()] # 关键点，前面加上一个0，使得首位形式一样 cur_width = i - stack[-1] - 1 max_area = max(max_area, cur_height * cur_width) stack.append(i) return max_area 85. 最大矩形 给定一个仅包含 0 和 1 、大小为 rows x cols 的二维二进制矩阵，找出只包含 1 的最大矩形，并返回其面积。 示例 1： 123输入：matrix = [[&quot;1&quot;,&quot;0&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;],[&quot;1&quot;,&quot;0&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;],[&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;],[&quot;1&quot;,&quot;0&quot;,&quot;0&quot;,&quot;1&quot;,&quot;0&quot;]]输出：6解释：最大矩形如上图所示。 思路：和前面两题一样 12345678910111213141516171819202122232425262728293031323334353637class Solution: def largestRectangleArea(self, heights) -&gt; int: stack = [] max_area = 0 heights = [0] + heights + [0] n = len(heights) for i in range(n): if not stack or heights[i] &gt;= heights[stack[-1]]: stack.append(i) else: # 采用单调栈保存最后的结果 while stack and heights[stack[-1]] &gt; heights[i]: cur_height = heights[stack.pop()] # 关键点，前面加上一个0，使得首位形式一样 cur_width = i - stack[-1] - 1 max_area = max(max_area, cur_height * cur_width) stack.append(i) return max_area def maximalRectangle(self, matrix) -&gt; int: m = len(matrix) if m == 0: return 0 n = len(matrix[0]) heights = [0] * n ans = 0 for i in range(m): for j in range(n): if matrix[i][j] == "0": heights[j] = 0 else: heights[j] += 1 ans = max(ans, self.largestRectangleArea(heights)) return ans 739. 每日温度 难度中等669收藏分享切换为英文接收动态反馈 请根据每日 气温 列表，重新生成一个列表。对应位置的输出为：要想观测到更高的气温，至少需要等待的天数。如果气温在这之后都不会升高，请在该位置用 0 来代替。 例如，给定一个列表 temperatures = [73, 74, 75, 71, 69, 72, 76, 73]，你的输出应该是 [1, 1, 4, 2, 1, 1, 0, 0]。 提示：气温 列表长度的范围是 [1, 30000]。每个气温的值的均为华氏度，都是在 [30, 100] 范围内的整数。 思路：保存一个递减单调栈，当当前栈元素大于栈顶元素，弹出栈。 1234567891011121314151617181920212223242526272829303132class Solution: """ 思路一：暴力，超时 思路二：借助栈 """ def dailyTemperatures(self, T): n = len(T) stack = [] ans = [] ans_dict = &#123;&#125; for i in range(len(T)): if not stack: stack.append(i) else: while stack: j = stack[-1] if T[i] &gt; T[j]: stack.pop() ans_dict[j] = i - j else: break stack.append(i) while stack: i = stack.pop() ans_dict[i] = 0 for i in range(n): ans.append(ans_dict[i]) return ans 迷宫求解采用dfs或者栈，得到迷宫最优解。 200. 岛屿数量 给你一个由 &#39;1&#39;（陆地）和 &#39;0&#39;（水）组成的的二维网格，请你计算网格中岛屿的数量。 岛屿总是被水包围，并且每座岛屿只能由水平方向和/或竖直方向上相邻的陆地连接形成。 此外，你可以假设该网格的四条边均被水包围。 示例1： 1234567输入：grid = [ [&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;], [&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;], [&quot;0&quot;,&quot;0&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;], [&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;1&quot;,&quot;1&quot;]]输出：3 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253class Solution: def numIslands(self, grid): m = len(grid) n = len(grid[0]) visited = [[0] * n for _ in range(m)] from collections import deque q = deque() count = 0 for i in range(m): for j in range(n): flag = False if not q and grid[i][j] == '1' and visited[i][j] == 0: q.append((i, j)) visited[i][j] = 1 while q: pos = q[0] x, y = pos[0], pos[1] # 向左移动 if x - 1 &gt;= 0: if grid[x-1][y] == '1' and visited[x-1][y] == 0: q.append((x-1, y)) visited[x-1][y] = 1 # 向上移动 if y - 1 &gt;= 0: if grid[x][y-1] == '1' and visited[x][y-1] == 0: q.append((x, y-1)) visited[x][y-1] = 1 # 向下移动 if x + 1 &lt; m: if grid[x+1][y] == '1' and visited[x+1][y] == 0: q.append((x+1, y)) visited[x+1][y] = 1 # 向右移动 if y + 1 &lt; n: if grid[x][y+1] == '1' and visited[x][y+1] == 0: q.append((x, y+1)) visited[x][y+1] = 1 q.popleft() flag = True if flag: count += 1 return count 树树的遍历1、先序遍历 非递归版先序遍历 1234567891011121314151617class Solution(object): def preorderTraversal(self, root): """ :type root: TreeNode :rtype: List[int] """ ret = [] stack = [] while root or stack: while root: ret.append(root.val) stack.append(root) root = root.left if stack: t = stack.pop() root = t.right return ret 617. 合并二叉树 给定两个二叉树，想象当你将它们中的一个覆盖到另一个上时，两个二叉树的一些节点便会重叠。 你需要将他们合并为一个新的二叉树。合并的规则是如果两个节点重叠，那么将他们的值相加作为节点合并后的新值，否则不为 NULL 的节点将直接作为新二叉树的节点。 示例 1: 1234567891011121314输入: Tree 1 Tree 2 1 2 / \ / \ 3 2 1 3 / \ \ 5 4 7 输出: 合并后的树: 3 / \ 4 5 / \ \ 5 4 7 1234567891011121314151617181920212223242526272829class Solution: """ 二叉树构建： 先序遍历，创建二叉树 """ def create_tree(self, t1,t2): if not t1 and not t2: return None root = TreeNode(0) if t1 and t2: root.val = t1.val + t2.val root.left = self.create_tree(t1.left, t2.left) root.right = self.create_tree(t1.right, t2.right) elif t1: root.val = t1.val root.left = self.create_tree(t1.left, None) root.right = self.create_tree(t1.right, None) elif t2: root.val = t2.val root.left = self.create_tree(None, t2.left) root.right = self.create_tree(None, t2.right) return root def mergeTrees(self, t1, t2): return self.create_tree(t1, t2) 2、中序遍历 123456789101112131415def inorderTraversal(root_node): if not root_node: return node_stack = [] node = root_node while node_stack or node: # 从跟节点开始，把它的左子树找出来 while node: node_stack.append(node) node = node.left # 上面 while 的结束就是 node 为空的时候，也就是前一个节点没有左子树的了 node = node_stack.pop() print node.val # 这个时候就开始查看右子树了 node= = node.right 3、后续遍历 123456789101112131415def postorderTraversal(root_node): if not root_node: return stack1 = [root_node] stack2 = [] while stack1: # 在这个 while 循环里面找到后序遍历的逆序，存在在 stack2 中 node = stack1.pop() if node.left: stack1.append(node.left) if node.right: stack1.append(node.right) stack2.append(node) while stack2: print stack2.pop().val 4、层序遍历 102. 二叉树的层序遍历 给你一个二叉树，请你返回其按 层序遍历 得到的节点值。 （即逐层地，从左到右访问所有节点）。 示例：二叉树：[3,9,20,null,null,15,7], 12345 3 / \9 20 / \ 15 7 123456789101112131415161718192021222324252627from queue import Queueclass Solution: def levelOrder(self, root): res = [] if root is None: return res q = Queue() q.put(root) while q.qsize() != 0: level = [] size = q.qsize() while size &gt; 0: root = q.get() level.append(root.val) if root.left is not None: q.put(root.left) if root.right is not None: q.put(root.right) size -= 1 res.append(level) return res 5、二叉树的深度 123456789class Solution: def maxDepth(self, root: TreeNode) -&gt; int: if root is None: return 0 else: left = self.maxDepth(root.left) + 1 right = self.maxDepth(root.right) + 1 return max(left, right) 6、二叉树的宽度 543. 二叉树的直径 给定一棵二叉树，你需要计算它的直径长度。一棵二叉树的直径长度是任意两个结点路径长度中的最大值。这条路径可能穿过也可能不穿过根结点。 示例 :给定二叉树 12345 1 / \ 2 3 / \ 4 5 返回 3, 它的长度是路径 [4,2,1,3] 或者 [5,2,1,3]。 注意：两结点之间的路径长度是以它们之间边的数目表示。 1234567891011121314151617181920212223242526272829303132# Definition for a binary tree node.# class TreeNode:# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution: def __init__(self): self.max_depth = 0 def sumTreeDepth(self, root): if not root: return 0 left = self.sumTreeDepth(root.left) right = self.sumTreeDepth(root.right) current = max(left, right) if left + right &gt; self.max_depth: self.max_depth = left + right return current + 1 def diameterOfBinaryTree(self, root): if not root: return 0 self.sumTreeDepth(root) return self.max_depth 二叉树公共先祖236. 二叉树的最近公共祖先 给定一个二叉树, 找到该树中两个指定节点的最近公共祖先。 百度百科中最近公共祖先的定义为：“对于有根树 T 的两个节点 p、q，最近公共祖先表示为一个节点 x，满足 x 是 p、q 的祖先且 x 的深度尽可能大（一个节点也可以是它自己的祖先）。” 示例 1： 123输入：root = [3,5,1,6,2,0,8,null,null,7,4], p = 5, q = 1输出：3解释：节点 5 和节点 1 的最近公共祖先是节点 3 。 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution: """ 求最近公共祖先，将右节点指向父节点，就能转换成链表求父节点的问题 """ def length(self, node): count = 0 while node: count += 1 node = node.right return count def lowestCommonAncestor(self, root: 'TreeNode', p: 'TreeNode', q: 'TreeNode') -&gt; 'TreeNode': def inorder(node, parent): if node: inorder(node.left, node) inorder(node.right, node) node.right = parent inorder(root, None) l1 = self.length(p) l2 = self.length(q) if l1 &gt; l2: i = 0 while i &lt; l1-l2: p = p.right i += 1 else: i = 0 while i &lt; l2 - l1: q = q.right i += 1 while p and q: if p == q: return p p = p.right q = q.right 二叉树序列化297. 二叉树的序列化与反序列化 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152from collections import dequeclass Codec: def serialize(self, root): """Encodes a tree to a single string. :type root: TreeNode :rtype: str """ if not root: return [] res = [] q = deque() q.append(root) while q: node = q.popleft() if node is None: res.append('null') else: res.append(str(node.val)) q.append(node.left) q.append(node.right) return res def deserialize(self, data): """Decodes your encoded data to tree. :type data: str :rtype: TreeNode """ if not data or len(data) == 0: return None self.root = TreeNode(data[0]) queue = deque([self.root]) leng = len(data) nums = 1 while nums &lt; leng: node = queue.popleft() if node: node.left = TreeNode(data[nums]) if data[nums] else None queue.append(node.left) if nums + 1 &lt; leng: node.right = TreeNode(data[nums + 1]) if data[nums + 1] else None queue.append(node.right) nums += 1 nums += 1 return self.root 字典树208. 实现 Trie (前缀树) 实现一个 Trie (前缀树)，包含 insert, search, 和 startsWith 这三个操作。 示例: 12345678Trie trie = new Trie();trie.insert(&quot;apple&quot;);trie.search(&quot;apple&quot;); // 返回 truetrie.search(&quot;app&quot;); // 返回 falsetrie.startsWith(&quot;app&quot;); // 返回 truetrie.insert(&quot;app&quot;); trie.search(&quot;app&quot;); // 返回 true 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class TrieNode: def __init__(self, val=None, children=[], end=False): self.val = val self.children = children self.end = endclass Trie: def __init__(self): """ Initialize your data structure here. """ # 创建一个根节点 self.node = &#123;&#125; def insert(self, word: str) -&gt; None: """ Inserts a word into the trie. """ node = self.node for w in word: if w not in node: node[w] = &#123;&#125; node = node[w] def search(self, word: str) -&gt; bool: """ Returns if the word is in the trie. """ node = self.node for w in word: if w not in node: return False node = node[w] return True def startsWith(self, prefix: str) -&gt; bool: """ Returns if there is any word in the trie that starts with the given prefix. """ node = self.node for p in prefix: if p not in node: return False node = node[p] return True 搜索二叉树给定一个整数 n，求以 1 … n 为节点组成的二叉搜索树有多少种？ 解析：二叉搜索数的定义是，所有对于所有节点都有 根节点大于左节点的 根节点小于右节点 先序遍历二叉搜索树，得到有序单调递增序列 定义两个函数 $G(n)$: 长度为n的序列能构成不同的二叉搜索树的个数 $F(i,n)$：以$i$为根、序列长度为n的不同二叉搜索树的个数 以不同的i作为节点，可得到 G(n)=\sum_{i=1}^nF(i,n)边界条件：G(0)=G(1)=1 $F(i, n)$的定点固定，所以能够组成的二叉搜索树个数是由两个子节点决定的。即 [1, i]和[i+1, n]决定。而[i+1, n]等价于[1, n-i-1] 所以有$F(i, n)=G(i)G(n-i)$ 所以最后的递推公式可以转换成 G(n)=\sum_{i=1}^nG(i)G(n-i)该公式可以归纳为卡塔兰数 C(n+1)=\frac{2(2n+1)}{n+2}C(n)12345678910def numTrees(self, n): G = [0] * (n+1) G[0] = G[1] = 1 for i in range(2, n+1): for j in range(1, i+1): G[i] += G[j-1] * G[i-j] return G[n] 类似题目： 小兔棋盘 538. 把二叉搜索树转换为累加树 难度中等487收藏分享切换为英文接收动态反馈 给出二叉 搜索 树的根节点，该树的节点值各不相同，请你将其转换为累加树（Greater Sum Tree），使每个节点 node 的新值等于原树中大于或等于 node.val 的值之和。 提醒一下，二叉搜索树满足下列约束条件： 节点的左子树仅包含键 小于 节点键的节点。 节点的右子树仅包含键 大于 节点键的节点。 左右子树也必须是二叉搜索树。 注意：本题和 1038: https://leetcode-cn.com/problems/binary-search-tree-to-greater-sum-tree/ 相同 示例 1： 12输入：[4,1,6,0,2,5,7,null,null,null,3,null,null,null,8]输出：[30,36,21,36,35,26,15,null,null,null,33,null,null,null,8] 位运算136. 只出现一次的数字 给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。 说明： 你的算法应该具有线性时间复杂度。 你可以不使用额外空间来实现吗？ 示例 1: 12输入: [2,2,1]输出: 1 思路：位运算，当两个数相同时，异或运算结果为0。 12345678class Solution: def singleNumber(self, nums): s = 0 for i in nums: s ^= i return s 338. 比特位计数 给定一个非负整数 num。对于 0 ≤ i ≤ num 范围中的每个数字 i ，计算其二进制数中的 1 的数目并将它们作为数组返回。 示例 1: 12输入: 2输出: [0,1,1] 思路：转换成二进制后，是形如这样的数字：aa…aa10…00，从右向左数有任意多个0，直到遇见第一个1，字母a用来占位，代表1左边的任意数字。 x-1转换成二进制后，是形如这样的数字：aa…aa01…11，从右向左数，原来的任意多个0都变成1，原来的第一个1，变成0，字母a部分不变。 对x 和 x-1 进行 按位与 计算，会得到：aa…aa00…00，从右向左数，原来的第一个1变成了0，字母a部分不变。 所以 x &amp; (x-1)相当于消除了 x 从右向左数遇到的第一个1。 12345678910111213class Solution: """位运算""" def countBits(self, num: int): int count_bit(x): count = 0 while x: count += 1 x &amp;= x-1 res = [count_bit(x) for x in range(0, num+1)] return res 进阶版: 12345678910class Solution: """位运算""" def countBits(self, num: int): res = [0] * (num + 1) for i in range(1, num + 1): res[i] = res[i &amp; i - 1] + 1 return res 461. 汉明距离 难度简单379收藏分享切换为英文接收动态反馈 两个整数之间的汉明距离指的是这两个数字对应二进制位不同的位置的数目。 给出两个整数 x 和 y，计算它们之间的汉明距离。 注意：0 ≤ x, y &lt; 231. 示例: 12345678910输入: x = 1, y = 4输出: 2解释:1 (0 0 0 1)4 (0 1 0 0) ↑ ↑上面的箭头指出了对应二进制位不同的位置。 思路：先异或运算，再为运算。 1234567891011121314class Solution: """ 汉明距离，数字中有多少个1的变形 """ def hammingDistance(self, x, y): nums = x ^ y count = 0 while nums != 0: if nums &amp; 1: count += 1 nums &gt;&gt;= 1 return count 查找算法二分查找4.寻找两个正序数组的中位数 给定两个大小分别为 m 和 n 的正序（从小到大）数组 nums1 和 nums2。请你找出并返回这两个正序数组的 中位数 。 示例 1： 123输入：nums1 = [1,3], nums2 = [2]输出：2.00000解释：合并数组 = [1,2,3] ，中位数 2 思路一：将两个序列进行合并，类似链表的操作方式，然后找到中位数。 12345678910111213141516171819202122232425262728class Solution: def findMedianSortedArrays(self, nums1, nums2): nums = [] len1 = len(nums1) len2 = len(nums2) i = 0 j = 0 while i &lt; len1 and j &lt; len2: if nums1[i] &lt; nums2[j]: nums.append(nums1[i]) i += 1 else: nums.append(nums2[j]) j += 1 if i &lt; len1: nums += nums1[i: len1] elif j &lt; len2: nums += nums2[j: len2] nums_size = len(nums) middle_index = int(nums_size/2) if nums_size == 0: return [] elif nums_size % 2 == 0: return (nums[middle_index - 1] + nums[middle_index]) / 2 else: return nums[middle_index] 思路二：二分查找。暂时没看懂 二分查找解法： 33. 搜索旋转排序数组 整数数组 nums 按升序排列，数组中的值 互不相同 。 在传递给函数之前，nums 在预先未知的某个下标 k（0 &lt;= k &lt; nums.length）上进行了 旋转，使数组变为 [nums[k], nums[k+1], ..., nums[n-1], nums[0], nums[1], ..., nums[k-1]]（下标 从 0 开始 计数）。例如， [0,1,2,4,5,6,7] 在下标 3 处经旋转后可能变为 [4,5,6,7,0,1,2] 。 给你 旋转后 的数组 nums 和一个整数 target ，如果 nums 中存在这个目标值 target ，则返回它的索引，否则返回 -1 。 思路：二分查找，比较简单，直接贴代码。 1234567891011121314151617181920class Solution: def search(self, nums: List[int], target: int) -&gt; int: if not nums: return -1 l, r = 0, len(nums) - 1 while l &lt;= r: mid = (l + r) // 2 if nums[mid] == target: return mid if nums[0] &lt;= nums[mid]: if nums[0] &lt;= target &lt; nums[mid]: r = mid - 1 else: l = mid + 1 else: if nums[mid] &lt; target &lt;= nums[len(nums) - 1]: l = mid + 1 else: r = mid - 1 return -1 148.排序链表 给你链表的头结点 head ，请将其按 升序 排列并返回 排序后的链表 思路：归并排序 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# Definition for singly-linked list.class ListNode: def __init__(self, val=0, next=None): self.val = val self.next = nextclass Solution: """ 方法一：冒泡排序 时间复杂度O(n2) 方法二：归并排序 """ def sortList(self, head: ListNode) -&gt; ListNode: if not head or not head.next: return head slow = head fast = head # 用快慢指针分成两部分 while fast.next and fast.next.next: slow = slow.next fast = fast.next.next # 找到左右部分, 把左部分最后置空 mid = slow.next slow.next = None # 递归下去 left = self.sortList(head) right = self.sortList(mid) # 合并 return self.merge(left, right) def merge(self, left, right): dummy = ListNode(0) p = dummy l = left r = right while l and r: if l.val &lt; r.val: p.next = l l = l.next p = p.next else: p.next = r r = r.next p = p.next if l: p.next = l if r: p.next = r return dummy.next 哈希表法分块查找图算法拓扑排序207. 课程表 你这个学期必须选修 numCourses 门课程，记为 0 到 numCourses - 1 。 在选修某些课程之前需要一些先修课程。 先修课程按数组 prerequisites 给出，其中 prerequisites[i] = [ai, bi] ，表示如果要学习课程 ai 则 必须 先学习课程 bi 。 例如，先修课程对 [0, 1] 表示：想要学习课程 0 ，你需要先完成课程 1 。 请你判断是否可能完成所有课程的学习？如果可以，返回 true ；否则，返回 false 。 示例 1： 123输入：numCourses = 2, prerequisites = [[1,0]]输出：true解释：总共有 2 门课程。学习课程 1 之前，你需要完成课程 0 。这是可能的。 思路： 本质是有向图是否存在环，拓扑排序问题 1、首先找到度入度为0的的点 2、然后以改点为起点，找到指向的点，度-1 3、然后找到指向的度为0的点，重复1/2操作。 123456789101112131415161718192021222324252627282930import collectionsclass Solution: def canFinish(self, numCourses: int, prerequisites): # 采用邻接链表 edges = collections.defaultdict(list) indeg = [0] * numCourses # 构建边与入度 for info in prerequisites: edges[info[1]].append(info[0]) indeg[info[0]] += 1 zero_indeg = [i for i in range(numCourses) if indeg[i] == 0] q = collections.deque(zero_indeg) count = 0 while q: node = q.popleft() count += 1 for i in edges[node]: indeg[i] -= 1 if indeg[i] == 0: q.append(i) return count == numCourses 复杂数据结构并查集399. 除法求值 给你一个变量对数组 equations 和一个实数值数组 values 作为已知条件，其中 equations[i] = [Ai, Bi] 和 values[i] 共同表示等式 Ai / Bi = values[i] 。每个 Ai 或 Bi 是一个表示单个变量的字符串。 另有一些以数组 queries 表示的问题，其中 queries[j] = [Cj, Dj] 表示第 j 个问题，请你根据已知条件找出 Cj / Dj = ? 的结果作为答案。 示例 1： 123456输入：equations = [["a","b"],["b","c"]], values = [2.0,3.0], queries = [["a","c"],["b","a"],["a","e"],["a","a"],["x","x"]]输出：[6.00000,0.50000,-1.00000,1.00000,-1.00000]解释：条件：a / b = 2.0, b / c = 3.0问题：a / c = ?, b / a = ?, a / e = ?, a / a = ?, x / x = ?结果：[6.0, 0.5, -1.0, 1.0, -1.0 ] 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677class UnionFind: # 定义一个并查集类 # 特点：一边查询，一边修改节点指向 def __init__(self): self.parent = &#123;&#125; self.weight = &#123;&#125; def find(self, x): # 路径压缩 # 找到根节点 root = x multi = 1 # if x in self.parent: # 判断查询语句是否有效 while self.parent[root] != root: # 计算路径上的权值 multi *= self.weight[root] root = self.parent[root] while x != root: last_parent = self.parent[x] cur_weight = self.weight[x] self.weight[x] = multi multi /= cur_weight self.parent[x] = root x = last_parent return root def merge(self, x, y, val): # 合并并查集 parent_x = self.find(x) parent_y = self.find(y) if parent_x == parent_y: return if parent_x != parent_y: self.parent[parent_x] = parent_y # 合并之后更新权值 self.weight[parent_x] = self.weight[y] * val/self.weight[x] def is_connected(self, x, y): # 判断两点是否相连 return x in self.parent and y in self.parent and self.find(x) == self.find(y) def add(self, x): if x not in self.parent: self.parent[x] = x self.weight[x] = 1.0class Solution: """ 思路：带权重并查集 """ def calcEquation(self, equations, values, queries): uf = UnionFind() # 构建并查集 for (a, b), val in zip(equations, values): uf.add(a) uf.add(b) uf.merge(a, b, val) res = [] for (a, b) in queries: if uf.is_connected(a, b): res.append(uf.weight[a]/uf.weight[b]) else: res.append(-1.0) return res LRU146. LRU 缓存机制 难度中等1219收藏分享切换为英文接收动态反馈 运用你所掌握的数据结构，设计和实现一个 LRU (最近最少使用) 缓存机制 。 实现 LRUCache 类： LRUCache(int capacity) 以正整数作为容量 capacity 初始化 LRU 缓存 int get(int key) 如果关键字 key 存在于缓存中，则返回关键字的值，否则返回 -1 。 void put(int key, int value) 如果关键字已经存在，则变更其数据值；如果关键字不存在，则插入该组「关键字-值」。当缓存容量达到上限时，它应该在写入新数据之前删除最久未使用的数据值，从而为新的数据值留出空间。 进阶：你是否可以在 O(1) 时间复杂度内完成这两种操作？ 示例： 1234567891011121314151617输入[&quot;LRUCache&quot;, &quot;put&quot;, &quot;put&quot;, &quot;get&quot;, &quot;put&quot;, &quot;get&quot;, &quot;put&quot;, &quot;get&quot;, &quot;get&quot;, &quot;get&quot;][[2], [1, 1], [2, 2], [1], [3, 3], [2], [4, 4], [1], [3], [4]]输出[null, null, null, 1, null, -1, null, -1, 3, 4]解释LRUCache lRUCache = new LRUCache(2);lRUCache.put(1, 1); // 缓存是 &#123;1=1&#125;lRUCache.put(2, 2); // 缓存是 &#123;1=1, 2=2&#125;lRUCache.get(1); // 返回 1lRUCache.put(3, 3); // 该操作会使得关键字 2 作废，缓存是 &#123;1=1, 3=3&#125;lRUCache.get(2); // 返回 -1 (未找到)lRUCache.put(4, 4); // 该操作会使得关键字 1 作废，缓存是 &#123;4=4, 3=3&#125;lRUCache.get(1); // 返回 -1 (未找到)lRUCache.get(3); // 返回 3lRUCache.get(4); // 返回 4 思路：哈希表+双向链表 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import collectionsclass DLinkedNode: def __init__(self, key=0, value=0): self.key = key self.value = value self.prev = None self.next = Noneclass LRUCache(collections.OrderedDict): """ 思路一：采用OrderedDict，面试一般需要自己实现 思路二：哈希表+双向链表 """ def __init__(self, capacity: int): self.cache = &#123;&#125; self.head = DLinkedNode() self.tail = DLinkedNode() self.head.next = self.tail self.tail.prev = self.head self.capacity = capacity self.size = 0 def get(self, key: int) -&gt; int: if key not in self.cache: return -1 node = self.cache[key] self.moveToHead(node) return node.value def put(self, key: int, value: int) -&gt; None: if key not in self.cache: node = DLinkedNode(key, value) self.cache[key] = node if self.size &gt;= self.capacity: removed = self.removeTail() self.cache.pop(removed.key) self.addToHead(node) else: # 如果存在哈希冲突，修改结果并将其移动到链表头部 node = self.cache[key] node.value = value self.moveToHead(node) print("哈希冲突") def addToHead(self, node): node.next = self.head.next node.prev = self.head self.head.next.prev = node self.head.next = node self.size += 1 def removeNode(self, node): node.prev.next = node.next node.next.prev = node.prev self.size -= 1 def moveToHead(self, node): self.removeNode(node) self.addToHead(node) def removeTail(self): node = self.tail.prev self.removeNode(node) return node# Your LRUCache object will be instantiated and called as such: LFU排序算法在计算机科学与数学中，一个排序算法（英语：Sorting algorithm）是一种能将一串资料依照特定排序方式进行排列的一种算法。最常用到的排序方式是数值顺序以及字典顺序。有效的排序算法在一些算法（例如搜索算法与合并算法）中是重要的，如此这些算法才能得到正确解答。排序算法也用在处理文字资料以及产生人类可读的输出结果。基本上，排序算法的输出必须遵守下列两个原则： 输出结果为递增序列（递增是针对所需的排序顺序而言） 输出结果是原输入的一种排列、或是重组 归并排序12345678910111213141516171819202122232425262728293031323334void Merge(int *a,int s,int m,int n)&#123; int temp[20]; int i=s,q=s; int j=m+1; while(i&lt;=m&amp;&amp;j&lt;=n) &#123; if(a[i]&lt;a[j]) temp[q++]=a[i++]; else temp[q++]=a[j++]; &#125; while(i&lt;=m) temp[q++]=a[i++]; while(j&lt;=n) temp[q++]=a[j++]; for(int k=s;k&lt;=n;k++) a[k]=temp[k];&#125;void MSort(int *a,int s,int t)&#123; int m; if(s==t) return; else &#123; m=(s+t)/2; MSort(a,s,m); MSort(a,m+1,t); Merge(a,s,m,t); &#125;&#125; 快速排序123456789101112131415161718192021222324252627282930int Partition(SqList &amp;L,int low,int high)//最后返回的位置为枢轴的位置&#123; RedType t; L.r[0]=L.r[low];//设置枢轴 while(low&lt;high) &#123; while(L.r[high].key&gt;=L.r[0].key&amp;&amp;low&lt;high) high--; L.r[low]=L.r[high]; while(L.r[low].key&lt;L.r[0].key&amp;&amp;low&lt;high) low++; L.r[high]=L.r[low]; &#125; L.r[low]=L.r[0]; return low;&#125;void Qsort(SqList &amp;L,int low,int high)&#123; int i; if(low&lt;high) &#123; i=Partition(L,low,high); Qsort(L,low,i-1); Qsort(L,i+1,high); count++; printf("第%d趟排序:",count); Print(L); &#125;&#125; 347. 前 K 个高频元素 给定一个非空的整数数组，返回其中出现频率前 k\ 高的元素。 示例 1: 12输入: nums = [1,1,1,2,2,3], k = 2输出: [1,2] 选择排序冒泡排序堆排序大根堆：父节点的值大于子节点的值。 小根堆：父节点的值小于子节点值。 合并K个升序链表 给你一个链表数组，每个链表都已经按升序排列。 请你将所有链表合并到一个升序链表中，返回合并后的链表。 思路一：利用堆排序 构建一个小根堆，将元素一次插入其中，然后将链表一次放入其中。 然后一次将链表弹出，最后得到的就是有序的链表。 思路二：将链表结果放到数组里面，然后利用快排。 123456789101112131415class Solution(object): def mergeKLists(self, lists): import heapq head = point = ListNode(0) heap = [] for l in lists: while l: heapq.heappush(heap, l.val) l = l.next while heap: val = heappop(heap) point.next = ListNode(val) point = point.next point.next = None return head.next 桶排序基数排序希尔排序]]></content>
      <categories>
        <category>算法与数据结构</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deep cross network原理及实现]]></title>
    <url>%2F2020%2F12%2F26%2Fdeep-cross-network%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[本文提出贡献： 提出了一个交叉网络，能够在每一层直接进行特征交叉，不需要手工特征 交叉网络简单并且有效，可以通过增加交叉网络层数来提升特征的交叉阶数。 交叉网络比较省内存并且易于扩展 交叉网络计算公式 x_{l+1}=x_0x_l^tw_l+b_l+x_l优点像残差网络 其中$x_0$为cross net第一层的输入，其维度为(k, 1)，$x_l^t$的维度为(1,k)]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
        <tag>排序算法</tag>
        <tag>CTR</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deepFM的原理及实现]]></title>
    <url>%2F2020%2F11%2F29%2FdeepFM%E7%9A%84%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[从FM、FM到deepFM]]></title>
    <url>%2F2020%2F11%2F18%2F%E4%BB%8EFM-FM%E5%88%B0deepFM%2F</url>
    <content type="text"><![CDATA[FM 在传统任务中LR存在的缺点： 1、模型一般为$y=w_0+\sum_{i=1}^nw_ix_i$，为考虑特征之间的关系。实际上交叉特征对于模型有很好地提升效果2、对于categorical特征进行one-hot编码，具有高度稀疏性，带来维度灾难二阶FM的定义 y=w_0+\sum_{i=1}^nw_ix_i+\sum_{i=1}^{n-1}\sum_{j=i+1}^nW_{i,j}x_ix_j $W$为实对称矩阵 所以FM的定义可以改写为 y=w_0+\sum_{i=1}^nw_ix_i+\sum_{i=1}^{n-1}\sum_{j=i+1}^nx_ix_jFM两个特点 解决特征交叉问题 利用矩阵分解解决数据量过大的问题 FFMFFM定义 y(x) = w_0+\sum_{i=1}^nw_ix_i + \sum_{i=1}^n\sum_{j=i+1}^nx_ix_j 考虑了特征的类别，认为类别之间也存在相关性，所以增加了一个维度。 deepFM 分成了DNN+FM模型的组合，DNN学习高阶交叉特征，FM学习低阶交叉特征 利用FM代替wide&amp;deep中wide部分，无需输入人工特征 第一步：数据预处理主要数据类型： 数值型，数值型需要归一化到[0,1] 离散单值型 离散多值型 张量 keras input shape的层，最后一层规定最后一层 keras outputlayer one-hot 其实是指这里的embedding，并没有one-hot 关于Embedding进行的操作，以keras embedding为例子 keras.layers.Embedding(input_dim, output_dim, embeddings_initializer=’uniform’, embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None) keras 主要进行了一下几个操作： 将Embedding进行了one-shot操作，将类别特征变成batch_size * k的向量 将得到的向量分别乘以一个k m的矩阵，得到embedding后的向量矩阵batch_size k *m 将矩阵按照一维reduce_sum，得到最后结果 一般来说，input_dim是类别特征的nunique值，output可以设置为定值或者 x**0.25 embedding数据的输入类型 (batch_size, filed_dim, embedding_dim) 关于FM的交叉项理解 1、在embedding的时候，对应的输出其实已经包含了$w_ix_i$ 2、embedding输出维度为[batch_size, filed_dim, embedding_dim] 3、利用tf.reduce_sum() 对embedding_input进行汇总，其实已经得到FM的一次项 离散特征与连续特征的处理 离散特征：先label_encode， 然后进行embedding操作 连续特征：直接作为输入 deepFM一共三个输入模块 1、线性模块 在类别特征后面接了Embedding(input_dim= k,output_dim=1)​，需要注意的是 如果是 然后与Dense特征合并 2、FM模块 Embedding(4,a) 3、DNN模块 与Embedding木块共享 参考资料1.【通俗易懂】手把手带你实现DeepFM！ 2.]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
        <tag>排序算法</tag>
        <tag>CTR</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deep&wide 论文笔记]]></title>
    <url>%2F2020%2F11%2F12%2Fdeep-wide%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[wide 模型基本特征+交叉特征，年龄特征分桶 Deep模型基本特征+embedding特征 Wide Deep模型get_layer. output和get_layer的区别 需要自己记一下]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
        <tag>深度学习</tag>
        <tag>deep wide</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统之评价指标]]></title>
    <url>%2F2020%2F11%2F08%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B9%8B%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87%2F</url>
    <content type="text"><![CDATA[NDCG@KCG只能判断推荐结果整体质量的高低，无法判断算法的排序好坏。 CG=\sum_{i=1}^Prel_i第一步计算DCG思想是等级较高的结果排在后面，就应该对结果得分打折。 DCG_p=rel_1 + \sum_{i=2}^P\frac{rel_i}{\log_2(i+1)}$DCG_p$还有另外一个中写法 DCG_p = \sum_{i=1}^P\frac{rel_i}{\log_2(i+1)}其实就是$rel_i$的值为{0,1}时候的变形。 第二步计算IDCG IDCG为理想情况下最大的DCG IDCG_p=\sum_{i=1}^{|REL|}\frac{2^{rel_i}-1}{\log_2(i+1)}IDCG其实就是将结果根据相关性进行排序之后再计算前$p$个DCG结果。 ndcg计算公式 nDCG_p = \frac{DCG_p}{IDCG_p}NCGC其实就是将DGC进行了归一化，因为DCG的值和返回结果数量有关，所以如果结果不同，两个页面的结果是无法比较，因此归一化之后，就能将其放到同一维度下。 在实际计算的时候一般计算公式为 \frac{\log(2)}{\log(x+1)}hit@k]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
        <tag>评价指标</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[召回之协同过滤算法]]></title>
    <url>%2F2020%2F10%2F25%2F%E5%8F%AC%E5%9B%9E%E4%B9%8B%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[UserCFItemCF矩阵分解MF矩阵分解其实和《推荐系统实战》那本书里面说的隐语意模型差不多多的意思，都是将用户-物品矩阵分解为用户矩阵和物品矩阵。分解的方法采用梯度下降。 T=P * Q preference(u, i)=r_{ui}=p_{u}^Tq_{i}NCF损失函数： pointwise，用于回归模型，最小化$\hat y_{ui}$和他的目标值$y_{ui}$之间的平方损失函数。 pairwise，思想史观测实例应该被排到为观测实例前面。观测到的entry $\hat y_{ui}$和为观测到的entry $y_{ui}$之间的差 https://blog.csdn.net/stalbo/article/details/79431662 参考资料]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
        <tag>协同过滤</tag>
        <tag>矩阵分解</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spark内存管理机制及spark-submit参数调优]]></title>
    <url>%2F2020%2F09%2F27%2Fspark%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%9C%BA%E5%88%B6%E5%8F%8Aspark-submit%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98%2F</url>
    <content type="text"></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>spark</tag>
        <tag>内存调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《深度学习推荐系统》阅读笔记(二)]]></title>
    <url>%2F2020%2F08%2F26%2F%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-2%2F</url>
    <content type="text"><![CDATA[Embedding作用及应用Embedding也是编码方式的一种，主要作用是将稀疏向量转换成稠密向量。Embedding是深度学习的基础核心操作，主要有一下三个原因1、推荐场景下会使用one-hot对类别和id进行编码，造成大量稀疏数据，神经网络无法很好地处理这种稀疏数据2、Embedding本身是极强的特征向量，可以引入任何信息进行编码。 3、Embedding对物品、用户的相似度计算是常用的推荐系统召回技术。 所以Embedding对应的应用方向主要有一下三个： 作为Embedding层，完成高维稀疏特征向量到低维稠密特征向量的转换 作为预训练的特征向量，在与其他特征向量连接之后，一同输入深度学习网络进行训练 计算物品和用户的相似度做Embedding Word2Vec和Item2VecWord2vec主要用于计算词向量相似度，Item2Vec是Word2Vec在推荐上面的应用，只是两者优化目标不同。并且Item2Vec使用的物品序列是由用户历史行为产生的物品序列。 假设Word2Vec中有一个长为$T$的句子为$w_1,w_2,…,w_T$,其优化的目标为 \frac{1}{T}\sum_{t=1}^T\sum_{-c\le j\le c,j\ne0}\log p(w_{t+j}|w_t)而对于Item2Vec，w表示历史记录，其优化目标为: \frac{1}{K}\sum_{i=1}^K\sum_{j\ne i}^K\log p(w_j|w_i)Item2Vec摒弃了时间窗口，认为任意两个物品都是相关的，而不仅仅是时间窗口之类的物品对数和。 缺点：只能利用序列型数据，对网络化数据捉襟见肘 Graph EmbeddingGraph Embedding是一种对图结构中的结点进行Embedding编码的方法。 DeepWalk主要思想是在由物品组成的图上随机游走，产生大量物品序列，然后将这些序列利用Word2Vec进行训练，得到物品的Embedding向量。 DeepWalk算法流程 1、基于用户行为构建关系图，例如用户先买A再买B，就会产生A到B的有向边，一次类推，将用户行为构建成物品关系图。 2、采用随机游走算法选择起始点，重新产生物品序列。 3、将产生序列输入到Word2Vec模型中 在DeepWalk算法流程中，唯一需要形式化定义的就是随机游走的跳转概率。假设遍历到节点$v_i$，那么跳转到其邻节点的概率是$v_j$的概率为： P(v_j|v_i)=\begin{cases} \frac{M_{ij}}{\sum_{j\in N_+(v_i) M_{ij}}}, & v_j\in N_+(v_i) \\ 0, & e_{ij}\notin \varepsilon \end{cases}其中$M_{ij}$是节点$v_i$到$v_j$的边的权重。 优点：简单 缺点：随机游走抽样性不强 Node2vec通过调整随机游走权重的方法使Graph Embedding的结果更加趋向于体现网络的同质性或结构。网络的同质性指距离相近的节点的Embedding应尽量相似。结构性是指结构上相似的节点Embedding应尽量相似。 为了表达网络的结构性，游走更加倾向于BFS。对于BFS，不同的节点例如局部中心节点、边缘节点、连接性节点，其生成的序列节点数量和顺序必然不同。 为了表达同质性，游走通常采用DFS。DFS通常在一个大的集团内部游走，这就使得社区内部节点Embedding更加相似。 Node2vec主要是通过节点间的跳转概率空值游走时DFS和BFS的倾向 如图所示(图先欠着)，Node2Vec算法从节点$t$跳到节点$v$，再从$v$跳节点$x$的概率为$\pi_{vx}=a_{pq}(t,x)\cdot w_{vx}$ a_{pq}=\begin{cases} \frac{1}{p},& 如果d_{tx}=0 \\ 1, &如果d_{tx}=1 \\ \frac{1}{q}, &如果 d_{tx}=2 \end{cases}其中$d_{tx}$表示节点$t$到节点$x$的距离，参数$p$和$q$共同控制这随机游走的倾向性，当$p$月小的时候，随机游走返回$t$的可能性越高，当$q$越小的时候，随机游走返回远方的可能性越大。 直观理解：同质性的物品很有可能是相似的物品或者经常被一同购买的物品，结构性可能是各类爆款、各品类的最佳凑单商品等拥有类趋势或结构性的商品。 优点：可以有效的挖掘不同的网络特征 缺点：需要较多的人工调参工作 EGESEnhanced Graph Embedding with Side information基本思想是在DeepWalk生成Graph Embedding的基础上引入补充信息，以解决冷启动问题。 可以利用物品相同属性、相同类别等信息建立物品之间的边，生成基于内容的知识图谱，基于知识图谱生成的物品Embedding向量作为补充信息，并且采用平均池化将不同物品的Embedding平均起来，为了防止平均池化导致有效信息丢失，对每个Embedding向量进行加权(Enhance 的体现)。在实际加权的过程中，采用了$e^{a_j}$而不是$a_j$进行加权，主要原因有两点：一：避免权重为0，二：指数函数在梯度下降的过程中有良好的数学性。因此EGES更多的是工程上的尝试，缺乏学术上的创新。 局部敏感哈希传统Embedding在做召回的时候，以为着要对所有物品进行Embedding进行遍历，效率比较低。在推荐系统中，通常物品总数动达几百万，因此会导致线上模型过程的巨大延迟。 局部敏感哈希则是为了解决这个问题，其基本思想是然相邻的点落入到同一个桶里面。 优点：解决利用Embedding作为推荐系统召回层的快速计算方法 缺点：存在小概率的最近邻遗漏的可能，需要进行较多的人工调参]]></content>
      <categories>
        <category>机器学习</category>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
        <tag>Embedding</tag>
        <tag>阅读笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《深度学习推荐系统》阅读笔记(一)]]></title>
    <url>%2F2020%2F08%2F24%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[传统模型协同过滤1、User-CF的缺点 一般用户数量远大于物品数，用户相似度矩阵较大，不便于存储。同时用户数增长会造成在线存储系统难以承载扩张速度 用户历史数据向量往往比较稀疏，User-CF不适用于正反馈获取比较困难的场景，例如大件商品购买等低频应用 2、User-CF和Item-CF的使用场景 User-CF适用于新闻推荐场景，具有较强的社交性、更容易发现热点 Item-CF适用于兴趣变化比较稳定的应用，比如电商和视频推荐场景 协同过滤存在天然缺陷，头部效应明显，处理稀疏向量的能力较弱。并且协同过滤仅仅利用了用户年龄、性别、商品描述、商品分类等信息，会造成有效信息遗漏。 矩阵分解矩阵分解，针对协同过滤算法头部效应明显，泛化能力弱，加入了隐向量。 矩阵分解的三种方法： 奇异值分解SVD 特征值分解 梯度下降法 特征值分解只适合方阵，不适用于分解用户-物品矩阵。 奇异值分解要求共现矩阵稠密，且时间复杂度过高。所以一般采用梯度下降来进行矩阵分解。 矩阵分解优点： 泛化能力强 空间复杂度低，只需要存储用户和物品隐向量 更好的扩张性和灵活性，可以和其他特征拼接 缺点： 和协同过滤一样，无法利用用户年龄性别等信息 逻辑回归将推荐问题转换成CTR问题 优点： 数学上的支撑 可解释性强 符合人类对预估过程的直觉认识 缺点： 表达能力不强，无法进行特征交叉，导致信息丢失 FM与FFM辛普森悖论：在分组中占优势的一方在总评中不占优势。 POLY2暴力交叉特征，对所有特征进行两两组合，数学形式： \Phi POLY2(w,x)=\sum_{j_1=1}^n\sum_{j_2=j_1+1}^nw_h(j_1,j_2)x_{j_1}x_{j_2}$x_i$和$x_j$表示特征$i,j$，$w_h(i,j)$表示特征的权重赋值，本质任是线性模型。 有点： 本质任然是线性模型，便于工程兼容 缺点： 采用one-shot编码，处理类别特征是会导致特征极度稀疏，并且无法选择特征交叉，导致部分稀疏特征更加稀疏，无法收敛 参数上升了，量级从$n$上升至$n^2$。 FM数学形式： FM(w,x)=\sum_{j_1=1}^n\sum_{j_2=j_1+1}^n(w_{j_1}\cdot w_{j_2})x_{j_1}x_{j_2}$w$为$(1,k)$维向量。 优点： 引入隐向量使FM有效解决数据稀疏性问题，将权重模型减少到了$n*k$ 可以使用梯度下降学习，不失灵活性和 FFM相对于FM，引入了特征感知域的概念，使得模型的表达能力更强 FFM(w,x)=\sum_{j_1=1}^n\sum_{j_2=j_1+1}^n(w_{j_1,f_2}\cdot w_{j_2,f_1})x_{j_1}x_{j_2}FFM和FM的区别在于隐向量由原来的$w_{j_1}$变成了$w_{j_1,f_2}$，意味着每个特征对应着不是唯一的隐向量，而是一个隐向量组。吧 GBDT+LR自动化特征的开端 1、GBDT进行特征转换 将样本输入一个子树之后，回落到一个叶子结点中，将该节点置为1，其他结点置为0，然后将所有结点进行拼接，就得到一个特征向量 决策树的深度决定交叉特征的的阶数，决策树深度为4，经过3次分裂，交叉特征为3阶 传统特征工程： 进行人工或者半人工的特征组合和筛选 改造目标函数，改进模型结构，提升特征交叉的方式增强特征组合 弊端： 对算法工程师经验和经历投入要求太高了 从根本上改变模型结构，对模型设计能力要求太高 GBDT+LR的优点：特征工程由独立模型完成，实现端到端的训练。 深度学习模型深度学习模型优点： 1、表达能力更强，能够挖掘出更多的数据中潜藏的模式。 2、模型结构灵活，能够根据业务场景和数据特点灵活调整模型结构。 深度学习模型的几个发展方向 改变神经网络复杂度 改变特征交叉的方式 组合模型 FM模型的学习演化版本 注意力机制和推荐模型的结合 序列模型与推荐系统的结合 强化模型与推荐系统的结合 AutoRec 浅层神经网络，对于协同过滤，存在$m\times n$的共现矩阵，相当于神经网络中的权重$w$，使用单层神经网络具有一定的泛化能力，但是结构较简单，泛化能力存在不足。 Deep Crossing微软搜索引擎中的搜索广告推荐场景。 Deep Crossing需要解决的三个问题 1、离散类特征过于稀疏，不利于直接输入神经网络进行训练，如何解决稀疏特征稠密化？ 引入embedding层，将稀疏特征稠密化 2、如何解决特征自动交叉问题？ 引入残差网络结构，通过多层残差对各个维度进行交叉&gt;。 3、如何在输出层达成问题设定的优化目标？ 引入Scoring层，对于CTR二分类问题，采用逻辑回归模型，对于图像类多分类问题，采用softmax模型。 优点： 没有采用任何人工特征的参与。 NeuralCFNeuralCF采用多元神经网络+输出层结构代替了矩阵分解模型中简单內积操作，目的是： 让用户向量和物品向量充分交叉，得到价值更多的特征组合信息 引入更多非线性特征，让模型表达能力更强 优势： 利用神经网络的优势，可灵活组合不同的特征，按需增加或减少模型复杂度 缺点： 由于基于协同过滤的思想，没有引入其他类别特征。 PNN相对于Deep Cross，将stacking层换成了Product Layer，乘积层，里面既有内集，也有外集。 优点： 对于Embedding向量多样化交叉，定义了內积和外积操作 缺点： 特征进行了无差别交叉，一定程度的忽略了原始特征向量中包含的价值信息。 Wide&amp;DeepWide&amp;Deep设计的初衷和最大价值在于同时具有较强的记忆能力和泛化能力 记忆能力：模型直接学习并且利用历史数据中的物品和特征共现能力，例如协同过滤，可以通过历史数据计算物品和用户共现矩阵，进而通过历史数据进行推荐。 泛化能力：模型的传递特征的相关性，发觉稀疏甚至从未出现过的稀有特征和最终标签相关性能力。 Deep部分输入的是全量的特征，数值型和类别特征的embedding向量通过全连接层连接在一起。 Wide部分仅输入已安装应用和曝光应用两类特征，已安装应用表示用户历史行为，曝光应用代表当前待推荐的应用，选择这两类特征的原因是充分发挥wide的记忆能力强的有点。 Wide&amp;Deep模型的优点： （1）抓住业务本质特点，融合传统模型的记忆能力和深度模型的泛化能力 （2）模型结构不复杂，容易工程化实现 缺点： Wide部分任需要人工筛选特征 Wide&amp;Cross使用Cross网络替代原来的wide部分。设计Cross网络的目的是为了增加特征之间的交互力度，使用多层交叉层对输入向量进行特征交叉。减少人工特征。 假设$l$层交叉层的输出向量为$x_l$，那么$l+1$层的向量输出为: x_{l+1}=x_0x_l^TW_l+b_l+x_l每层均保留了输入向量，因此在输入向量和输出向量之间的差别不是特别大。 优点：可以自动进行交叉特征，避免了很多基于业务理解的人工特征。 缺点：Cross部分网络复杂度较高。 FM系列FNN为了解决Embedding训练速度慢的问题，FNN采用的思路是用FM模型训练好的个特征隐向量初始化Embedding层参数，有点类似预训练。FM的计算公式： y_{FM}=sigmod(w_0+\sum_{i=1}^Nw_ix_i+\sum_{i=1}^N\sum_{j=i+1}^Nx_ix_j优点：利用FM初始化Embedding层参数，加快训练 缺点：结构比较简单，没有针对性的特征交叉层 DeepFM采用FM优化Wide&amp;Deep模型中Wide模块，主要针对Wide部分不具备自动组合特征的能力的缺陷进行改善的。利用FM替换了原来的Wide部分，加强了浅层网络部分特征组合的能力。左边FM与右边神经网络共享相同的embedding层。FM对不同特征域两两交叉。也就是将embedding层当做原FM中隐向量。 NFMNFM的思想，利用神经网络改进FM，主要思路是利用一个表达能力更强的函数替代原FM \hat y_{FM}(x)=w_0+\sum_{i=1}^Nw_ix_i+\sum_{i=1}^N\sum_{j=i+1}^Nv_i^Tv_j\cdot x_ix_j \hat y_{MFM}(x)=w_0+\sum_{i=1}^Nw_ix_i+f(x)主要有5各模块 原始稀疏特征向量 Embedding层 特征交叉池化层 隐层 预测层 其实就是在Embedding层和多层神经网络之间增加了特征交叉池化层，具体操作如下： f_{BI}(V_x)=\sum_{i=1}^n\sum_{j=i+1}^n(x_iv_i)\odot (x_jv_j)$\odot$表示两个向量的元素积操作 (v_i\odot v_j)_k=v_{ik}v_{j_k}基于FM的深度学习模型的有点和局限性 优点： 让模型具备非常强的非线性表达能力 局限： 进行了大量基于不同特征交互操作思路的尝试，特征工程的思路已经穷尽了。 AFM在NFM模型中，对于不同的特征一视同仁，但是实际上不同的特征对于业务的影响是不一致的，因此AFM通过在NFM的特征交叉层和最终输出层加上注意力机制实现，AFM的特征交叉过程同样采用元素积操作 f_{PI}(\delta) =\{(v\odot v_j)x_ix_j\}_{(i,j)\in R_{x}}AMF加入注意力得分之后的池化过程 f_{Att}(f_{PI}(\delta))=\sum_{(i,j)\R_x}a_{i,j}(v_i\odot v_j)x_ix_j为了防止交叉特征数据稀疏问题带来的权重难以收敛，AFM在交叉层和池化层之间的注意力网络来生成注意力得分 DIN应用场景： 阿里巴巴电商广告推荐 DIN模型是在深度学习网络中加入了注意力机制，利用候选商品和历史行为相关性计算出一个权重，这个权重代表注意力的强弱。例如，广告中的商品是键盘，用户点击商品序列有几个不同的商品id，分别为鼠标、T恤和洗面奶。因此鼠标这个历史行为的商品id对于预测键盘广告的点击率重要程度大于后两者。 注意力形式化表达： V_u=f(V_a)=\sum_{i=1}^Nw_i\cdot V_i = \sum_{i=1}^Ng(V_i,V_a)\cdot V_i$V_u$是用户Embedding向量，$V_a$是候选广告商品Embedding向量，$V_i$是用户$u$第$i$次行为Embedding向量。用户行为指的是游览的商品和店铺。$w_i$由$V_i$和$V_a$的关系决定，即$w_i=g(V_i,V_a)$, g函数采用的是注意力激活单元。 优点： 在传统深度学习推荐系统模型基础上，引入了注意力机制，并利用用户历史行为和目标广告商品的相关性计算注意力得分 缺点： 没有充分利用历史行为以外的其他特征。 DIEN相比DIN，考虑到了时序信息，用户的兴趣也是随着时间变化的，因此时序信息能够 1、加强最近行为对下一次购买的预测影响 2、序列模型能够学习到购买趋势 网络结构还是输入层+Embedding层+连接层+多层全连接层+输出层 DIEN的创新点在于构建了一个兴趣进化网络。 兴趣进化网络分三层： 1、行为序列层：将原始的ID行为序列转换成Embedding行为序列 2、兴趣抽取层：通过模拟用户兴趣迁移过程，抽取用户兴趣。采用GRU，相对于LSTM参数更少 3、兴趣进化层：通过在兴趣层基础上加上注意力机制，模拟兴趣的进化过程。结构为AUGRU，在院GRU的更新门的结构上加上了注意力得分。 优点： 考虑到了时序信息 缺点： 序列模型训练起来比较复杂]]></content>
      <categories>
        <category>机器学习</category>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
        <tag>阅读笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[特征工程之特征选择]]></title>
    <url>%2F2020%2F08%2F05%2F%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E4%B9%8B%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%2F</url>
    <content type="text"><![CDATA[​ 特征选择，即对于生成的特征集合进行筛选，得到一个子集，主要有一下三个目的 简化模型，增加可解释性 改善性能，并且节省存储空间和计算开销 改善通用性，降低过拟合风险。 特征选择主要分为三种方法，过滤方法、封账方法和嵌入方法过滤方法Filter过滤方法主要特点： 不依赖与机器学习算法 一般分为单变量和多变量 单变量一般基于特征变量与目标变量之间的相关性或互信息，根据相关性排序，过滤掉最不相关特征 多变量有基于相关性和一致性的特征选择 单变量覆盖率一般来说，会把缺失率15%-20%左右的特征丢弃掉，不过不是绝对的，也可以通过其他特征的关系或者利用模型预测对缺失值进行补齐。 1234cols = data.columns.values.tolist()missing_rate = pd.DataFrame(&#123;'column_name':cols&#125;)for c in cols: missing_rate.loc[missing_rate['column_name']==c,'missing_rate'] = data[data[c].isna()==True].shape[0]/data.shape[0] 皮尔逊相关系数皮尔逊相关性系数用于度量两个变量$X$和$Y$的线性相关性，计算公式为 \rho_{X,Y}=\frac{cov(X,Y)}{\sigma_X\sigma_Y}样本上的相关性系数为 r=\frac{\sum_{i=1}^n(X_i-\bar X_i)(Y_i-\bar Y_i)}{\sqrt{(\sum_{i=1}^n(X_i-\bar X_i)^2)}\sqrt{(\sum_{i=1}^n(Y_i-\bar Y_i)^2)}}在数据标准化（ ）后，Pearson相关性系数、Cosine相似度、欧式距离的平方可认为是等价的。 如何理解皮尔逊相关系数（Pearson Correlation Coefficient）？ - 微调的回答 - 知乎 https://www.zhihu.com/question/19734616/answer/349132554 使用方法 123from scipy.stats import pearsonrr,p = pearsonr(X,Y) r表示相关性系数 r&gt;0表示正相关 r=1表示正线性相关 r&lt;0表示负相关 r=0表示非线性相关。 r=-1表示负线性相关 p-value越低表示越低，可靠性越高。https://www.cnblogs.com/lijingblog/p/11043513.html Fisher得分在分类问题中，对于好的特征，在同一类别中取值比较相似，在不同类别中取值差异较大。因此特征i的重要性可以用Fisher得分$S_i$表示： S_i=\frac{\sum_{j=1}^Kn_j(u_{ij}-u_i)^2}{\sum_{j=1}^Kn_j\rho^2_{ij}}$u_{ij}$和$\rho_{ij}$分别表示特征$i$在类别$j$中的中的均值和方差，$n_j$表示类别$j$的样本数，Fisher特征越高，特征在不同类别的差异性越大，在同一类别的差异性越小。 卡方检验目的：检验特征变量和目的变量之间的相关性 公式为： \chi^2=\sum_{i=1}^r\sum_{j=1}^c\frac{(O_{i,j}-E_{i,j})^2}{E_{i,j}^2}其中$O_{i,j}$表示观测值，$E_{i,j}$表示期望值，$i$表示类别$i$，$j$表示对应的目标变量$j$。如何假设正确，$\chi$越小，相关性越小。 1234567from sklearn.feature_selection import SelectKBestfrom sklearn.feature_selection import chi2from sklearn.datasets import load_irisiris = load_iris()model1 = SelectKBest(chi2, k=2)#选择k个最佳特征model1.fit_transform(iris.data, iris.target) 互信息用于度量两个变量之间的相关性，互信息越大，表示两个变量的相关性越高，互信息为0，表示两个变量相互独立。 互信息计算公式： I(X,Y)=\sum_{x\in X}\sum_{y\in Y}p(x,y)log\frac{p(x,y)}{p(x)p(y)}其中$X、Y$的联合分布为$p(x,y)$，边缘分布为$p(x),p(y)$。 12from sklearn import metrics as mrmr.mutual_info_score(Y,X) 多变量最小冗余最大相关性mRmR相关特征选择(CFS)相关特征选择(Correlation Feature Selection，CFS)基于以下假设来评估集合的重要性：好的特征集合包含于目标变量非常相关的特征，但这些特征彼此不想关。 公式如下： CFS=\max_{S_k}[\frac{r_{cf_1}+r_{cf_2}+...+r_{cf_k}}{\sqrt{k+2(r_{f_1f_2}+r_{f_if_j}+...+r_{f_kf_1})}}其中$r_{cf_i}$和$r_{f_if_j}$分别表示特征变量和目标变量之间的相关性以及特征变量与特征变量之间的相关性。 这部分代码暂时没有搞懂，后续在研究。 1234567891011121314import numpy as npfrom skfeature.function.statistical_based import CFSfrom sklearn.datasets import load_iris # 利用iris数据作为演示数据集# 载入数据集iris = load_iris()X, y = iris.data, iris.targettrain_set = X[0:100,:]test_set = X[100:,]train_y = y[0:100]num_feature = 2 # 从原数据集中选择两个变量feature_index = CFS.cfs(train_set, train_y) FCBFFCBF算法： 全称 Fast Correlation-Basd Filter Solution, 是一种快速过滤的特征选择算法，一种基于symmetrical uncertainty（SU）的方法。其计算步骤如下： 1、计算每个特征与目标C之间的相关性$SU_{F_i,c}$ SU(X,Y)=2\frac{IG(X,Y)}{E(X)+E(Y)} \\E(x)=-\sum_{i=1}^cPx_i()*\log_2(P_{X_i}) \\E(X|Y)=-\sum_{i=1}^{C_Y}P(y_i)\sum_{j=1}^cP(x_j|y_i)\log_2(P(x_j|y_i))其中$IG(X,Y)$代表信息增益，$E(X)$代表信息熵，$P(X_i)$表示$X$取到$i$的概率，$c$为类别数目 2、将最大相关性的特征预先使用$\delta$选择出来 3、将$SU_{F_i,c}$按照大小排序，并且计算每个特征$F_i$与排序中SU小于$SU_{}$的特征$F_j$之间的相关性$SU_{F_i,F_j}$，如果$SU_{F_i,c}&gt;SU_{F_j,c}$,计算$SU_{F_i,F_j}$ 4、如果$SU_{F_i,F_j}&gt;SU_{F_j,c}$，删除特征$F_j$ 封装方法Wrapper封装方法直接利用机器学习算法评价特征子集的效果，它可以检测两个或者多个特征之间的相互关系，而且选择的特征子集让模型效果运行达到最优 确定性算法序列前向特征选择(SFS)和序列后向特征选择(SBE)序列向前算法，特征子集从空集开始，每次只加入一个特征， 随机算法退火算法遗传算法遗传算法步骤： 1、初始化种群 一个种群有好几条染色体，假设有m个初始特征，那么染色体为一个m*1的一维向量[0,1,0,1,….1]，全部由0或者1组成，初始化时，0和1随机选择。 2、评估种群中个体适合度 用交叉检验cross_val_score(个体，y)的结果作为适应度。适应度计算类似LDA 3、选择 每条染色体的适应度不同，被选择的概率也不同，用轮盘赌选择，先生成与染色体个数相同的随机数个数，先生成与染色体个数（种群大小）相同的随机数然后再一个个看这些随机数落在哪个染色体的范围内例：染色体的选择概率：①[0,0.3), ②[0.3,0.6), ③[0.6,0.7), ④[0.7,0.9), ⑤[0.9,1]生成的随机数：0.2, 0.4, 0.5, 0.78, 0.8被选中的染色体：①, ②, ②, ④, ④ 5、交叉 若第i条与第i+1条染色体发生交叉，随机选择交叉点，然后交叉。 例如 父染色体 a:[0,1,0,0,1] b:[1,0,1,1,1] 交叉之后的染色体为[0,1,0,1,1] 6、变异 染色体的某个点取反。目的是防止局部最优 蚁群算法蚁群算法的基本思想： 1、蚂蚁在路径上释放信息素。 2、碰到还没走过的路口，就随机挑选一条路走。同时，释放与路径长度有关的信息素。 3、信息素浓度与路径长度成反比。后来的蚂蚁再次碰到该路口时，就选择信息素浓度较高路径。 4、最优路径上的信息素浓度越来越大。 5、最终蚁群找到最优寻食路径。 嵌入方法Embedded嵌入方法将特征选择嵌入到模型的构建过程当中，具有封装方法与机器学习方法相结合的有点，而且具有过滤方法计算效率高的有点，避免了前面两种方法的不足。 LASSO方法及线性回归+L1范数，具体原理就不细讲了。 123456789101112from sklearn.linear_model import Lassofrom sklearn.preprocessing import StandardScalerfrom sklearn.datasets import load_bostonboston = load_boston()scaler = StandardScaler()X = scaler.fit_transform(boston["data"])Y = boston["target"]names = boston["feature_names"]lasso = Lasso(alpha=.3)lasso.fit(X, Y) 基于树模型的特征选择树模型本身可以进行特征选择，配合sklearn中的SelectFromModel可以进行特征选择。 1、结合SelectFromModel SelectFromModel的作用是训练基础模型，得到系数较高的特征 1234567from sklearn.feature_selection import SelectFromModelfrom sklearn.ensemble import GradientBoostingClassifierfrom sklearn.datasets import load_iris iris = load_iris()gbdt = GradientBoostingClassifier()SelectFromModel(gbdt).fit_transform(iris.data,iris.target) 2、结合相关系数 主要分为一下几步： 第一次训练lightGBM，得到特征重要性 挑选重要性比较高的特征，计算特征相似度，热力图也行 筛选掉相似度过高的特征 将筛选之后的特征送入lightGBM重新训练 参考资料 1、https://www.cnblogs.com/hhh5460/p/5186226.html 2、https://www.kaggle.com/juliaflower/feature-selection-lgbm-with-python/comments 3、美团机器学习实践 4、https://blog.csdn.net/u012017783/article/details/71872950 5、https://www.cnblogs.com/holaworld/p/12631851.html 6、https://zhuanlan.zhihu.com/p/33042667 7、https://www.cnblogs.com/heaad/archive/2010/12/20/1911614.html 8、https://www.cnblogs.com/holaworld/p/12631933.html]]></content>
      <categories>
        <category>数据挖掘</category>
      </categories>
      <tags>
        <tag>特征工程</tag>
        <tag>数据挖掘</tag>
        <tag>特征选择</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[特征工程之特征构建]]></title>
    <url>%2F2020%2F07%2F11%2F%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E4%B9%8B%E7%89%B9%E5%BE%81%E6%9E%84%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[类别特征 几乎总是需要做一些处理 类别特征种类过多会造成稀疏数据 难以填充缺失值 热独编码(Onehot-encoding) 通常和大多数线性算法一起使用 稀疏格式对内存友好 大多数方法无法处理缺失或者不可见数据 对于没有大小区分的类别特征，可以使用Oneshot-encoding 哈希编码(Hash encoding) 固定长度的oneHot-encoding 避免数据过度稀疏 碰撞通常会降低准确率，但是也能提高 可以很好地处理新变量 Label encoding 给每个类别变量一个唯一的数字ID 对于非线性树模型比较有用 不会增加数据维度 随机化映射 car_var-&gt;num_id的映射，在训练，平均，对精度能有小提升(小提升) 计数编码(Count encoding) 在训练集中用他们的统计量替代类别特征 对于线性和非线性算法都有用 对于异常值很敏感 增加log转换，对于统计量可能更好 用1替代无法观测数据 可能会造成冲突，同一个编码，不同的变量值 计数排名编码(LabelCount encoding) 通过统计量给类别特征排序 对于线性和非线性算法都有用 对异常值不敏感 不会给同一个变量不同的值 Category Embedding 使用神经网络对类别特征创建一个稠密的embeddings，找到不同类别特征关联性 NaN encoding： 给NaN 值一个明确的编码，而不是忽略 NaN里面也包含信息 小心过拟合 仅仅当训练集和测试集NaN都是同样的原因造成，或者本地验证结果证明NaN包含信息(即这种方法是有效果的) 数字特征 对于算法更可读 很容易填补缺失值 截断(Rounding) 对数字变量四舍五入 有损压缩，保留数据最重要的特征 有时候精度太准确只是噪声 四舍五入后的变量能够当成类别特征处理 在四舍五入之前可以进行log转换 分桶(Binning) 对数据进行分桶，并且赋予一个分桶ID 分桶能够使用分位数或者模型来找到最佳分桶 能够很好地处理超出训练集范围的数据 分桶的作用，当一个特征的数值比较大，但是模型对数值比较敏感的时候，最好的方法是分桶，将数值变量分配到一个桶里。 缩放(Scaling) 将数字变量缩放到一个明确的范围 Standard(Z) Scaling MinMax Scaling Root Scaling Log Scaling 原因：因为部分模型例如线性回归、逻辑回归等对于数据输入比较敏感将数值缩放到一个维度， 标准化Standarisation和归一化Normalisation 归一化的原因 当变量维度不同的时候，对模型产生的作用不一致，这时候需要归一化 神经网络在特征缩放之后训练速度更快 特征缩放的时机 KNN K-means NN 树模型不需要特征缩放 填充(Imputation) 对缺失值进行填充 硬编码能够和填充结合起来 Mean：最常见的 Median：对于异常值更有鲁棒性 Igonre：忽略，后面在处理或者不处理？ 使用模型对结果进行预测，然后填充 交叉(Interaction) 对数字变量之间的相互影响进行编码 尝试加减乘除 使用特征选择：统计测试、或者已经训练好的特征重要性 忽略主观意愿和奇怪的关联能够有明显提升 高斯转换 一些机器学习模型假设数据是正态分布的，例如linear和logistic回归 高斯分布能够帮助机器学习下模型表现得更好 集中不同的转换 Logarithmic Transformation Reciprocal Transformation Square Root Transformation Exponential Transformation Boxcox Transformation 相关问题： 1.为什么要做对数变换 https://www.zhihu.com/question/22012482 https://tianchi.aliyun.com/notebook-ai/detail?postId=62338 异常值(Outlier)1、异常点是否需要清除，需要结合具体业务 2、异常点的定义 高于1.5倍的第三分位数和第一分位数之差 与均值的差小于三倍的标准差 3、异常值存在的原因 数据多样性 测量错误 4、异常点的影响 在统计分析的时候造成多种问题 对于数据均值和标准差影响比较大 5、找出异常值 IQR z score Scatter plots Box plot 时间特征 日起相关特征，节假日之类 lag feature，根据业务决定选择lag1、lag2、。。。。 检查lag函数重要性两种方法 ACF，Autocorrelation Function PACF, Partial Autocorrelation Function rolling windows 滑动窗口 Expanding windows 空间特征 欧氏距离 球面距离 曼哈顿距离 geohash 文本特征N-GramN-Gram是一种基于统计语言模型的算法。它的基本思想是将文本里面的内容按照字节进行大小为N的滑动窗口操作，形成了长度是N的字节片段序列。 每一个字节片段称为gram，对所有gram的出现频度进行统计，并且按照事先设定好的阈值进行过滤，形成关键gram列表，也就是这个文本的向量特征空间，列表中的每一种gram就是一个特征向量维度。 该模型基于这样一种假设，第N个词的出现只与前面N-1个词相关，而与其它任何词都不相关，整句的概率就是各个词出现概率的乘积。这些概率可以通过直接从语料中统计N个词同时出现的次数得到。常用的是二元的Bi-Gram和三元的Tri-Gram。 词袋模型词袋模型可以理解为将文本拆成一个个的词语，然后用一个个词作为字典来表达文本 ，字典中的词没有特定的顺序，也舍弃了句子总体结构。其中TF-IDF是一种表示方式 TF-IDF用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度 TF-IDF的核心思想是：如果某个词或短语在一篇文章中出现的频率TF高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。TF-IDF实际上是：TF*IDF。TF是词频(Term Frequency)，指的是特定词语在该文件中出现的频率。 tf_{i,j}=\frac{n_{i,j}}{\sum_{k}n_{n,j}}其中$tf_{i,j}$表示词i出现在文章j中的次数，分母表示文章j中出现档次数量总和。 IDF是逆文本频率指数(Inverse Document Frequency)。IDF的意思是在文档集D中，包含词i的数量越少，词i对于文档集越重要，此时更好区分。 idf_i=log\frac{|D|}{|{j:t_i\in d_j}|}$|D|$表示所有文档数量，文档集中出现此$t_i$的文档数。 余弦相似度Jaccard相似度定义：两个文档中相交的单词个数除以两个文档单词总数之和 J(d_1,d_2)=\frac{|d_1\cap d2|}{|d1 \cup d2|}Jaccard距离 d_j(d_1,d_2)=1-J(d_1,d_2)=\frac{|d_1\cup d2| - |d_1 \cap d_2|}{|d_1\cup d_2|}编辑距离衡量两个字符串相似度的指标，指的是两个字符串有一个字符串转成另外一个字符串需要的最少编辑操作(插入、删除、替换)次数 推荐系统中的特征工程推荐系统中特征工程主要分为以下几个部分 用户行为数据 用户关系数据 属性标签数据，类似性别年龄、爱好等 内容数据(多模态,通过cv、nlp等技术识别图片和文本中的信息) 上下文信息，时间、地点、重大事件等。 统计类特征 组合特征 参考资料 1、https://www.kaggle.com/pavansanagapati/feature-engineering-a-comprehensive-tutorial/notebook 2、美团机器学习实践 3、词袋模型 4、百面机器学习]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>特征工程</tag>
        <tag>数据挖掘</tag>
        <tag>特征构造</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[word embedding作用及用法]]></title>
    <url>%2F2020%2F06%2F07%2Fword-embedding%E4%BD%9C%E7%94%A8%E5%8F%8A%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[关于word embedding总结词向量表示词语的向量都可以称为词向量，one shot向量和distributed向量都可以表示为词向量热编码表示(one shot)优点 解决了分类器不好解决离散数据的问题， 起到了扩充特征的作用 缺点： 首先，它是一个词袋模型，不考虑词与词之间的顺序(文本中词的顺序信息非常重要) 其次假设词与词之间是独立的(大多数情况下，词与词之间是相互影响的) 最后得到的特征是系数的 分布式表示核心思想 通过训练将某种语言中的每一个词映射成一个固定长度的短向量（当然这里的“短”是相对于 one-hot representation 的“长”而言的），将所有这些向量放在一起形成一个词向量空间，而每一向量则为该空间中的一个点，在这个空间上引入“距离”，则可以根据词之间的距离来判断它们之间的（词法、语义上的）相似性了。 基于矩阵的分布表示基于聚类的分布表示基于神经网络的分布表示1、基本概念 基于神经网络的分布表示一般称为word embedding(词嵌入)或者distributed representation 2、word2vec 两种方式 CBOW:输入一个词上下文，输出这个词 Skip-Gram：输入一个词输出这个词的上下文 embedding layer：和word2vec一样 embedding layer和word2vec 参考资料1、DeepNLP的表示学习·词嵌入来龙去脉·深度学习（Deep Learning）·自然语言处理（NLP）·表示（Representation） 2、word2vec 中的数学原理详解 3、秒懂词向量本质]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>NLP</tag>
        <tag>词向量</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lightGBM论文总结]]></title>
    <url>%2F2020%2F03%2F10%2Fxgboost%E5%92%8ClightGBM%2F</url>
    <content type="text"><![CDATA[LightGBM提出动机为了解决GBDT在海量数据中遇到的问题，让GBDT算法更好的适用于工业实践。1、XGBoost的缺点 需要保存特征值和排序结果，还需要保存排序的索引 每次分裂一个点的时候，都需要计算收益 对cache优化不友好，容易造成cache miss 2、LightGBM的优化 单边梯度采样GOSS 直方图算法 互斥特征捆绑算法 Leaf-Wise分裂算法 类别特征最有分裂 并行学习优化 cache命中率优化 2. 数据原理2.1.基于直方图的算法对于XGBoost，其实现是预排序算法，LiggtGBM是基于直方图的算法。 直方图算法计算过程 遍历每一个叶子结点的每一个特征 为每一个特征创建一个直方图，将样本的梯度($g_i$)之和和样本数$n$保存到bin中 然后遍历所有的bin，以当前的bin作为分裂点，然后计算分裂后的左右节点梯度和节点数目 通过直方图加速法算出左右节点的梯度和$S_L$和$S_R$，已经bin的数量 计算分裂后的收益$loss=\frac{S_L^2}{n_L}+\frac{S_R^2}{n_R}-\frac{S_P^2}{n_p}$ 其实，思想和xgb差不多，在选择分裂点的时候，xgb用的是预排序算法，lgb用的是梯度直方图。 然后在计算上的代价也大幅降低，预排序算法每遍历一个特征值就需要计算一次分裂的增益，而直方图算法只需要计算k次（k可以认为是常数），时间复杂度从O(#data#feature)优化到O(k#features)。 直方图离散化优点： 占用内存更小，相对于XGBoost预排序算法，无需存储特征值和排序索引 计算代价更小，预排序算法需要每遍历一个特征值，就计算一次收益，而直方图算法只用计算K次，时间复杂度有O(data feature)下降到O(k feature) 当然，Histogram算法并不是完美的。由于特征被离散化后，找到的并不是很精确的分割点，所以会对结果产生影响。但在不同的数据集上的结果表明，离散化的分割点对最终的精度影响并不是很大，甚至有时候会更好一点。原因是决策树本来就是弱模型，分割点是不是精确并不是太重要；较粗的分割点也有正则化的效果，可以有效地防止过拟合；即使单棵树的训练误差比精确分割的算法稍大，但在梯度提升（Gradient Boosting）的框架下没有太大的影响。 2.2 单边梯度采样GOSS对于GBDT的数据，梯度越大，说明训练误差越大，这样的样本对模型的提升也越大(adaboost思想)，因此GOSS的算法的思想是保留梯度交大的样本，然后在剩余梯度较小的样本中进行采样。不直接丢掉梯度较小的样本数据的原因是会影响数据总体分布。 具体流程 首先将分裂的特征按照绝对值大小进行排序 选择梯度最大的a%的数据 在剩余的数据中随机挑选b%个数据 然后对于梯度较小的数据，乘以1个常数$\frac{1-a}{b}$ 最后将挑选出来的数据进行合并，计算信息增益 2.3 互斥特征捆绑算法互斥捆绑算法的目的是为了减少特征维度，因为实际任务中，特征一般是高维稀疏的。 对于完全互斥的特征，可以将其捆绑起来，例如one-shot产生的特征，捆绑之后不会造成信息丢失。 对于不完全互斥的特征，存在部分情况下两个特征都为非0值，可以使用冲突比率（同时不为0的样本数之和/所有样本数）对不互斥程度进行衡量，当小于一定值时，可以将两个不完全互斥的特征捆绑。 对于特征捆绑，有两个问题 1、如何确定哪些特征需要绑在一起 2、如何构建绑定后的特征 对于第一个问题，确定那些问题需要绑定，LightGBM的做法如下 1、构建一个无向加权图，顶点表示特征，边的权值大小表示冲突比率 2、基于特征在图中的度数进行降序排序 3、遍历每个捆绑特征，检查捆绑之后特征数是否小于最大冲突数 冲突数小于K，将该特征添加到捆绑 冲突数大于K，创建新的捆绑特征 对于第二个问题，如何构建绑定后的特征，关键在于如何从绑定后的特征识别出原始特征中的值。基于直方图算法存储的是离散的箱子，而不是连续的特征值。LightGBM是基于特征从属于不同的箱子来构建捆绑特征的。假设特征A的原始特征取值空间为[0,10),特征B的取值空间为[0,20)，当 此时可以在特征B的区间上加上偏置10，此时B的取值空间为[10,20)，而AB绑定后的特征取值空间为[0,30)。 EFB算法可以将很多互斥稀疏特征捆绑成少量稠密特征，避免针对特征值0的不必要计算。虽然可以优化基于直方图的算法，使用一张表保存每个特征非0取值，然后通过扫描这张表来构建直方图，这样时间复杂度就从原来的O(data)变成了O(no_zero_data)，缺点在于需要额外的算力和空间保存和更新这张表。LGB将其作为辅助功能。 2.4 Leaf-Wise分裂算法 2.5 类别特征最优分裂这部分没怎么看懂，参考的 离散特征建立直方图的过程：统计该特征下每一种离散值出现的次数，并从高到低排序，并过滤掉出现次数较少的特征值, 然后为每一个特征值，建立一个bin容器, 对于在bin容器内出现次数较少的特征值直接过滤掉，不建立bin容器。 计算分裂阈值的过程： 先看该特征下划分出的bin容器的个数，如果bin容器的数量小于4，直接使用one vs other方式, 逐个扫描每一个bin容器，找出最佳分裂点; 对于bin容器较多的情况, 先进行过滤，只让子集合较大的bin容器参加划分阈值计算, 对每一个符合条件的bin容器进行公式计算(公式如下: 该bin容器下所有样本的一阶梯度之和/该bin容器下所有样本的二阶梯度之和 + 正则项(参数cat_smooth)，这里为什么不是label的均值呢？其实上例中只是为了便于理解，只针对了学习一棵树且是回归问题的情况， 这时候一阶导数是Y, 二阶导数是1)， 3 工程优化3.1 并行学习优化LightGBM 提供以下并行学习优化算法： 特征并行适用于数据量比较少，feature比较多 传统的特征并行算法旨在于在并行化决策树中的“ Find Best Split.主要流程如下: 垂直划分数据（不同的机器有不同的特征集） 在本地特征集寻找最佳划分点 {特征, 阈值} 本地进行各个划分的通信整合并得到最佳划分 以最佳划分方法对数据进行划分，并将数据划分结果传递给其他线程 其他线程对接受到的数据进一步划分 然而，该特征并行算法在数据量很大时仍然存在计算上的局限。因此，建议在数据量很大时使用数据并行。 数据并行适用于大数据，feature比较少 数据并行旨在于并行化整个决策学习过程。数据并行的主要流程如下： 水平划分数据 线程以本地数据构建本地直方图 将本地直方图整合成全局整合图 在全局直方图中寻找最佳划分，然后执行此划分 数据并行的缺点 机器的通讯开销大约为 “O(#machine #feature #bin)” 。 如果使用集成的通讯算法（例如， “All Reduce”等），通讯开销大约为 “O(2 #feature #bin)”[8] 。 投票并行大数据并且feature比较多 基于投票的并行是对于数据并行的优化，主要分为两步： 通过本地数据，找到本地top k的特征 利用投票筛选出可能是全局最优点的特征 合并直方图时，只合并被选出来的部分 3.2 Cache命中率优化预排序算法： 不同的特征访的梯度顺序不同 对于索引表的访问，pre_sort使用了行号和叶子节点的索引表 都是随机访问，容易造成cache miss lightGBM对直方图优化： 梯度直方图不需要对梯度进行排序 直方图算法不需要数据到叶子id的索引表 4 XGBoost和LightGBM区别 xgboost是预排序算法，lightGBM是直方图算法。 分裂方式，xgb是level-wise，lgb是Leaf-Wise lgb支持类别特征 采用了单边梯度采样和互信息捆绑进行优化 并行化，feature在节点进行分裂的时候采用了多线程并行化，而lgb采用了特征并行、数据并行、投票并行 基于分裂算法的不同，lgb对cache命中更加高效 参考1、https://cloud.tencent.com/developer/article/1528372 2、https://mp.weixin.qq.com/s/M25d_43gHkk3FyG_Jhlvog 3、https://www.biaodianfu.com/lightgbm.html 4、https://www.zhihu.com/question/266195966 5、https://lightgbm.apachecn.org/#/docs/4 6、直方图算法深入理解]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>决策树</tag>
        <tag>Xgboost</tag>
        <tag>lightGBM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[XGBoost原理总结]]></title>
    <url>%2F2020%2F03%2F09%2FXGBoost%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Xgboost, 是GBDT的一种实现方式，并且xgboost做了一些改进和优化。1. 原理1.1 优化目标函数对于GBDT方法，都是基模型组成的加法公式。 \hat y_i = \sum_{i=1}^kf_t(x_i)\tag{1}其中$f_k$为基模型,$y_i$表示第$i$个样本预测值。正则化损失函数 \zeta^t=\sum_{i=1}^n l(y_i,\hat y_i^{(t-1)})+\Omega(f_t)\tag{2}对于损失函数（2）进行二阶展开有： \zeta^{(t)} \approx \sum_{i=1}^n[l(y_i,\hat y_i) +g_if_t(x_i)+\frac{1}{2}h_if_t^2(x_i)]+\Omega(f_t) \\ where\quad \Omega(f)=\gamma T+\frac{1}{2}\lambda||w||^2\tag{3}对于损失函数，xgboost在处理的时候进行了二阶展开，其中$g_i=\frac{\partial l(y_i,\hat y_i^{(t-1)})}{\partial \hat y_i^{(t-1)}}$, $h_i=\frac{\partial ^2l(y_i,\hat y_i^{(t-1)})}{\partial (\hat y_i^{(t-1)})^2}$。其中$g_i$和$h_i$分别对应一阶倒和二阶倒数，正则项$T$表示叶子节点数目，$w$表示叶子的分数。$\gamma$空值叶子节点的个数，保证叶子节点不会过多分裂，而$\lambda$空值叶子结点的分值，避免分值过大造成过拟合。 对于第$t$步而言，前面的$t-1$步已经固定，因此有一阶、二阶梯度$g_i$和$h_i$为一个常数。因此目标函数可以化简为 \hat \zeta^t=\sum_{i=1}^n[g_if_t(x_i)+\frac{1}{2}h_if_t^2(x_i)]+\Omega(f_t)\tag{4}定义$I_j=\{x|q(x_i)=j\}$,表示为叶子结点$j$中的样本。所以上式(3)可以重写为 \hat\zeta^{(t-1)}=\sum_{i=1}^n[g_if_t(x_i)+\frac{1}{2}h_if^2_t(x_i)]+\gamma T + \frac{1}{2}\lambda \sum_{j=1^T}w_j^2\tag{5} =\sum_{j=1}^T[(\sum_{i\in I_j}g_i)w_j+\frac{1}{2}(\sum_{i\in I_j}h_i+\lambda)w_j^2]+\gamma T \tag{6}这里其实进行了一个转换，对于公式5而言，计算的损失函数是将所有数据得到损失函数。对于决策树，样本最终会落到叶子结点，因此公式6是通过叶子节点求损失值。 对于固定结构的$q(x)$，即改树节点时固定的，可以计算叶子结点$j$的最优权重$w_j^*$ w_j^*=-\frac{2\sum_{i\in I_j}g_i}{\sum_{i\in I_j}h_i+\lambda}将结果带入上式6有 \hat \zeta^{(t)}=-\frac{1}{2} \sum_{j=1}^T\frac{(\sum_{i\in I_j}g_i)^2}{\sum_{i\in I_j}h_i+\lambda}\tag{7}定$G_j=\sum_{i\in I_j}g_i$,$H_j=\sum_{i\in I_j}h_i$，则有 w_j^*=-\frac{G_j}{H_j+\lambda}将上式带入公式7化简有 \zeta^{(t)}=-\frac{1}{2}\sum_{j=1}^T\frac{G_j^2}{H_j+\lambda}\tag{8}对于Xgboost使用泰勒展开的原因是因为想统一损失函数的形式，方便自定义损失函数。 1.2最佳切分点算法xgboost支持两种实现，贪心算法和近似算法。sklearn中GBDT是贪心算法 1）贪心算法，和GBDT一样，暴力枚举 1、对于所有叶子节点枚举可用的特征，并且将特征值按照升序排序 2、计算节点分裂时候的收益 3、选择收益做大的节点和特征进行分裂 4、重复1，直到分裂结束 关键点在于对收益的计算 假设某一节点完成分裂，在分裂前，其目标函数为 L(y,\hat y_i)=-\frac{1}{2}[\frac{(G_L+G_R)^2}{H_L+H_R+\lambda}]+\gamma\tag{9}分裂后的目标函数为 L=-\frac{1}{2}[\frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda}]+2\gamma\tag{10}所以分裂一个节点的收益可以从用式（9）-（10） Gain=-\frac{1}{2}[\frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda}-\frac{(G_L+G_R)^2}{H_L+H_R+\lambda}]-\gammaG表示所有叶子节点的梯度 2)近似算法 作用在于选择，当数据量比较大，无法全部读入内存时，给出近似最优解。对比贪心算法，可能在精度上有所缺失，但是提升了速度，降低了内存消耗。 该算法的核心思想是根据特征分布的分位数提出候选点，然后将特征映射到候选划分的桶之中，然后统计桶中的聚合信息(指的前面的$g$和$h$)，找到所有区间最佳分裂点。 1、对于特征k根据分位数找到候选集合 2、将样本映射到改候选集合对应的分区桶中 该算法有两种变体，区别在于何时剔除候选点： Global：在初始阶段就给出所有候选节点，并且在后续分裂中使用相同的分裂节点。 Local：每次分裂重新提出候选节点 分位图 加权分位图： 由于前面我们知道目标函数为 L=\sum_{i=1}^n[g_if_t(x_i)+\frac{1}{2}h_if_t^2(x_i)]+\Omega(f_t)\tag{11}由于$g_i$和$h_i$是有上一轮迭代得到，因此都是常数，所以上式可以变形为： L\approx\sum_{i=1}^n\frac{1}{2}h_i[(f_t(x_i)+\frac{g_i}{h_i})^2]+\Omega(f_t)+C \\C=-\frac{g_i^2}{h_i}\tag{12}这样损失函数就变成了加权的形式，因此对于每个样本，其实权值是不等的，所以采用加权分位图。 1.3 稀疏感知分裂在实际问题中，通常输入数据都是稀疏的，造成稀疏的原因有： 数据缺失 一些统计量常常为0 特征工程的结果，如one-shot 稀疏感知算法的目的是给每个节点一个默认的分裂方向，其思想非常简单，就是分别计算缺失值样本分裂到左边或者右边是的收益，选择收益大的一个分支作为最优缺省值方向 2. 工程优化2.1 块结构设计树学习中最耗时的部分是数据排序。为了减少排序的成本，我们提出将数据存储在内存单元中，称之为block。每个block中的数据每列根据特征取值排序，并以压缩列（CSC）格式储存。这种输入数据布局只需要在训练前计算一次，可以在后续迭代中重复使用。 每个块包含一个或者多个已经排好序的特征 缺失值将不在进行排序 每个特征值都会存储样本梯度统计值索引 因为每个特征都是独立存放，因此在选择特征进行分裂的时候可以分布式实现 2.2 缓存方法优化算法是通过行索引提取梯度统计量，但是在排序之后就会乱掉，不能够直接访问。并且当统计量没法放进CPU缓存是，会导致访问失败，因此xgb给每个线程分配一个内部缓冲区。 2.3 核外快计算方式对于数据量比较大的数据，没有办法存储到内存，可以考虑部分读取，将数据存储到硬盘，但是硬盘读取会占用大量时间 XGBoost采用两种方式降低硬盘读取开销 1、块压缩：对Block进行案列压缩，并且在读取时解压 2、块拆分：将每个块存储到不同的磁盘，然后从多个磁盘读取增加吞吐量。 3. GBDT和XGBoost区别 传统GBDT以CART作为基分类器，xgboost还支持线性分类器，这个时候xgboost相当于带L1和L2正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）。 传统GBDT在优化时只用到一阶导数信息，xgboost则对代价函数进行了二阶泰勒展开，同时用到了一阶和二阶导数。顺便提一下，xgboost工具支持自定义代价函数，只要函数可一阶和二阶求导。 xgboost在代价函数里加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、每个叶子节点上输出的score的L2模的平方和。从Bias-variance tradeoff角度来讲，正则项降低了模型的variance，使学习出来的模型更加简单，防止过拟合，这也是xgboost优于传统GBDT的一个特性。 Shrinkage（缩减），相当于学习速率（xgboost中的eta）。xgboost在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间。实际应用中，一般把eta设置得小一点，然后迭代次数设置得大一点。（补充：传统GBDT的实现也有学习速率） 列抽样（column subsampling）。xgboost借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算，这也是xgboost异于传统gbdt的一个特性。 对缺失值的处理。对于特征的值有缺失的样本，xgboost可以自动学习出它的分裂方向。 xgboost工具支持并行。boosting不是一种串行的结构吗?怎么并行的？注意xgboost的并行不是tree粒度的并行，xgboost也是一次迭代完才能进行下一次迭代的（第t次迭代的代价函数里包含了前面t-1次迭代的预测值）。xgboost的并行是在特征粒度上的。我们知道，决策树的学习最耗时的一个步骤就是对特征的值进行排序（因为要确定最佳分割点），xgboost在训练之前，预先对数据进行了排序，然后保存为block结构，后面的迭代中重复地使用这个结构，大大减小计算量。这个block结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行。 可并行的近似直方图算法。树节点在进行分裂时，我们需要计算每个特征的每个分割点对应的增益，即用贪心法枚举所有可能的分割点。当数据无法一次载入内存或者在分布式情况下，贪心算法效率就会变得很低，所以xgboost还提出了一种可并行的近似直方图算法，用于高效地生成候选的分割点。 调参技巧略，直接看API就行了。。。。懒得总结了 参考资料 [1].https://www.zhihu.com/question/41354392/answer/98658997 [2].https://mp.weixin.qq.com/s/LoX987dypDg8jbeTJMpEPQ [3].行抽样、列抽样]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>决策树</tag>
        <tag>GBDT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop数据倾斜及解决办法]]></title>
    <url>%2F2019%2F12%2F15%2Fhadoop%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95%2F</url>
    <content type="text"></content>
      <categories>
        <category>hadoop</category>
        <category>hive</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于决策树总结]]></title>
    <url>%2F2019%2F11%2F04%2F%E5%85%B3%E4%BA%8E%E5%86%B3%E7%AD%96%E6%A0%91%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[决策树处理连续值]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>决策树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[梯度提升树]]></title>
    <url>%2F2019%2F10%2F10%2FGBDT%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[GBDT主要由三个概念组成：Regression Decistion Tree（即DT)，Gradient Boosting（即GB)，Shrinkage（算法的一个重要演进分枝，目前大部分源码都按该版本实现）。搞定这三个概念后就能明白GBDT是如何工作的，要继续理解它如何用于搜索排序则需要额外理解RankNet概念，之后便功德圆满。下文将逐个碎片介绍，最终把整张图拼出来。 加法模型对于算法模型而言，一个性能弱的算法模型可能很难得到很好的效果，加法模型的思想是将性能较弱的模型通过加权得到一个性能较强的模型。形如 f(x)=\sum_{m=1}^{M}\beta_m b(x;\gamma_m)\tag{1}其中$b(x;y_m)$表示基函数，$\gamma_m$表示基函数系数，$\beta_m$表示基函数系数。 前向分布算法在给定训练集的情况下以及损失函数$L(y,f(x))$的条件下，学习加法模型$f(x)$即为最小化损失函数的问题： \min\limits_{\beta_m,\gamma_m}\sum_{i=1}^N L(y_i,\sum_{m=1}^M\beta_mb(x_i;\gamma_m))\tag{2}前向分步算法的思想：加法模型是不同模型的组合，因此从前向后每次学习一个基函数和基函数系数来逐步优化目标函数$(1)$,从而降低复杂度。 计算流程： (1).初始化第一个基函数$f_0(x)$ (2)对于$m=1,2,3,…,M$，极小化损失函数 (\beta_m,\gamma_m)=\arg \min\limits_{\beta,\gamma}+\beta_mb(x;\gamma_m)\tag{3}得到参数$\beta_m,\gamma_m$ (3) 更新加法模型 f_m(x)=f_{m-1}(x)+\beta_mb(x;\gamma_m)\tag{4}(4)得到加法模型 f(x)=\sum_{i=1}^M\beta_mb(x;\gamma_m)\tag{5}GBDT梯度提升模型提升树算法提升方法可以总结为加法模型与前向分布算法，以决策树为基函数的模型成为提升树，无论是分类问题还是回归问题，都是基于回归树(这点和统计学系方法里面不一样)，提升树算法则是采用前向分步算法来更新加法模型。对于提升树，基函数变为决策树，所以加法模型为 f_m(x)=\sum_{i=1}^MT(x;w_m)\tag{6}其中$M$为决策树的个数，$w$为决策树的参数，$T$表示决策树。 初始化第一棵决策树，第$m$部的模型为 f_m(x)=f_{m-1}(x)+T(x;w)\tag{7}通过最小化损失函数确定下一棵决策树的参数$w_m$ \arg\min\limits_{w_m}\sum_{i=1}^NL(y_i,f_{m-1}+T(x_i,w_m))当采用平方误差时 L(y,f(x))=(y-f(x))^2\tag{8}损失函数变为 L(y)=(y-f_{m-1}(x)-T(x;w_m))^2 =[r-T(x;w_m)]^2\tag{9}其中残差$r=y-f_{m-1}(x)$，所以最后的目的就是为了是$T(x;w_m)$的值更加接近残差，从而达到最小化损失函数的作用。 回归问题提升树1.计算出第一颗树第一棵提升树 f_0(x)=\arg \min\limits\sum_{i=1}^NL(y_i,c)\tag{10}2.得到提升树的残差 r_{mi}=y_i-f_{m-1}(x_i), i=1,2,3....,N\tag{11}3.通过拟合残茶学习回归树，得到$T_m(x;w_m)$ 4.更新提升树 f_m(x)=f_{m-1}(x)+T(x;w_m)\tag{12}梯度提升梯度提升本质其实是利用梯度下降算法来对前向分步算法进行优化求解的方法。其关键是利用损失函数负梯度在当前模型的值作为残差的近似值，进行一个拟合。 r_{mi}=-[\frac{\partial L(y,f(x_i))}{\partial f(x_i)}]_{f(x_i)=f_m(x_i) }\tag{13}利用负梯度代替残差的原因是因为只有在损失函数为平方差的时候，梯度才等于残差，但是当损失函数比较复杂的时候，此时梯度是不等于残差的。 对于特征的选择和回归树一样，同样是遍历所有特征找到最佳切分点。 回归例子可以参见统计学习方法。 GBDT用于分类和回归的区别前面主要将的是GBDT的思想，利用残差不断的拟合，直到最后接近目标。但是对于对于分类和回归任务的处理，主要有以下几个方面不一样。 特征选择1、分裂节点的评价标准不同 对于回归类问题，分裂节点的时候主要评价方式为 (1)平方误差 L(x,c)=min \sum_{i=1}^m\sum_{j\in R_i}(x_j-c_i)^2将特征划分为m个不同的区域$R_i$，然后求出每个区域的平方误差求和，平方误差和最小的特征和切分点。 (2)绝地值误差 L(x,c)=min \sum_{i=1}^m\sum_{j\in R_i}|x_j-c_i|(3)friedman_mse：费尔德曼均方误差，改进后的均方误差，一般能够达到比较好的效果 对于分类问题，其节点分类的评价方式为 (1)信息熵(entropy) H(x)=-\sum_{i=1}^np_i\log p_i(2)gini,基尼系数(信息增益) g(D,A)=H(D)-H(D|A)详细计算过程见统计学习方法。 损失函数在介绍分类的原理之前首先要了解一下对数损失函数 L(y,P(Y|X))=log P(Y|X)\tag{14}对于分类任务，GBDT是结合回归加分类模型计算每种分类的概率，对于二分类，采用的是logistic进行分类 P(Y=1|X)=\frac{1}{1+exp(-\sum_{i=1}^Mf_i(x))}\tag{15} P(Y=0|X)=\frac{1}{1+exp(\sum_{i=1}^Mf_i(x))}\tag{16}令$h_\theta(x)=\frac{1}{1+exp(-\sum_{i=1}^Mf_i(x))}$ 所以有 P(Y=1|X)=h_\theta(x)\tag{17} P(Y=0|X)=1-h_\theta(x)\tag{18} P(Y|X)=h_\theta(x)^{y_i}(1-h_\theta(x))^{1-y_i}损失函数为 J_\theta(x)=-\sum_{i=1}^N [y_ilogh_\theta(x)+(1-y_i)log(1-h_\theta(x))]\tag{19}所以经过计算有 \frac{\partial J}{\partial h_\theta(x)}=y-\hat y对于多分类问题 损失函数为交叉熵 L(y,p(y|x))=-\sum_{i=1}^M y_ilog {p_i}\tag{20}其中$i$表示所属类别，$M$表示分类树,$p_i$表示属于$i$的概率 并且有 p(y=i|x)=\frac{exp(F_i(x))}{\sum_{i=1}^Mexp(F_i(x))}\tag{21}同样求梯度有 r_{mi}=-\frac{\partial L(y_i,F(x_i))}{\partial F(x_i)}|_{f(x_i)=f_{m-1}(x_i)}回归损失函数 (1)平方损失函数 L(y,x)=\sum_{i=1}^n(y_i-f(x_i))^2(2)绝对值损失函数 L(y,x)=\sum_{i=1}^n|y_i-f(x_i)|(3)huber损失函数 L(y)=\left\{ \begin{array}{rcl} \frac{1}{2}(y-f(x))^2 & & {|y-f(x)|\leq\delta}\\ \delta*|y-f(x)-\frac{1}{2}\delta| & & {|y-f(x)|>\delta} \end{array} \right.GBDT的正则化和Adaboost一样，我们也需要对GBDT进行正则化，防止过拟合。GBDT的正则化主要有三种方式。 （1）第一种是和Adaboost类似的正则化项，即步长（learning rate）。定义为ν,对于前面的弱学习器的迭代 f_k(x)=f_{k-1}(x)+h_k(x) 如果我们加上了正则化项，则有 f_k(x)=f_{k-1}(x)+v\cdot h_k(x) ν的取值范围为0&lt;ν≤10。对于同样的训练集学习效果，较小的ν意味着我们需要更多的弱学习器的迭代次数。通常我们用步长和迭代最大次数一起来决定算法的拟合效果。 （2）第二种正则化的方式是通过子采样比例（subsample）。取值为(0,1]。注意这里的子采样和随机森林不一样，随机森林使用的是放回抽样，而这里是不放回抽样。如果取值为1，则全部样本都使用，等于没有使用子采样。如果取值小于1，则只有一部分样本会去做GBDT的决策树拟合。选择小于1的比例可以减少方差，即防止过拟合，但是会增加样本拟合的偏差，因此取值不能太低。推荐在[0.5, 0.8]之间。 使用了子采样的GBDT有时也称作随机梯度提升树(Stochastic Gradient Boosting Tree, SGBT)。由于使用了子采样，程序可以通过采样分发到不同的任务去做boosting的迭代过程，最后形成新树，从而减少弱学习器难以并行学习的弱点。（注：这一点没明白。。） （3）第三种是对于弱学习器即CART回归树进行正则化剪枝。在决策树章节里我们已经讲过，这里就不重复了。 调参经验分类sklearn.ensemble.`RandomForestClassifier Parameters n_estimators ：树的个数，迭代次数 The number of trees in the forest.Changed in version 0.22: The default value of n_estimators changed from 10 to 100 in 0.22. criterion： 叶子结点分裂的方式，默认的是gini和entropy max_depth：树的深度，默认为空，会一直分裂，直到无法继续分裂 min_samples_split： 分裂一个节点所需要的最小样本 int：表示样本数 float 表示的百分比 min_samples_leaf：保持一颗叶子结点所需要的样本数，该参数能够对模型进行平滑，特别在回归任务中。int和float和min_samples_split一样。 min_weight_fraction_leaf：叶子结点所有权重和的最小值，如果分布相差很大或者有很多缺失值，可以引入该参数 max_features：当考虑最佳分割点是考虑的特征数。 如果是float型，表示的是百分比 如果是’auto’ or ‘log2’，表示sqrt(n_features) 如果是log2, 表示log2(n_features) max_leaf_nodes : 最大叶子结点，用于防止过拟合 min_impurity_split：早停的阈值，如果一个节点的不纯度高于该值，则分裂，否则为叶子结点 Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.Deprecated since version 0.19: min_impurity_split has been deprecated in favor of min_impurity_decrease in 0.19. The default value of min_impurity_split will change from 1e-7 to 0 in 0.23 and it will be removed in 0.25. Use min_impurity_decrease instead. bootstrap： 是否使用bootstrap采样，为否表示使用整个数据集 oob_score：袋外精度来泛化 Whether to use out-of-bag samples to estimate the generalization accuracy. class_weight：类别权重，用于样本分布不均衡时使用 ‘’dict, list of dicts, “balanced”, “balanced_subsample” or None, optional (default=None） 格式为{class_label: weight} ，例如 {0: 1, 1: 1} ’balanced‘模式下会自动调整权值，根据训练数据中类别出现频率， n_samples/(n_class *np.bincount()) ‘balanced_subsample’和balanced一样，区别在于才用的boostrap max_samples：从训练集中取出的每个样本量 None：表示使用所有样本 如果为int 表示为该值 float表示 百分比 class sklearn.ensemble.``GradientBoostingRegressor loss ：损失函数，默认为ls ‘ls’ 平方损失函数，损失函数为$L(y)=(y-f(x))^2$ ‘lad’，绝对值 ,损失函数 $L(y)=|y-f(x)|$ ‘huber’： 两者的结合 L(y)=\left\{ \begin{array}{rcl} \frac{1}{2}(y-f(x))^2 & & {|y-f(x)|\leq\delta}\\ \delta*|y-f(x)-\frac{1}{2}\delta| & & {|y-f(x)|>\delta} \end{array} \right. subsample：子采样比例，子采样会减少方差，增大偏差 criterion： 衡量节点分裂质量的指标 friedman_mse, ‘mse’ ’mae‘ New in version 0.18. min_samples_split: 和分类一样 tol：学习率 参考资料 [1]https://zhuanlan.zhihu.com/p/86281279 [2].统计学习方法]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>决策树</tag>
        <tag>集成学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pandas的基本用法]]></title>
    <url>%2F2019%2F10%2F05%2Fpandas%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Matplotlib的基本用法]]></title>
    <url>%2F2019%2F10%2F04%2FMatplotlib%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Matplotlib的基本用法简单的折线图plt.plot(x,y, fortmat_string)作用是定义画图的样式x,y表示横纵左表， format可以定义画图格式12345678#导入Matploylib库from matplotlib import pyplot as plt %matplotlib inline #画布上画图plt.plot([1,2,3,4], [1,2,3,4], 'b', linewidth=2)plt.plot([1,2,3,4], [1,4,9,16], 'r', linewidth=2)#在画布上显示plt.show() 添加标题标签及图的样式123456789101112from matplotlib import pyplot as plt %matplotlib inline x = [5,2,7]y = [2,16,4]plt.plot(x,y)# 图片的标题plt.title('Image Title')# 坐标轴Y轴plt.ylabel('Y axis')# 坐标轴X轴plt.xlabel('X axis')plt.show() 12345678910111213141516from matplotlib import pyplot as pltfrom matplotlib import style style.use('ggplot')x = [5,8,10]y = [12,16,6]x2 = [6,9,11]y2 = [6,15,7]plt.plot(x,y,'g',label='line one', linewidth=5)plt.plot(x2,y2,'r',label='line two',linewidth=5)plt.title('Epic Info')plt.ylabel('Y axis')plt.xlabel('X axis')#设置图例位置plt.legend()plt.grid(True,color='k')plt.show() 直方图pyplot.bar(left, height, alpha=1, width=0.8, color=, edgecolor=, label=, lw=3) 画一个柱状图 参数 left： x轴的位置序列，一般采用arange函数产生一个序列 height: y轴的数值序列，也就是柱状图的高度，即我们需要展示的数据 alpha： 透明度 width: 柱状图的宽度 color or facecolor: 柱状图的填充颜色 edgecolor: 图形边缘颜色 label: 每个图像代表的意思 linewidth or linewidths or lw：边缘or线的宽度 12345678from matplotlib import pyplot as plt plt.bar([0.25,1.25,2.25,3.25,4.25],[50,40,70,80,20],label="BMW", color='b', width=.5)plt.bar([.75,1.75,2.75,3.75,4.75],[80,20,20,50,60],label="Audi", color='r',width=.5)plt.legend()plt.xlabel('Days')plt.ylabel('Distance (kms)')plt.title('Information')plt.show() 频率图matplotlib.pyplot.hist(x, bins=10, range=None, normed=False, weights=None, cumulative=False, bottom=None, histtype=u’bar’, align=u’mid’, orientation=u’vertical’, rwidth=None, log=False, color=None, label=None, stacked=False) 统计每个区间出现的频率 参数 x：直方图统计的数据 bins: 指定统计的间隔，如bins=10时表示以10为一个区间 color: 柱状图的颜色 histtype: 可选{‘bar’, ‘barstacked’,’step’, ‘stepfilled’}之一 density: 显示频率 stacked: 是否显示堆叠柱状图 12345678import matplotlib.pyplot as pltpopulation_age = [22,55,62,45,21,22,34,42,42,4,2,102,95,85,55,110,120,70,65,55,111,115,80,75,65,54,44,43,42,48]bins = [0,10,20,30,40,50,60,70,80,90,100]plt.hist(population_age, bins=10, histtype='bar', color='b', rwidth=0.8)plt.xlabel('age groups')plt.ylabel('Number of people')plt.title('Histogram')plt.show() 散点图12345678910111213import matplotlib.pyplot as pltx = [1,1.5,2,2.5,3,3.5,3.6]y = [7.5,8,8.5,9,9.5,10,10.5] x1=[8,8.5,9,9.5,10,10.5,11]y1=[3,3.5,3.7,4,4.5,5,5.2] # scatter表示画散点图plt.scatter(x,y, label='high income low saving',color='r')plt.scatter(x1,y1,label='low income high savings',color='b')plt.xlabel('saving*100')plt.ylabel('income*1000')plt.title('Scatter Plot')plt.legend()plt.show() 堆叠图matplotlib.pyplot.stackplot(x, args, labels=(), colors=None, baseline=’zero’, data=None, *kwargs) 画堆叠图，主要有三个参数 x:需要画堆叠图的数值 laebl: 堆叠图中折现的标签 colors: 设置折线图的颜色 1234567891011sleeping =[7,8,6,11,7]eating = [2,3,4,3,2]working =[7,8,7,2,2]playing = [8,5,7,8,13] labels = ['Sleeping', 'Eating', 'Working', 'Playing']plt.stackplot(days, sleeping,eating,working,playing,labels=labels,colors=['m','c','r','k']) plt.xlabel('x')plt.ylabel('y')plt.title('Stack Plot')plt.legend()plt.show() 饼状图123456slices = [7,3,2,13]activities = ['sleeping','eating','working','playing']cols = ['c','m','r','b'] plt.pie(slices, labels=activities, colors=cols, startangle=90, shadow= True, explode=(0,0.1,0,0), autopct='%1.1f%%') plt.title('Pie Plot')plt.show() 多个子图合并plt.subplot(numRows, numCols, plotNum) 将一块画布分为多个区域，将不同图分别放入不同的子图 参数 numRows：指的行数 numCols：指的列数 plotNum：子图的位置 如上面所示的221，表示的是将图分为2 * 2个子图，然后使用第一个位置 子图的位置依次为 123(1,1) (1,2)(2,1) (2,2) 依次对应的位置为1,2,3,4 1234567891011import numpy as npimport matplotlib.pyplot as plt def f(t): return np.exp(-t) * np.cos(2*np.pi*t)t1 = np.arange(0.0, 5.0, 0.1)t2 = np.arange(0.0, 5.0, 0.02)plt.subplot(221)plt.plot(t1, f(t1), 'bo', t2, f(t2))plt.subplot(222)plt.plot(t2, np.cos(2*np.pi*t2))plt.show() pandas与matplotlib结合123import pandas as pdimport numpy as npimport matplotlib.pyplot as plt np.random.rand(nums) 随即产生nums个位于[0,1]的样本 np.random.randn(nums) 随即返回nums个标准正态分布的样本 1plt.plot(np.random.rand(10)) 1[&lt;matplotlib.lines.Line2D at 0x24f3122c2b0&gt;] 设置坐标轴刻度 图名 x轴标签 y轴标签 图例 x轴边界 y轴边界 x轴刻度 y轴刻度 x轴刻度标签 y轴刻度标签 123456789101112131415161718192021df = pd.DataFrame(np.random.rand(10,2),columns=['A','B'])fig = df.plot(figsize=(8,4)) # figsize：创建图表窗口，设置窗口大小plt.title('TITLETITLETITLE') # 图名plt.xlabel('XXXXXX') # x轴标签plt.ylabel('YYYYYY') # y轴标签plt.legend(loc = 'upper right') # 显示图例，loc表示位置plt.xlim([0,12]) # x轴边界plt.ylim([0,1.5]) # y轴边界plt.xticks(range(10)) # 设置x刻度plt.yticks([0,0.2,0.4,0.6,0.8,1.0,1.2]) # 设置y刻度fig.set_xticklabels("%.1f" %i for i in range(10)) # x轴刻度标签fig.set_yticklabels("%.2f" %i for i in [0,0.2,0.4,0.6,0.8,1.0,1.2]) # y轴刻度标签# 这里x轴范围是0-12，但刻度只是0-9，刻度标签使得其显示1位小数 1234567[Text(0, 0, &apos;0.00&apos;), Text(0, 0, &apos;0.20&apos;), Text(0, 0, &apos;0.40&apos;), Text(0, 0, &apos;0.60&apos;), Text(0, 0, &apos;0.80&apos;), Text(0, 0, &apos;1.00&apos;), Text(0, 0, &apos;1.20&apos;)] 修改图标样式pd.Series()作用是产生一个有编号的序列 np.random.randn()产生正太分布的样本，当只有一个参数是，返回n个标准正太分布的结果，当有两个或多个参数时，参数表示对应的维度 np.random.rand() 用法和上面一个函数一样，但是返回的是 np.cumsum()表示将前一行或者前一列加到后面 参数 ​ a：表示传入函数的数据 axi：{0,1}，axi=0时表示行相加，axi=1时表示列相加 12s = pd.Series(np.random.randn(100).cumsum())s.plot(linestyle = '--', marker = '.',color="r",grid=False) dataframe直接画图DataFrame.plot(x=None, y=None, kind=’line’, ax=None, subplots=False, sharex=None, sharey=False, layout=None,figsize=None, use_index=True, title=None, grid=None, legend=True, style=None, logx=False, logy=False, loglog=False, xticks=None, yticks=None, xlim=None, ylim=None, rot=None, xerr=None,secondary_y=False, sort_columns=False, **kwds) Parameters:x : label or position, default None#指数据框列的标签或位置参数 y : label or position, default None kind : str‘line’ : line plot (default)#折线图‘bar’ : vertical bar plot#条形图‘barh’ : horizontal bar plot#横向条形图‘hist’ : histogram#柱状图‘box’ : boxplot#箱线图‘kde’ : Kernel Density Estimation plot#Kernel 的密度估计图，主要对柱状图添加Kernel 概率密度线‘density’ : same as ‘kde’‘area’ : area plot#不了解此图‘pie’ : pie plot#饼图‘scatter’ : scatter plot#散点图 需要传入columns方向的索引‘hexbin’ : hexbin plot#不了解此图 ax : matplotlib axes object, default None#子图(axes, 也可以理解成坐标轴) 要在其上进行绘制的matplotlib subplot对象。如果没有设置，则使用当前matplotlib subplot其中，变量和函数通过改变figure和axes中的元素（例如：title,label,点和线等等）一起描述figure和axes，也就是在画布上绘图。 subplots : boolean, default False#判断图片中是否有子图 Make separate subplots for each column sharex : boolean, default True if ax is None else False#如果有子图，子图共x轴刻度，标签 In case subplots=True, share x axis and set some x axis labels to invisible; defaults to True if ax is None otherwise False if an ax is passed in; Be aware, that passing in both an ax and sharex=True will alter all x axis labels for all axis in a figure! sharey : boolean, default False#如果有子图，子图共y轴刻度，标签 In case subplots=True, share y axis and set some y axis labels to invisible layout : tuple (optional)#子图的行列布局 (rows, columns) for the layout of subplots figsize : a tuple (width, height) in inches#图片尺寸大小 use_index : boolean, default True#默认用索引做x轴 Use index as ticks for x axis title : string#图片的标题用字符串 Title to use for the plot grid : boolean, default None (matlab style default)#图片是否有网格 Axis grid lines legend : False/True/’reverse’#子图的图例，添加一个subplot图例(默认为True) Place legend on axis subplots style : list or dict#对每列折线图设置线的类型 matplotlib line style per column logx : boolean, default False#设置x轴刻度是否取对数 Use log scaling on x axis logy : boolean, default False Use log scaling on y axis loglog : boolean, default False#同时设置x，y轴刻度是否取对数 Use log scaling on both x and y axes xticks : sequence#设置x轴刻度值，序列形式（比如列表） Values to use for the xticks yticks : sequence#设置y轴刻度，序列形式（比如列表） Values to use for the yticks xlim : 2-tuple/list#设置坐标轴的范围，列表或元组形式 ylim : 2-tuple/list rot : int, default None#设置轴标签（轴刻度）的显示旋转度数 Rotation for ticks (xticks for vertical, yticks for horizontal plots) fontsize : int, default None#设置轴刻度的字体大小 Font size for xticks and yticks colormap : str or matplotlib colormap object, default None#设置图的区域颜色 Colormap to select colors from. If string, load colormap with that name from matplotlib. colorbar : boolean, optional #图片柱子 If True, plot colorbar (only relevant for ‘scatter’ and ‘hexbin’ plots) position : float Specify relative alignments for bar plot layout. From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5 (center) layout : tuple (optional) #布局 (rows, columns) for the layout of the plot table : boolean, Series or DataFrame, default False #如果为正，则选择DataFrame类型的数据并且转换匹配matplotlib的布局。 If True, draw a table using the data in the DataFrame and the data will be transposed to meet matplotlib’s default layout. If a Series or DataFrame is passed, use passed data to draw a table. yerr : DataFrame, Series, array-like, dict and str See Plotting with Error Bars for detail. xerr : same types as yerr. stacked : boolean, default False in line and bar plots, and True in area plot. If True, create stacked plot. sort_columns : boolean, default False # 以字母表顺序绘制各列，默认使用前列顺序 secondary_y : boolean or sequence, default False ##设置第二个y轴（右y轴） Whether to plot on the secondary y-axis If a list/tuple, which columns to plot on secondary y-axis mark_right : boolean, default True When using a secondary_y axis, automatically mark the column labels with “(right)” in the legend kwds : keywords Options to pass to matplotlib plotting method Returns:axes : matplotlib.AxesSubplot or np.array of them 12345# 直接用风格样式设置# 透明度与颜色版# s.plot(style="--.",alpha = 0.8,colormap = 'Reds_r')df = pd.DataFrame(np.random.randn(100, 4),columns=list('ABCD')).cumsum()df.plot(style = '--.',alpha = 0.8,colormap = 'summer_r') 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x24f379a4cc0&gt; 123df = pd.DataFrame(np.random.randn(10,2))df.plot(style = '--o')plt.text(5,0.5,'Hello',fontsize=12) 1Text(5, 0.5, &apos;Hello&apos;) 子图绘制figure对象plt.figure(num=None, figsize=None, dpi=None, facecolor=None, edgecolor=None, frameon=True, FigureClass=, **kwargs) 作用创建一块画布 num相当于id，如果没有id则递增创建，如果已存在则返回该存在的对象 1234fig1 = plt.figure(num=1,figsize=(8,6))plt.plot(np.random.rand(50).cumsum(),'k--')fig2 = plt.figure(num=2,figsize=(8,6))plt.plot(50-np.random.rand(50).cumsum(),'k--') 1[&lt;matplotlib.lines.Line2D at 0x24f3780f6d8&gt;] 先创建子图然后填充12345678910111213141516171819202122# 先建立子图然后填充图表fig = plt.figure(figsize=(10,6),facecolor = 'gray')# 第一个子图曲线图ax1 = fig.add_subplot(2,2,1)plt.plot(np.random.rand(50).cumsum(),'k--')plt.plot(np.random.randn(50).cumsum(),'b--')# 第二个字图，直方图ax2 = fig.add_subplot(2,2,2)ax2.hist(np.random.rand(50),alpha=0.4)# 第三个饼状图slices = [7,3,2,13]activities = ['sleeping','eating','working','playing']cols = ['c','m','r','b']ax3 = fig.add_subplot(223)ax3.pie(slices, labels=activities, colors=cols, startangle=90, shadow= True, explode=(0,0.1,0,0), autopct='%1.1f%%')# 第四个折线图ax4 = fig.add_subplot(2,2,4) df2 = pd.DataFrame(np.random.rand(10, 4), columns=['a', 'b', 'c', 'd'])ax4.plot(df2,alpha=0.5,linestyle='--',marker='.') 1234[&lt;matplotlib.lines.Line2D at 0x24f38c19940&gt;, &lt;matplotlib.lines.Line2D at 0x24f3905ed68&gt;, &lt;matplotlib.lines.Line2D at 0x24f3905ef28&gt;, &lt;matplotlib.lines.Line2D at 0x24f3906b0f0&gt;] 使用subplots子图数组填充子图12345678910# 创建一个新的figure，并返回一个subplot对象的numpy数组 → plt.subplotfig,axes = plt.subplots(2,3,figsize=(10,4))ts = pd.Series(np.random.randn(1000).cumsum())print(axes, axes.shape, type(axes))# 生成图表对象的数组# 通过数组访问对应的子图ax1 = axes[0,1]ax1.plot(ts) 123456[[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F38EFABA8&gt; &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F38F13BA8&gt; &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F38CA4C88&gt;] [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F38CC8DA0&gt; &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F38CECEB8&gt; &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F38D17320&gt;]] (2, 3) &lt;class &apos;numpy.ndarray&apos;&gt; 1[&lt;matplotlib.lines.Line2D at 0x24f38d39978&gt;] 12345678910# plt.subplots 参数调整fig,axes = plt.subplots(2,2,sharex=True,sharey=True)# sharex,sharey：是否共享x，y刻度for i in range(2): for j in range(2): axes[i,j].hist(np.random.randn(500),color='k',alpha=0.5) # wspace,hspace：用于控制宽度和高度的百分比，比如subplot之间的间距plt.subplots_adjust(wspace=0,hspace=0) 多系列子图绘制plt.plot(): subplots, 是否分别绘制子图,为true的时候表示分开绘制，为false表示在一个图立面绘制 layout：挥之子图矩阵，按顺序填充 subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=None) 有六个可选参数来控制子图布局。值均为0~1之间。其中left、bottom、right、top围成的区域就是子图的区域。wspace、hspace分别表示子图之间左右、上下的间距。实际的默认值由matplotlibrc文件控制的。 1234567df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=list('ABCD'))df = df.cumsum()df.plot(style = '--.',alpha = 0.4,grid = True,figsize = (20,8), subplots = True, layout = (2,2), sharex = False)plt.subplots_adjust(wspace=0.1,hspace=0.2) 基本图表绘制Series 与 DataFrame 绘图plt.plot(kind=’line’, ax=None, figsize=None, use_index=True, title=None, grid=None, legend=False,style=None, logx=False, logy=False, loglog=False, xticks=None, yticks=None, xlim=None, ylim=None,rot=None, fontsize=None, colormap=None, table=False, yerr=None, xerr=None, label=None, secondary_y=False, **kwds) 参数含义： series的index为横坐标 value为纵坐标 kind → line,bar,barh…（折线图，柱状图，柱状图-横…） label → 图例标签，Dataframe格式以列名为label style → 风格字符串，这里包括了linestyle（-），marker（.），color（g） color → 颜色，有color指定时候，以color颜色为准 alpha → 透明度，0-1 use_index → 将索引用为刻度标签，默认为True rot → 旋转刻度标签，0-360 grid → 显示网格，一般直接用plt.grid xlim,ylim → x,y轴界限 xticks,yticks → x,y轴刻度值 figsize → 图像大小 title → 图名 legend → 是否显示图例，一般直接用plt.legend() 12345678910111213141516171819ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000)) # pandas 时间序列ts = ts.cumsum()ts.plot(kind='line', label = "what", style = '--.', color = 'g', alpha = 0.4, use_index = True, rot = 45, grid = True, ylim = [-50,50], yticks = list(range(-50,50,10)), figsize = (8,4), title = 'TEST_TEST', legend = True)# 对网格项进行更加细致的设置#plt.grid(True, linestyle = "--",color = "gray", linewidth = "0.5",axis = 'x') # 网格plt.legend()plt.show() 12345678910111213# subplots → 是否将各个列绘制到不同图表，默认Falsedf = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=list('ABCD')).cumsum()df.plot(kind='line', style = '--.', alpha = 0.4, use_index = True, rot = 45, grid = True, figsize = (8,4), title = 'test', legend = True, subplots = False, colormap = 'Greens') 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x24f32b0f630&gt; 柱状图 plt.bar() x,y参数：x，y值 width：宽度比例 facecolor柱状图里填充的颜色、edgecolor是边框的颜色 left-每个柱x轴左边界,bottom-每个柱y轴下边界 → bottom扩展即可化为甘特图 Gantt Chart align：决定整个bar图分布，默认left表示默认从左边界开始绘制,center会将图绘制在中间位置xerr/yerr ：x/y方向error bar 1234567891011121314151617181920# 创建一个新的figure，并返回一个subplot对象的numpy数组fig,axes = plt.subplots(4,1,figsize = (10,10))s = pd.Series(np.random.randint(0,10,16),index = list('abcdefghijklmnop')) df = pd.DataFrame(np.random.rand(10,3), columns=['a','b','c'])# 单系列柱状图方法一：plt.plot(kind='bar/barh')s.plot(kind='bar',color = 'k',grid = True,alpha = 0.5,ax = axes[0]) # ax参数 → 选择第几个子图# 多系列柱状图df = pd.DataFrame(np.random.rand(10,3), columns=['a','b','c'])df.plot(kind='bar',ax = axes[1],grid = True,colormap='Reds_r')# 多系列堆叠图# stacked → 堆叠df.plot(kind='bar',ax = axes[2],grid = True,colormap='Blues_r',stacked=True) # The bars are positioned at y with the given align. Their dimensions are given by width and height. The horizontal baseline is left (default 0). # https://matplotlib.org/api/_as_gen/matplotlib.pyplot.barh.html?highlight=barh#matplotlib.pyplot.barhdf.plot.barh(ax = axes[3],grid = True,stacked=True,colormap = 'BuGn_r') 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x24f32cf0550&gt; 123456789101112131415plt.figure(figsize=(10,4))x = np.arange(10)y1 = np.random.rand(10)y2 = -np.random.rand(10)plt.bar(x,y1,width = 1,facecolor = 'yellowgreen',edgecolor = 'white',yerr = y1*0.1)plt.bar(x,y2,width = 1,facecolor = 'lightskyblue',edgecolor = 'white',yerr = y2*0.1)for i,j in zip(x,y1): plt.text(i-0.2,j-0.15,'%.2f' % j, color = 'white')for i,j in zip(x,y2): plt.text(i-0.2,j+0.05,'%.2f' % -j, color = 'white')# 给图添加text# zip() 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。 面积图 stacked：是否堆叠，默认情况下，区域图被堆叠 为了产生堆积面积图，每列必须是正值或全部负值！ 当数据有NaN时候，自动填充0，图标签需要清洗掉缺失值 1234567fig,axes = plt.subplots(2,1,figsize = (8,6))df1 = pd.DataFrame(np.random.rand(10, 4), columns=['a', 'b', 'c', 'd'])df2 = pd.DataFrame(np.random.randn(10, 4), columns=['a', 'b', 'c', 'd'])df1.plot.area(colormap = 'Greens_r',alpha = 0.5,ax = axes[0])df2.plot.area(stacked=False,colormap = 'Set2',alpha = 0.5,ax = axes[1]) 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x24f3288f668&gt; 填图123456789101112131415161718192021fig,axes = plt.subplots(2,1,figsize = (8,6))x = np.linspace(0, 1, 500)y1 = np.sin(4 * np.pi * x) * np.exp(-5 * x)y2 = -np.sin(4 * np.pi * x) * np.exp(-5 * x)axes[0].fill(x, y1, 'r',alpha=0.5,label='y1')axes[0].fill(x, y2, 'g',alpha=0.5,label='y2')# 对函数与坐标轴之间的区域进行填充，使用fill函数# 也可写成：plt.fill(x, y1, 'r',x, y2, 'g',alpha=0.5)x = np.linspace(0, 5 * np.pi, 1000) y1 = np.sin(x) y2 = np.sin(2 * x) axes[1].fill_between(x, y1, y2, color ='b',alpha=0.5,label='area') # 填充两个函数之间的区域，使用fill_between函数for i in range(2): axes[i].legend() axes[i].grid()# 添加图例、格网 饼图plt.pie(x, explode=None, labels=None, colors=None, autopct=None, pctdistance=0.6, shadow=False, labeldistance=1.1, startangle=None, radius=None, counterclock=True, wedgeprops=None, textprops=None, center=(0, 0), frame=False, hold=None, data=None) 参数含义： 第一个参数：数据 explode：指定每部分的偏移量 labels：标签 colors：颜色 autopct：饼图上的数据标签显示方式 pctdistance：每个饼切片的中心和通过autopct生成的文本开始之间的比例 labeldistance：被画饼标记的直径,默认值：1.1 shadow：阴影 startangle：开始角度 radius：半径 frame：图框 counterclock：指定指针方向，顺时针或者逆时针 1234567891011121314s = pd.Series(3 * np.random.rand(4), index=['a', 'b', 'c', 'd'], name='series')plt.axis('equal') # 保证长宽相等plt.pie(s, explode = [0.1,0,0,0], labels = s.index, colors=['r', 'g', 'b', 'c'], autopct='%.2f%%', pctdistance=0.6, labeldistance = 1.2, shadow = True, startangle=0, radius=1.5, frame=False)plt.show() 直方图plt.hist(x, bins=10, range=None, normed=False, weights=None, cumulative=False, bottom=None,histtype=’bar’, align=’mid’, orientation=’vertical’,rwidth=None, log=False, color=None, label=None,stacked=False, hold=None, data=None, **kwargs) 参数 bin：箱子的宽度 normed 标准化 histtype 风格，bar，barstacked，step，stepfilled orientation 水平还是垂直{‘horizontal’, ‘vertical’} align : {‘left’, ‘mid’, ‘right’}, optional(对齐方式) stacked：是否堆叠 1234567891011# 直方图s = pd.Series(np.random.randn(1000))s.hist(bins = 20, histtype = 'bar', align = 'mid', orientation = 'vertical', alpha=0.5, normed =True)# 密度图s.plot(kind='kde',style='k--')plt.show() 123D:\Program Files (x86)\Anaconda3\lib\site-packages\pandas\plotting\_core.py:2477: MatplotlibDeprecationWarning: The &apos;normed&apos; kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use &apos;density&apos; instead. ax.hist(values, bins=bins, **kwds) 123456789101112131415# 堆叠直方图plt.figure(num=1)df = pd.DataFrame(&#123;'a': np.random.randn(1000) + 1, 'b': np.random.randn(1000), 'c': np.random.randn(1000) - 1, 'd': np.random.randn(1000)-2&#125;, columns=['a', 'b', 'c','d'])df.plot.hist(stacked=True, bins=20, colormap='Greens_r', alpha=0.5, grid=True)# 使用DataFrame.plot.hist()和Series.plot.hist()方法绘制df.hist(bins=50)# 生成多个直方图 12345array([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F34C1B710&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F34C4D2E8&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F34C80898&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F34CB2E48&gt;]], dtype=object) 1&lt;Figure size 432x288 with 0 Axes&gt; 散点图plt.scatter(x, y, s=20, c=None, marker=’o’, cmap=None, norm=None, vmin=None, vmax=None, alpha=None, linewidths=None,verts=None, edgecolors=None, hold=None, data=None, **kwargs) 参数含义： s：散点的大小 c：散点的颜色 vmin,vmax：亮度设置，标量 cmap：colormap 1234567891011plt.figure(figsize=(8,6))x = np.random.randn(1000)y = np.random.randn(1000)plt.scatter(x,y,marker='.', s = np.random.randn(1000)*100, cmap = 'Reds_r', c = y, alpha = 0.8,)plt.grid() 12D:\Program Files (x86)\Anaconda3\lib\site-packages\matplotlib\collections.py:857: RuntimeWarning: invalid value encountered in sqrt scale = np.sqrt(self._sizes) * dpi / 72.0 * self._factor 123456789101112# pd.scatter_matrix()散点矩阵# pd.scatter_matrix(frame, alpha=0.5, figsize=None, ax=None, # grid=False, diagonal='hist', marker='.', density_kwds=None, hist_kwds=None, range_padding=0.05, **kwds)# diagonal：(&#123;‘hist’, ‘kde’&#125;)，必须且只能在&#123;‘hist’, ‘kde’&#125;中选择1个 → 每个指标的频率图# range_padding：(float, 可选)，图像在x轴、y轴原点附近的留白(padding)，该值越大，留白距离越大，图像远离坐标原点df = pd.DataFrame(np.random.randn(100,4),columns = ['a','b','c','d'])pd.plotting.scatter_matrix(df,figsize=(10,6), marker = 'o', diagonal='kde', alpha = 0.5, range_padding=0.5) 1234567891011121314151617array([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F39EB5828&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F222278&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F37E518&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F391F98&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F3AF128&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F3C5278&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F3DC3C8&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F3F3550&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F3F3588&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F41FC18&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F43C208&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F4507B8&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F466D68&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F483358&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F498908&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3F4AFEB8&gt;]], dtype=object) 箱型图箱型图：又称为盒须图、盒式图、盒状图或箱线图，是一种用作显示一组数据分散情况资料的统计图 包含一组数据的：最大值、最小值、中位数、上四分位数（Q1）、下四分位数（Q3）、异常值 ① 中位数 → 一组数据平均分成两份，中间的数 ② 下四分位数Q1 → 是将序列平均分成四份，计算(n+1)/4与(n-1)/4两种，一般使用(n+1)/4 ③ 上四分位数Q3 → 是将序列平均分成四份，计算(1+n)/4*3=6.75 ④ 内限 → T形的盒须就是内限，最大值区间Q3+1.5IQR,最小值区间Q1-1.5IQR （IQR=Q3-Q1） ⑤ 外限 → T形的盒须就是内限，最大值区间Q3+3IQR,最小值区间Q1-3IQR （IQR=Q3-Q1） ⑥ 异常值 → 内限之外 - 中度异常，外限之外 - 极度异常 plt.plot.box(),plt.boxplot() 123456789101112131415# plt.plot.box()绘制fig,axes = plt.subplots(2,1,figsize=(10,6))df = pd.DataFrame(np.random.rand(10, 5), columns=['A', 'B', 'C', 'D', 'E'])color = dict(boxes='DarkGreen', whiskers='DarkOrange', medians='DarkBlue', caps='Gray')# 箱型图着色# boxes → 箱线# whiskers → 分位数与error bar横线之间竖线的颜色# medians → 中位数线颜色# caps → error bar横线颜色df.plot.box(ylim=[0,1.2], grid = True, color = color, ax = axes[0]) 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x24f394cc9b0&gt; 1234567891011121314151617181920212223242526272829303132333435df = pd.DataFrame(np.random.rand(10, 5), columns=['A', 'B', 'C', 'D', 'E'])plt.figure(figsize=(10,4))# 创建图表、数据f = df.boxplot(sym = 'o', # 异常点形状，参考marker vert = True, # 是否垂直 whis = 1.5, # IQR，默认1.5，也可以设置区间比如[5,95]，代表强制上下边缘为数据95%和5%位置 patch_artist = True, # 上下四分位框内是否填充，True为填充 meanline = False,showmeans=True, # 是否有均值线及其形状 showbox = True, # 是否显示箱线 showcaps = True, # 是否显示边缘线 showfliers = True, # 是否显示异常值 notch = False, # 中间箱体是否缺口 return_type='dict' # 返回类型为字典 ) plt.title('boxplot')for box in f['boxes']: box.set( color='b', linewidth=1) # 箱体边框颜色 box.set( facecolor = 'b' ,alpha=0.5) # 箱体内部填充颜色for whisker in f['whiskers']: whisker.set(color='k', linewidth=0.5,linestyle='-')for cap in f['caps']: cap.set(color='gray', linewidth=2)for median in f['medians']: median.set(color='DarkBlue', linewidth=2)for flier in f['fliers']: flier.set(marker='o', color='y', alpha=0.5)# boxes, 箱线# medians, 中位值的横线,# whiskers, 从box到error bar之间的竖线.# fliers, 异常值# caps, error bar横线# means, 均值的横线, 1234567891011# plt.boxplot()绘制# 分组汇总df = pd.DataFrame(np.random.rand(10,2), columns=['Col1', 'Col2'] )df['X'] = pd.Series(['A','A','A','A','A','B','B','B','B','B'])df['Y'] = pd.Series(['A','B','A','B','A','B','A','B','A','B'])df.boxplot(by = 'X')df.boxplot(column=['Col1','Col2'], by=['X','Y'])# columns：按照数据的列分子图# by：按照列分组做箱型图 123array([&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F3519AD68&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000024F34B67C88&gt;], dtype=object)]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>matplotlib</tag>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Matplotlib的Seaborn风格可视化]]></title>
    <url>%2F2019%2F10%2F04%2FMatplotlib%E7%9A%84Seaborn%E9%A3%8E%E6%A0%BC%E5%8F%AF%E8%A7%86%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Seaborn风格可视化什么是seaborn​ Seaborn是基于matplotlib的图形可视化python包。它提供了一种高度交互式界面，便于用户能够做出各种有吸引力的统计图表。Seaborn是在matplotlib的基础上进行了更高级的API封装，从而使得作图更加容易，在大多数情况下使用seaborn能做出很具有吸引力的图，而使用matplotlib就能制作具有更多特色的图。应该把Seaborn视为matplotlib的补充，而不是替代物。同时它能高度兼容numpy与pandas数据结构以及scipy与statsmodels等统计模式。 seaborn APISeaborn 要求原始数据的输入类型为 pandas 的 Dataframe 或 Numpy 数组，画图函数有以下几种形式: sns.图名(x=’X轴 列名’, y=’Y轴 列名’, data=原始数据df对象) sns.图名(x=’X轴 列名’, y=’Y轴 列名’, hue=’分组绘图参数’, data=原始数据df对象) sns.图名(x=np.array, y=np.array[, …]) 123456import numpy as npimport pandas as pdimport scipy as statsimport matplotlib.pyplot as pltimport seaborn as sns%matplotlib inline 基本绘图设置1234567# 创建正弦函数def sinplot(flip=1): x = np.linspace(0, 14, 100) for i in range(1,7): plt.plot(x, np.sin(x+i*.5)*(7-i)*flip)sinplot() 简单切换成Seaborn风格1234# 切换Seaborn风格sns.set()fig = plt.figure(figsize=(8,6))sinplot() 1234567891011# 切换seaborn图标风格fig = plt.figure(figsize=(10,6), facecolor='white')ax1 = fig.add_subplot(211)sns.set_style('whitegrid')data = np.random.normal(size=(20,6))+np.arange(6)/2sns.boxplot(data=data)plt.title('style-whitegrid')ax2 = fig.add_subplot(212)sns.set_style('dark')sinplot() 设置图标坐标轴1234567891011121314151617181920212223242526#despine()# seaborn.despine(fig=None, ax=None, top=True, right=True, left=False, bottom=False, offset=None, trim=False)# 设置风格sns.set_style("ticks")# 创建图表fig = plt.figure(figsize=(6,9))plt.subplots_adjust(hspace=0.3)ax1 = fig.add_subplot(3,1,1) sinplot()# 删除了上、右坐标轴sns.despine()ax2 = fig.add_subplot(3,1,2)sns.violinplot(data=data)# offset：与坐标轴之间的偏移# trim：为True时，将坐标轴限制在数据最大最小值#sns.despine(offset=10, trim=True)ax3 = fig.add_subplot(3,1,3)# top, right, left, bottom：布尔型，为True时不显示#sns.despine(left=True, right = False)sns.boxplot(data=data, palette="deep") 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b20e4f7a58&gt; 设置局部图标风格123456789with sns.axes_style("darkgrid"): plt.subplot(211) sinplot()# 设置局部图表风格，用with做代码块区分sns.set_style("whitegrid")plt.subplot(212)sinplot()# 外部表格风格 设置显示比例123456789#set_context()# 选择包括：'paper', 'notebook', 'talk', 'poster'## 与上面的cell比较你就会发现不同 sns.set_style("whitegrid")sns.set_context("poster")plt.subplot(212)sinplot() 调色板123456789# color_palette()# 默认6种颜色：deep, muted, pastel, bright, dark, colorblind# seaborn.color_palette(palette=None, n_colors=None, desat=None)current_palette = sns.color_palette()print(type(current_palette))# sns.palplot(current_palette[2:4])sns.palplot(current_palette) 1&lt;class &apos;seaborn.palettes._ColorPalette&apos;&gt; 颜色风格1234567891011121314# 颜色风格内容：Accent, Accent_r, Blues, Blues_r, BrBG, BrBG_r, BuGn, BuGn_r, BuPu, # BuPu_r, CMRmap, CMRmap_r, Dark2, Dark2_r, GnBu, GnBu_r, Greens, Greens_r, Greys, Greys_r, OrRd, OrRd_r, Oranges, Oranges_r, PRGn, PRGn_r, # Paired, Paired_r, Pastel1, Pastel1_r, Pastel2, Pastel2_r, PiYG, PiYG_r, PuBu, PuBuGn, PuBuGn_r, PuBu_r, PuOr, PuOr_r, PuRd, PuRd_r, Purples,# Purples_r, RdBu, RdBu_r, RdGy, RdGy_r, RdPu, RdPu_r, RdYlBu, RdYlBu_r, RdYlGn, RdYlGn_r, Reds, Reds_r, Set1, Set1_r, Set2, Set2_r, Set3, # Set3_r, Spectral, Spectral_r, Wistia, Wistia_r, YlGn, YlGnBu, YlGnBu_r, YlGn_r, YlOrBr, YlOrBr_r, YlOrRd, YlOrRd_r, afmhot, afmhot_r, # autumn, autumn_r, binary, binary_r, bone, bone_r, brg, brg_r, bwr, bwr_r, cool, cool_r, coolwarm, coolwarm_r, copper, copper_r, cubehelix, # cubehelix_r, flag, flag_r, gist_earth, gist_earth_r, gist_gray, gist_gray_r, gist_heat, gist_heat_r, gist_ncar, gist_ncar_r, gist_rainbow, # gist_rainbow_r, gist_stern, gist_stern_r, gist_yarg, gist_yarg_r, gnuplot, gnuplot2, gnuplot2_r, gnuplot_r, gray, gray_r, hot, hot_r, hsv, # hsv_r, icefire, icefire_r, inferno, inferno_r, jet, jet_r, magma, magma_r, mako, mako_r, nipy_spectral, nipy_spectral_r, ocean, ocean_r, # pink, pink_r, plasma, plasma_r, prism, prism_r, rainbow, rainbow_r, rocket, rocket_r, seismic, seismic_r, spectral, spectral_r, spring, # spring_r, summer, summer_r, terrain, terrain_r, viridis, viridis_r, vlag, vlag_r, winter, winter_rsns.palplot(sns.color_palette('Accent',12))sns.palplot(sns.color_palette('Accent_r',8)) 设置饱和度和亮度1234sns.palplot(sns.hls_palette(4,l=.3,s=.8))# l-&gt;亮度# s-&gt;饱和度 设置颜色线性变化1234567891011#设置颜色线性变化sns.palplot(sns.cubehelix_palette(16, gamma=2))sns.palplot(sns.cubehelix_palette(16, start=.5, rot=.75))sns.palplot(sns.cubehelix_palette(16,start=0.5, rot=0, dark=0.95, reverse=True))# n_colors → 颜色个数# start → 值区间在0-3，开始颜色# rot → 颜色旋转角度# gamma → 颜色伽马值，越大颜色越暗# dark，light → 值区间0-1，颜色深浅# reverse → 布尔值，默认为False，由浅到深 创建分散颜色123456plt.figure(figsize = (8,6))x = np.arange(25).reshape(5, 5)# 创建分散颜色cmap = sns.diverging_palette(200, 20, sep=20, as_cmap=True)sns.heatmap(x, cmap=cmap) 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21a370cf8&gt; 123456789sns.set_style('whitegrid')fig=plt.figure(figsize=(12,8))with sns.color_palette('PuBuGn_d'): plt.subplot(211) sinplot() sns.set_palette('husl')plt.subplot(212)sinplot() 123456sns.set_style('darkgrid')sns.set_context('paper')import warningswarnings.filterwarnings('ignore')#不再发出警告 分布数据可视化直方图12345678910111213141516#直方图#设计随即种子rs = np.random.RandomState(10)s = pd.Series(rs.randn(100)*100)sns.distplot(s, bins=10, hist=True, kde=False, norm_hist=False, rug=True,vertical=False,color='y', label='distplot', axlabel='x')plt.legend()# bins → 箱数# hist、ked → 是否显示箱/密度曲线# norm_hist → 直方图是否按照密度来显示# rug → 是否显示数据分布情况# vertical → 是否水平显示# color → 设置颜色# label → 图例# axlabel → x轴标注 1&lt;matplotlib.legend.Legend at 0x1b20e65e4e0&gt; 123456sns.distplot(s, rug=True, rug_kws=&#123;'color':'g'&#125;, kde_kws=&#123;"color": "k", "lw": 1, "label": "KDE",'linestyle':'--'&#125;, # 设置密度曲线颜色，线宽，标注、线形 hist_kws=&#123;"histtype": "step", "linewidth": 1,"alpha": 1, "color": "g"&#125;) # 设置箱子的风格、线宽、透明度、颜色 # 风格包括：'bar', 'barstacked', 'step', 'stepfilled' 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21bc8e828&gt; 密度图123456789101112131415161718# 密度图 - kdeplot()# 单个样本数据密度分布图sns.kdeplot(s, shade = False, # 是否填充 color = 'b', # 设置颜色 vertical = False # 设置是否水平 )sns.kdeplot(s,bw=5, label="bw: 0.2", linestyle = '-',linewidth = 1.2,alpha = 0.5)sns.kdeplot(s,bw=20, label="bw: 2", linestyle = '-',linewidth = 1.2,alpha = 0.5)# bw → 控制拟合的程度，类似直方图的箱数sns.rugplot(s,height = 0.1,color = 'k',alpha = 0.5)# 数据频率分布图 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21babf470&gt; 123456789101112131415161718# 密度图 - kdeplot()# 两个样本数据密度分布图rs = np.random.RandomState(2) # 设定随机数种子df = pd.DataFrame(rs.randn(100,2), columns = ['A','B'])sns.kdeplot(df['A'],df['B'], cbar = True, # 是否显示颜色图例 shade = True, # 是否填充 cmap = 'Reds', # 设置调色盘 shade_lowest=False, # 最外围颜色是否显示 n_levels = 10 # 曲线个数（如果非常多，则会越平滑） )# 两个维度数据生成曲线密度图，以颜色作为密度衰减显示sns.rugplot(df['A'], color="g", axis='x',alpha = 0.5)sns.rugplot(df['B'], color="r", axis='y',alpha = 0.5)# 注意设置x，y轴 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21bb63470&gt; 1234567891011121314151617# 密度图 - kdeplot()# 两个样本数据密度分布图# 多个密度图rs1 = np.random.RandomState(2) rs2 = np.random.RandomState(5) df1 = pd.DataFrame(rs1.randn(100,2)+2,columns = ['A','B'])df2 = pd.DataFrame(rs2.randn(100,2)-2,columns = ['A','B'])# 创建数据sns.kdeplot(df1['A'],df1['B'],cmap = 'Greens', shade = True,shade_lowest=False)sns.kdeplot(df2['A'],df2['B'],cmap = 'Blues', shade = True,shade_lowest=False)# 创建图表#sns.rugplot(df2['A']+df1['A'], color="g", axis='x',alpha = 0.5)#sns.rugplot(df2['B']+df1['B'], color="r", axis='y',alpha = 0.5) 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21be56278&gt; 综合散点图1234567891011121314151617# 综合散点图 - jointplot()# 散点图 + 分布图rs = np.random.RandomState(2) df = pd.DataFrame(rs.randn(200,2),columns = ['A','B'])sns.jointplot(x=df['A'], y=df['B'], # 设置xy轴，显示columns名称 data=df, # 设置数据 color = 'k', # 设置颜色 s = 50, edgecolor="w",linewidth=1, # 设置散点大小、边缘线颜色及宽度(只针对scatter） kind = 'scatter', # 设置类型：“scatter”、“reg”、“resid”、“kde”、“hex” space = 0.2, # 设置散点图和布局图的间距 size = 8, # 图表大小（自动调整为正方形） ratio = 5, # 散点图与布局图高度比，整型 marginal_kws=dict(bins=15, rug=True) # 设置柱状图箱数，是否设置rug ) 1&lt;seaborn.axisgrid.JointGrid at 0x1b21bee2be0&gt; 12345678910# 综合散点图 - jointplot()# 散点图 + 分布图# 六边形图df = pd.DataFrame(rs.randn(500,2),columns = ['A','B'])with sns.axes_style("white"): sns.jointplot(x=df['A'], y=df['B'],data = df, kind="hex", color="g", marginal_kws=dict(bins=20)) 123456789101112131415# 综合散点图 - jointplot()# 散点图 + 分布图# 密度图rs = np.random.RandomState(15)df = pd.DataFrame(rs.randn(300,2),columns = ['A','B'])# 创建数据g = sns.jointplot(x=df['A'], y=df['B'],data = df, kind="kde", color="k", shade_lowest=False)# 创建密度图g.plot_joint(plt.scatter,c="w", s=30, linewidth=1, marker="*")# 添加散点图 1&lt;seaborn.axisgrid.JointGrid at 0x1b21c4325f8&gt; 1234567891011121314151617181920212223242526# 综合散点图 - JointGrid()# 可拆分绘制的散点图# plot_joint() + ax_marg_x.hist() + ax_marg_y.hist()sns.set_style("white")# 设置风格tips = sns.load_dataset("tips")print(tips.head())# 导入数据g = sns.JointGrid(x="total_bill", y="tip", data=tips)# 创建一个绘图表格区域，设置好x、y对应数据g.plot_joint(plt.scatter, color ='m', edgecolor = 'white') # 设置框内图表，scatterg.ax_marg_x.hist(tips["total_bill"], color="b", alpha=.6, bins=np.arange(0, 60, 3)) # 设置x轴直方图，注意bins是数组g.ax_marg_y.hist(tips["tip"], color="r", alpha=.6, orientation="horizontal", bins=np.arange(0, 12, 1)) # 设置x轴直方图，注意需要orientation参数from scipy import statsg.annotate(stats.pearsonr) # 设置标注，可以为pearsonr，spearmanrplt.grid(linestyle = '--') 123456 total_bill tip sex smoker day time size0 16.99 1.01 Female No Sun Dinner 21 10.34 1.66 Male No Sun Dinner 32 21.01 3.50 Male No Sun Dinner 33 23.68 3.31 Male No Sun Dinner 24 24.59 3.61 Female No Sun Dinner 4 1234567891011# 综合散点图 - JointGrid()# 可拆分绘制的散点图# plot_joint() + plot_marginals()g = sns.JointGrid(x="total_bill", y="tip", data=tips)# 创建一个绘图表格区域，设置好x、y对应数据g = g.plot_joint(plt.scatter,color="g", s=40, edgecolor="white") # 绘制散点图plt.grid(linestyle = '--')g.plot_marginals(sns.distplot, kde=True, color="g") # 绘制x，y轴直方图 1&lt;seaborn.axisgrid.JointGrid at 0x1b21c630da0&gt; 123456789101112# 综合散点图 - JointGrid()# 可拆分绘制的散点图# plot_joint() + plot_marginals()# kde - 密度图g = sns.JointGrid(x="total_bill", y="tip", data=tips)# 创建一个绘图表格区域，设置好x、y对应数据g = g.plot_joint(sns.kdeplot,cmap = 'Reds_r') # 绘制密度图plt.grid(linestyle = '--')g.plot_marginals(sns.kdeplot, shade = True, color="r") # 绘制x，y轴密度图 1&lt;seaborn.axisgrid.JointGrid at 0x1b21d7aef60&gt; 矩阵散点图1234567891011121314151617# 矩阵散点图 - pairplot()sns.set_style("white")# 设置风格iris = sns.load_dataset("iris")print(iris.head())# 读取数据sns.pairplot(iris, kind = 'scatter', # 散点图/回归分布图 &#123;‘scatter’, ‘reg’&#125; diag_kind="hist", # 直方图/密度图 &#123;‘hist’, ‘kde’&#125; hue="species", # 按照某一字段进行分类 palette="husl", # 设置调色板 markers=["o", "s", "D"], # 设置不同系列的点样式（这里根据参考分类个数） size = 2, # 图表大小 ) 123456 sepal_length sepal_width petal_length petal_width species0 5.1 3.5 1.4 0.2 setosa1 4.9 3.0 1.4 0.2 setosa2 4.7 3.2 1.3 0.2 setosa3 4.6 3.1 1.5 0.2 setosa4 5.0 3.6 1.4 0.2 setosa 1&lt;seaborn.axisgrid.PairGrid at 0x1b21d8a44e0&gt; 123456# 矩阵散点图 - pairplot()# 只提取局部变量进行对比sns.pairplot(iris,vars=["sepal_width", "sepal_length"], kind = 'reg', diag_kind="kde", hue="species", palette="husl") 1&lt;seaborn.axisgrid.PairGrid at 0x1b21e003c18&gt; 123456789# 矩阵散点图 - pairplot()# 其他参数设置sns.pairplot(iris, diag_kind="kde", markers="+", plot_kws=dict(s=50, edgecolor="b", linewidth=1), # 设置点样式 diag_kws=dict(shade=True) # 设置密度图样式 ) 1&lt;seaborn.axisgrid.PairGrid at 0x1b21c37be48&gt; 123456789101112131415161718192021# 矩阵散点图 - PairGrid()# 可拆分绘制的散点图# map_diag() + map_offdiag()g = sns.PairGrid(iris,hue="species",palette = 'hls', vars = ['sepal_length','sepal_width','petal_length','petal_width'], # 可筛选 )# 创建一个绘图表格区域，设置好x、y对应数据，按照species分类g.map_diag(plt.hist, histtype = 'barstacked', # 可选：'bar', 'barstacked', 'step', 'stepfilled' linewidth = 1, edgecolor = 'w') # 对角线图表，plt.hist/sns.kdeplotg.map_offdiag(plt.scatter, edgecolor="w", s=40,linewidth = 1, # 设置点颜色、大小、描边宽度 ) # 其他图表，plt.scatter/plt.bar...g.add_legend()# 添加图例 1&lt;seaborn.axisgrid.PairGrid at 0x1b218fe3f98&gt; 12345678# 矩阵散点图 - PairGrid()# 可拆分绘制的散点图# map_diag() + map_lower() + map_upper()g = sns.PairGrid(iris)g.map_diag(sns.kdeplot, lw=3) # 设置对角线图表g.map_upper(plt.scatter, color = 'r') # 设置对角线上端图表g.map_lower(sns.kdeplot, cmap="Blues_d") # 设置对角线下端图表 1&lt;seaborn.axisgrid.PairGrid at 0x1b21ee966a0&gt; 分类数据可视化分类散点图1234567891011121314# stripplot()# 按照不同类别对样本数据进行分布散点图绘制tips = sns.load_dataset("tips")print(tips.head())sns.stripplot(x="day", # x → 设置分组统计字段 y="total_bill", # y → 数据分布统计字段 # 这里xy数据对调，将会使得散点图横向分布 data=tips, # data → 对应数据 jitter = True, # jitter → 当点数据重合较多时，用该参数做一些调整，也可以设置间距如：jitter = 0.1 size = 5, edgecolor = 'w',linewidth=1,marker = 'o' # 设置点的大小、描边颜色或宽度、点样式 ) 123456 total_bill tip sex smoker day time size0 16.99 1.01 Female No Sun Dinner 21 10.34 1.66 Male No Sun Dinner 32 21.01 3.50 Male No Sun Dinner 33 23.68 3.31 Male No Sun Dinner 24 24.59 3.61 Female No Sun Dinner 4 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21f971320&gt; 12345# stripplot()# 通过hue参数再分类sns.stripplot(x="sex", y="total_bill", hue="day", data=tips, jitter=True) 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21f9b2b00&gt; 12345678# stripplot()# 设置调色盘sns.stripplot(x="sex", y="total_bill", hue="day", data=tips, jitter=True, palette="Set2", # 设置调色盘 dodge=True, # 是否拆分 ) 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21fc11198&gt; 123456789# stripplot()# 筛选分类类别print(tips['day'].value_counts())# 查看day字段的唯一值sns.stripplot(x="day", y="total_bill", data=tips,jitter = True, order = ['Sat','Sun'])# order → 筛选类别 12345Sat 87Sun 76Thur 62Fri 19Name: day, dtype: int64 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21fc8c748&gt; 分簇散点图1234567# swarmplot()# 分簇散点图sns.swarmplot(x="total_bill", y="day", data=tips, size = 5, edgecolor = 'w',linewidth=1,marker = 'o', palette = 'Reds')# 用法和stripplot类似 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21fcdef28&gt; 箱型图123456789101112131415# boxplot()sns.boxplot(x="day", y="total_bill", data=tips, linewidth = 2, # 线宽 width = 0.8, # 箱之间的间隔比例 fliersize = 3, # 异常点大小 palette = 'hls', # 设置调色板 whis = 1.5, # 设置IQR notch = True, # 设置是否以中值做凹槽 order = ['Thur','Fri','Sat','Sun'], # 筛选类别 )# 绘制箱型图#sns.swarmplot(x="day", y="total_bill", data=tips,color ='k',size = 3,alpha = 0.8)# 可以添加散点图 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21fd32710&gt; 123# 通过hue参数再分类sns.boxplot(x="day", y="total_bill", data=tips, hue = 'smoker', palette = 'Reds') 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21fdce5c0&gt; 小提琴图12345678910111213# violinplot()sns.violinplot(x="day", y="total_bill", data=tips, linewidth = 2, # 线宽 width = 0.8, # 箱之间的间隔比例 palette = 'hls', # 设置调色板 order = ['Thur','Fri','Sat','Sun'], # 筛选类别 scale = 'area', # 测度小提琴图的宽度：area-面积相同，count-按照样本数量决定宽度，width-宽度一样 gridsize = 50, # 设置小提琴图边线的平滑度，越高越平滑 inner = 'box', # 设置内部显示类型 → “box”, “quartile”, “point”, “stick”, None #bw = 0.8 # 控制拟合程度，一般可以不设置 ) 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21feb0d68&gt; 123456# 通过hue参数再分类sns.violinplot(x="day", y="total_bill", data=tips, hue = 'smoker', palette="muted", split=True, # 设置是否拆分小提琴图 inner="quartile") 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21ff37940&gt; 12345# 结合散点图sns.violinplot(x="day", y="total_bill", data=tips, palette = 'hls', inner = None)sns.swarmplot(x="day", y="total_bill", data=tips, color="w", alpha=.5)# 插入散点图 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21fff0e80&gt; LV图123456789101112# lvplot()sns.lvplot(x="day", y="total_bill", data=tips, palette="mako", #hue = 'smoker', width = 0.8, # 箱之间间隔比例 linewidth = 12, scale = 'area', # 设置框的大小 → “linear”、“exonential”、“area” k_depth = 'proportion', # 设置框的数量 → “proportion”、“tukey”、“trustworthy” )# 绘制LV图sns.swarmplot(x="day", y="total_bill", data=tips,color ='k',size = 3,alpha = 0.8)# 可以添加散点图 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b22101c400&gt; 分类统计图1234567891011121314151617181920# barplot()# 柱状图 - 置信区间估计# 置信区间：样本均值 + 抽样误差titanic = sns.load_dataset("titanic")#print(titanic.head())#print('-----')# 加载数据sns.barplot(x="sex", y="survived", hue="class", data=titanic, palette = 'hls', order = ['male','female'], # 筛选类别 capsize = 0.05, # 误差线横向延伸宽度 saturation=.8, # 颜色饱和度 errcolor = 'gray',errwidth = 2, # 误差线颜色，宽度 ci = 'sd' # 置信区间误差 → 0-100内值、'sd'、None )#print(titanic.groupby(['sex','class']).mean()['survived'])#print(titanic.groupby(['sex','class']).std()['survived'])# 计算数据 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b2210a1048&gt; 1234567# barplot()# 柱状图 - 置信区间估计sns.barplot(x="day", y="total_bill", hue="sex", data=tips, palette = 'Blues',edgecolor = 'w')tips.groupby(['day','sex']).mean()# 计算数据 .dataframe tbody tr th:only-of-type { vertical-align: middle; } 1234567.dataframe tbody tr th &#123; vertical-align: top;&#125;.dataframe thead th &#123; text-align: right;&#125; total_bill tip size day sex Thur Male 18.714667 2.980333 2.433333 Female 16.715312 2.575625 2.468750 Fri Male 19.857000 2.693000 2.100000 Female 14.145556 2.781111 2.111111 Sat Male 20.802542 3.083898 2.644068 Female 19.680357 2.801786 2.250000 Sun Male 21.887241 3.220345 2.810345 Female 19.872222 3.367222 2.944444 12345678910111213141516171819202122# 1、barplot()# 柱状图 - 置信区间估计crashes = sns.load_dataset("car_crashes").sort_values("total", ascending=False)print(crashes.head())# 加载数据f, ax = plt.subplots(figsize=(6, 15))# 创建图表sns.set_color_codes("pastel")sns.barplot(x="total", y="abbrev", data=crashes, label="Total", color="b",edgecolor = 'w')# 设置第一个柱状图sns.set_color_codes("muted")sns.barplot(x="alcohol", y="abbrev", data=crashes, label="Alcohol-involved", color="b",edgecolor = 'w')# 设置第二个柱状图ax.legend(ncol=2, loc="lower right")sns.despine(left=True, bottom=True) 12345678910111213 total speeding alcohol not_distracted no_previous ins_premium \40 23.9 9.082 9.799 22.944 19.359 858.97 34 23.9 5.497 10.038 23.661 20.554 688.75 48 23.8 8.092 6.664 23.086 20.706 992.61 3 22.4 4.032 5.824 21.056 21.280 827.34 17 21.4 4.066 4.922 16.692 16.264 872.51 ins_losses abbrev 40 116.29 SC 34 109.72 ND 48 152.56 WV 3 142.39 AR 17 137.13 KY 1234567# countplot()# 计数柱状图sns.countplot(x="class", hue="who", data=titanic,palette = 'magma')#sns.countplot(y="class", hue="who", data=titanic,palette = 'magma') # x/y → 以x或者y轴绘图（横向，竖向）# 用法和barplot相似 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b22117aac8&gt; 123456789101112# pointplot()# 折线图 - 置信区间估计sns.pointplot(x="time", y="total_bill", hue = 'smoker',data=tips, palette = 'hls', dodge = True, # 设置点是否分开 join = True, # 是否连线 markers=["o", "x"], linestyles=["-", "--"], # 设置点样式、线型 )tips.groupby(['time','smoker']).mean()['total_bill']# 计算数据# # 用法和barplot相似 123456time smokerLunch Yes 17.399130 No 17.050889Dinner Yes 21.859429 No 20.095660Name: total_bill, dtype: float64 线性数据可视化基本使用1234567891011# 基本用法tips = sns.load_dataset("tips")print(tips.head())# 加载数据sns.lmplot(x="total_bill", y="tip", hue = 'smoker',data=tips,palette="Set1", ci = 70, # 误差值 size = 5, # 图表大小 markers = ['+','o'], # 点样式 ) 123456 total_bill tip sex smoker day time size0 16.99 1.01 Female No Sun Dinner 21 10.34 1.66 Male No Sun Dinner 32 21.01 3.50 Male No Sun Dinner 33 23.68 3.31 Male No Sun Dinner 24 24.59 3.61 Female No Sun Dinner 4 1&lt;seaborn.axisgrid.FacetGrid at 0x1b21c57d7b8&gt; 多表格1sns.lmplot(x="total_bill", y="tip", col="smoker", data=tips) 1&lt;seaborn.axisgrid.FacetGrid at 0x1b2215774e0&gt; 1234567# 多图表1sns.lmplot(x="size", y="total_bill", hue="day", col="day",data=tips, aspect=0.6, # 长宽比 x_jitter=.30, # 给x或者y轴随机增加噪音点 col_wrap=4, # 每行的列数 ) 1&lt;seaborn.axisgrid.FacetGrid at 0x1b2216276a0&gt; 12345# 多图表2sns.lmplot(x="total_bill", y="tip", row="sex", col="time",data=tips, size=4)# 行为sex字段，列为time字段# x轴total_bill, y轴tip 1&lt;seaborn.axisgrid.FacetGrid at 0x1b22160a400&gt; 非线性回归1234# 非线性回归sns.lmplot(x="total_bill", y="tip",data=tips, order = 2) 1&lt;seaborn.axisgrid.FacetGrid at 0x1b2214d7b00&gt; 其他图表可视化时间线图123456789101112131415# tsplot()x = np.linspace(0, 15, 31)data = np.sin(x) + np.random.rand(10, 31) + np.random.randn(10, 1)#print(data.shape)#print(pd.DataFrame(data).head())# 创建数据sns.tsplot(data=data, err_style="ci_band", # 误差数据风格，可选：ci_band, ci_bars, boot_traces, boot_kde, unit_traces, unit_points interpolate=True, # 是否连线 ci = [40,70,90], # 设置误差区间 color = 'r' # 设置颜色 ) 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b21668c860&gt; 123sns.tsplot(data=data, err_style="boot_traces", n_boot=300 # 迭代次数 ) 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b216533048&gt; 12345678910111213gammas = sns.load_dataset("gammas")print(gammas.head())print('数据量为：%i条' % len(gammas))print('timepoint为0.0时的数据量为：%i条' % len(gammas[gammas['timepoint'] == 0]))print('timepoint共有%i个唯一值' % len(gammas['timepoint'].value_counts()))#print(gammas['timepoint'].value_counts()) # 查看唯一值具体信息# 导入数据sns.tsplot(time="timepoint", # 时间数据，x轴 value="BOLD signal", # y轴value unit="subject", # condition="ROI", # 分类 data=gammas) 123456789 timepoint ROI subject BOLD signal0 0.0 IPS 0 0.5134331 0.0 IPS 1 -0.4143682 0.0 IPS 2 0.2146953 0.0 IPS 3 0.8148094 0.0 IPS 4 -0.894992数据量为：6000条timepoint为0.0时的数据量为：60条timepoint共有100个唯一值 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b221f95a58&gt; 热图123456789# 热图 - heatmap()# 简单示例df = pd.DataFrame(np.random.rand(10,15))# 创建数据 - 10*12图表sns.heatmap(df, # 加载数据 vmin=0, vmax=1 # 设置图例最大最小值 ) 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b221faac88&gt; 123456789101112131415161718# heatmap()# 参数设置flights = sns.load_dataset("flights")flights = flights.pivot("month", "year", "passengers") #print(flights.head())# 加载数据 sns.heatmap(flights, annot = True, # 是否显示数值 fmt = 'd', # 格式化字符串 linewidths = 0.2, # 格子边线宽度 #center = 100, # 调色盘的色彩中心值，若没有指定，则以cmap为主 #cmap = 'Reds', # 设置调色盘 cbar = True, # 是否显示图例色带 #cbar_kws=&#123;"orientation": "horizontal"&#125;, # 是否横向显示图例色带 #square = True, # 是否正方形显示图表 ) 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b223040588&gt; 123456789101112131415161718192021# heatmap()# 绘制半边热图sns.set(style="white")# 设置风格rs = np.random.RandomState(33)d = pd.DataFrame(rs.normal(size=(100, 26)))corr = d.corr() # 求解相关性矩阵表格# 创建数据mask = np.zeros_like(corr, dtype=np.bool)mask[np.triu_indices_from(mask)] = True# 设置一个“上三角形”蒙版cmap = sns.diverging_palette(220, 10, as_cmap=True)# 设置调色盘sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, square=True, linewidths=0.2)# 生成半边热图 1&lt;matplotlib.axes._subplots.AxesSubplot at 0x1b2231f3128&gt; 图标矩阵12345678910111213141516attend = sns.load_dataset("attention")print(attend.head())# 加载数据g = sns.FacetGrid(attend, col="subject", col_wrap=5, # 设置每行的图表数量 size=1.5)g.map(plt.plot, "solutions", "score", marker="o",color = 'gray',linewidth = 2)# 绘制图表矩阵g.set(xlim = (0,4), ylim = (0,10), xticks = [0,1,2,3,4], yticks = [0,2,4,6,8,10] )# 设置x，y轴刻度 123456 Unnamed: 0 subject attention solutions score0 0 1 divided 1 2.01 1 2 divided 1 3.02 2 3 divided 1 3.03 3 4 divided 1 5.04 4 5 divided 1 4.0 1&lt;seaborn.axisgrid.FacetGrid at 0x1b22328cb00&gt;]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>matplotlib</tag>
        <tag>可视化</tag>
        <tag>Seaborn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PCA主成分分析]]></title>
    <url>%2F2019%2F09%2F26%2FPCA%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[S_B=(u_1-u_2)(u_1-u_2)^T S_w^{-1}(u_1-u_2)(u_1-u_2)^Tw=\lambda W因为$(u_1-u_2)^Tw$是一个标量，所以可以看出 W\propto S_W^{-1}(u_1-u_2)需要注意的是$S_W$在大多数情况下是不可逆的，所以为了解决这个问题，通常有两种方法 令$S_W=S_W+\gamma I$，其中$I$是一个特别小的数，这样$S_W$一定可逆 先使用PCA对数据局进行降维，使得降维后的数据的$S_W$一定可逆 S_w=\sum_{i=1}^C S_{wi} S_{wi}=\sum_{x\in{y_i}}(x-\mu_i)(x-\mu_i)^T S_B=\sum_{i=1}^C\frac{N_i}{N}(\mu_i-\mu)(\mu_i-\mu)^T其中$\mu$表示所有的特征值得均值 \mu=\frac{1}{N}\sum_{\forall x\in y_i}x而$\mu_i$求的是每一个分类的均值，在而分类中$S_B$表示的是类间的差值，但是在多分类中肯定无法这样计算，所以分类中计算的是每个分类中心点到所以分类中心点的方差。C表示的是分类数。 最后得到的结果和原来还是一样 S_w^{-1}S_Bw_i=\lambda w_i所以总结下来LDA的计算流程为 计算每个分类的特征中心值$\mu$ 计算每个分类的类内方差$S_W$ 计算每个分类的类间方差$S_B$ 计算评价函数$J(w)=\frac{wS_Bw^t}{wS_ww^t}$ 利用拉格朗日得到最后的结果 LDA用于降维，和PCA有很多相同，也有很多不同的地方，因此值得好好的比较一下两者的降维异同点。 首先我们看看相同点： 1）两者均可以对数据进行降维。 2）两者在降维时均使用了矩阵特征分解的思想。 3）两者都假设数据符合高斯分布。 我们接着看看不同点： 1）LDA是有监督的降维方法，而PCA是无监督的降维方法 2）LDA降维最多降到类别数k-1的维数，而PCA没有这个限制。，所以 3）LDA除了可以用于降维，还可以用于分类。 4）LDA选择分类性能最好的投影方向，而PCA选择样本点投影具有最大方差的方向。 这点可以从下图形象的看出，在某些数据分布下LDA比PCA降维较优。 感觉使用latex写公式真的爽的一笔啊 f(x)=\frac{1}{x}+3y+7z]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>特征工程</tag>
        <tag>特征降维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据挖掘比赛技巧]]></title>
    <url>%2F2019%2F09%2F21%2F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E6%AF%94%E8%B5%9B%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[特征工程 缺失值填充 特征为连续值，且为正态分布，使用均值填充，保持期望不变 特征值为连续值，且为长尾分布，使用中值填充，避免异常点影响 特征为离散值，使用众数填充 使用模型预测完善用户画像 特征转换 对长尾分布的特征，做对数变换 标准化、归一化 连续值特征离散化 基于LR、SVM、DNN等对特征的分布和尺度敏感的，归一化有助于模型收敛，基于树模型，具有伸缩不变形，不需要做特征变换 ID类特征处理 OneHot编码，例如性别，编码为0,1或者1,0 使用某种特征的统计量代替该特征 Word Embedding，将高纬稀疏特征映射到低纬稠密特征。 异常值剔除 模型选择1、对于高维稀疏特征(如ID特征 One hot编码后)，使用线性模型LR、FM(腾讯社交广告大赛) 2、对于低纬稠密特征，使用集成树模型XgBoost，GDBT，Random Forest(o2o优惠券核销预测) 3、对于图像语音类数据，使用DNN，如CNN，LSTM 数据挖掘比赛中集成树模型占优势的原因： 比赛数据特点 结构化标单数据 混合类型(类别型，连续型) 大量缺失值 含有离群点 长尾分布 树算法模型法特点 善于处理混合类型特征 善于处理缺失值 伸缩不变性 对离群点有鲁棒性 容易并行化、有高效开源工具 模型融合Average、Voting、Stacking，Blending Stacking工具mlxtend 调参经验和技巧 树模型调参经验 GridSearchCV]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>特征工程</tag>
        <tag>数据降维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hive的基本操作]]></title>
    <url>%2F2019%2F09%2F17%2Fhive%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[表的增删改查操作创建表使用if not exists 如果存在则跳过，comment为注释。123456789create table if not exists mydb.employees( name string comment 'Employee name', salary float comment 'Employee salary', subordinates array&lt;string&gt; comment 'Names of subordinates', deduction map&lt;string, float&gt;, address struct&lt;street:string, city:string, state:string, zip:int&gt; comment 'Home address')comment 'descriptions of table'location '/user/hive/warehouse/mydb.db/employees'; 描述表显示表的字段和结构，使用desc/describe 1234--显示表的字段和数据类型desc table_name;--显示对应字段的数据类型desc table_name.columns 管理表和外部表管理表是hive创建的表，由hive控制其生命周期，hive默认情况下会将数据存在在配置文件指定的目录当中，由hive.metastore.warehouse.dir指定。当使用hive删除表的时候，对应的数据也会被删除，即hdfs文件系统中的数据也会被删除。管理表的缺点在于无法共享数据，比如利用pig等工具创建的数据，hive对其没有权限。当使用hive查询这些数据的时候就可以使用一个外部表指向这份数据，而不需要对其的权限。外部表需要使用external修饰。 123456789101112create external table if not exists stocks( exchange string, symbol string, ymd string, price__open string, price__high string, price__low string, price__close float, volume int, price_adj_close float)row format delimited fields terminated by ',' '分隔符为,'location 'data/stocks'; 加上external字段值后，删除表并不会删除这份数据，不过描述标的元数据信息会被删除。元数据可以理解为对该表的描述信息，而不是表内数据。 需要注意的是如果语句省略了external关键字同事源表是外部表，那么新表也是外部表，如果源表是管理表，新表也是管理表。在加上external之后，无论源表是管理表还是外部表，新表都是外部表。 分区表在建表过程中，会根据分区字段创建对应目录，优点在于分层存储，可以加快查询速度，而缺点在于一些数据存在于文件目录下，但是hive只能从表中读取数据，因此会造成资源浪费。分区表创建： 12345678create table employees( name string, salary float, subordinates array&lt;string&gt;, deduction map&lt;string,float&gt;, address struct&lt;street:string, city:string, city:string, state:string&gt;)partitioned by (country string, state string); 在建表的时候hive在hdfs上的目录为…/employees/country/state 查看表中存在所有分区 1show partitions employees; 查询指定分区 1show partitions employees partition(country='CHINA') 删除表1drop table if exists table_name; 对于管理表，表的元数据和表内数据都会被删除。 修改表 表的重命名将表从ａ重命名为ｂ 1alter table a rename to b; 增加表分区1234567alter table add partiion--在一个查询语句中增加多个分区alter table table_name if not exists partition(...) location '/user/hive/warehouse/a'partition(...) location '/user/hive/warehouse/b'partition(...) location '/user/hive/warehouse/c' 修改列的信息将列名从a改到b，并且将其移到serverity字段后面。 1234alter table table_name change column a b type_name '修改列的数据类型'comment 'xxx'after serverity 增加新的列1234alter table table_name add column( app_name string comment 'Application name', session_id long comment 'the current session id';) 删除或替换列1234alter table table_name replace columns（ hour_mins_secs INT comment 'xxx' severity string comment 'xxx';) 将之前的列都删除，只留下replace的列 修改表的属性1alter table table_name set tblproperties('notes'='xxx'); 修改表的存储属性1alter table table_name partition(a=xxx,b=xxx,c=xxx) set fileformat sequencefile; 指定对应的分区中的表，并且重新设置其格式。 加载和导出数据从本地加载数据123load data local inpath '/home/hadopp/data.txt'overwrite into table employeespartition(country='US',state='CA'); 需要注意的是创建分区表的时候使用的是partition by。如果目录不存在，hive会先创建分区目录。 通过查询语句加载数据123insert overwrite table employeespartition(country='US',state='CA')select * from table_name where xxx=xxx; 通过查询语句建表12create table if not exists table_name as select * from table_name_b; 导出数据12345--方法一，谁用hadoop提供的工具hadoop fs -cp source_path target_path--方法二insert overwrite local directory '/home/hadoop/employees'select * from employees; hive的连接操作table stu 12341 chenli 212 xuzeng 223 xiaodan 234 hua 24 table sub 12341 chinese2 english3 science5 nature 内连接inner join，关键字 join on。仅列出两个表中符合连接条件的数据。 12345select a.*,b.* from stu a join sub b on a.id=b.id--结果1 chenli 21 1 chinese2 xuzeng 22 2 english3 xiaodan 23 3 science join后面连接表，而on指定连接条件。 左连接和右连接左连接，显示左边表的所有数据，如果右边表有与之对应的数据则显示，否则显示为NULL。 123456select a.* from stu a left outer join sub b on a.id=b.id;--结果1 chenli 21 1 chinese2 xuzeng 22 2 english3 xiaodan 23 3 science4 hua 24 NULL NULL 右连接与左连接相反，使用的关键字为 right outer join xxx on xxx。 标准查询关键字执行顺序为 from-&gt;where-&gt;group by-&gt;having-&gt;order by。 全连接左表和右表都显示，如果没有对应数据，则都显示为NULL 1234567select a.* from stu a full outer join sub b on a.id=b.id;--结果1 chenli 21 1 chinese2 xuzeng 22 2 english3 xiaodan 23 3 science4 hua 24 NULL NULLNULL NULL NULL 5 nature 左半开连接左半开连接。left semi join，语法与左连接不一样，只能选择出左边表的数据，此数据符合on后面的条件。 1234567select a.* from stu a left semi join sub b on a.id=b.id;--结果1 chenli 212 xuzeng 223 xiaodan 23--下列语句会报错select a.*,b.* from stu a left semi join sub b on a.id=b.id; 笛卡尔连接123456789101112131415161718select a.*,b.* from cl_student a join cl_stu_sub b;--结果1 chenli 21 1 chinese1 chenli 21 2 english1 chenli 21 3 science1 chenli 21 5 nature2 xuzeng 22 1 chinese2 xuzeng 22 2 english2 xuzeng 22 3 science2 xuzeng 22 5 nature3 xiaodan 23 1 chinese3 xiaodan 23 2 english3 xiaodan 23 3 science3 xiaodan 23 5 nature4 hua 24 1 chinese4 hua 24 2 english4 hua 24 3 science4 hua 24 5 nature 花了几天的时间整理了hive的用法，终于不用在对着SQL摸瞎了，加油吧进击的SQL boy！ 日常福利(●´∀｀●)]]></content>
      <categories>
        <category>大数据</category>
        <category>hive编程</category>
      </categories>
      <tags>
        <tag>Hive</tag>
        <tag>基本操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hive数据类型]]></title>
    <url>%2F2019%2F09%2F08%2Fhive%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[文本文件数据编码 TSV：tab separated values；即“制表符分隔值”，用制表符分隔数据 CSV： comma separated values；即“逗号分隔值”，用逗号分隔数据 两种文件存在的缺点在于文件中可能存在不需要作为分隔符的逗号或者制表符存在，所有hive有专门的分隔符。hive记录中默认的分隔符 分隔符 描述 \n 对于文本文件来说每一行都是记录，可以使用换行符作为分隔符 ^A(ctrl+A) 用于分隔字段(列)，在CREATE TABLE 语句中可以使用八进制编码\001表示，键盘上打不出来。 ^B 用于分隔array或者struct中的元素，或于用map钟键值对的分隔，在CREATE TABLE中使用\002表示 ^C 用于MAP钟键与值的分隔，用\003表示 读时模式传统数据库是写时模式，即在写入文件的时候会，会对数据的格式进行校验，如果不符合，将无法写入数据库。 hive是读时模式，在往数据库里写入不会对数据进行校验，但是在读取数据的时候会对数据进行校验，对于不合格的数据，会设置为null。 hive的优点在于加载(写)数据的时候速度较快，因为不需要对数据进行解析，而传统写时模式则有利于数据的查询。 好久没有更新博客了，这篇虽然水了点，写得像个笔记，算是开篇吧，福利就上亚丝娜吧!!!]]></content>
      <categories>
        <category>大数据</category>
        <category>hive编程</category>
      </categories>
      <tags>
        <tag>Hive</tag>
        <tag>编码类型</tag>
      </tags>
  </entry>
</search>
